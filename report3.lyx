#LyX 1.6.2 created this file. For more info see http://www.lyx.org/
\lyxformat 345
\begin_document
\begin_header
\textclass amsbook
\begin_preamble



\usepackage{amsfonts}
\end_preamble
\use_default_options false
\begin_modules
theorems-ams
\end_modules
\language english
\inputencoding auto
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\paperfontsize 10
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry true
\use_amsmath 1
\use_esint 0
\cite_engine basic
\use_bibtopic false
\paperorientation portrait
\leftmargin 1.5in
\topmargin 1in
\rightmargin 1.5in
\bottommargin 1.25in
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\author "" 
\author "" 
\end_header

\begin_body

\begin_layout Title
Motivated Decision-Making using Transformation Invariant Probability Estimates
\end_layout

\begin_layout Author
Ryan Michael
\begin_inset Newline newline
\end_inset

 
\family typewriter
kerinin@gmail.com
\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset nomencl_print
LatexCommand printnomenclature

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Chapter
Introduction
\end_layout

\begin_layout Section
General Overview
\end_layout

\begin_layout Standard
The goal is to create a method of statistical inference capable of processing
 multiple sources of data which are both multi-variate and exhibit transformatio
n-invariant behaviors.
 This type of data is common, and developing a robust method of analysis
 has applications in many domains.
 
\end_layout

\begin_layout Standard
For any estimator of a probability density function, the accuracy (measured
 by the confidence interval) of the estimator can be shown to depend on
 two factors; the number of observations from which the estimates are made
 and the amount of information the estimator is capable of extracting from
 from those observations.
 Existing estimators, such as the Parzen Window estimator extract information
 about the probability of a given point by comparing the distance between
 that point and the set of points previously observed; the greater the number
 of points in that are "close", the higher the probability.
 It is possible to determine the confidence interval of such an estimator
 using the VC Entropy of the estimating function.
 The VC Entropy of an estimator is based on the number of points which are
 needed to "cover" the observations with some level of closeness.
 This is to say that if the set of observations contain multiple points
 which are "close" to each other, the estimator can ignore all but one in
 generating estimates (provided the number of similar points is retained).
\end_layout

\begin_layout Standard
Our task is to develop a set of estimators whose confidence interval is
 less than the confidence interval determined by the VC Entropy, and we
 do so by extending the concept of VC Entropy to sets of observations under
 linear transformations.
 Where the VC Entropy is determined by the number of points necessary to
 "cover" the set of observations, we define the Transformation-Invariant
 Entropy (TI Entropy) as the number of 
\emph on
sets of points
\emph default
 necessary to "cover" the observations under linear transformations.
 In the same way that the VC Entropy is determined by the similarity between
 individual observations, the TI Entropy is determined between sets of observati
ons.
 
\end_layout

\begin_layout Standard
The distance between two points can easily be determined using well-known
 distance metrics; the distance between two sets of points requires that
 we develop a new distance metric.
 This distance metric measures the potential similarity between two sets
 when one has been subjected to some linear transformation.
 For simplicity we will integrate this similarity measure over all possible
 transformations; the resulting similarity measure will describe the net
 similarity of the two sets under 
\emph on
any
\emph default
 linear transformation.
 It is for this reason that we refer to our extension of the VC Entropy
 as Transformation-Invariant.
 It will be shown that the TI Entropy is necessarily less than or equal
 to the VC Entropy, and that as a result the confidence interval of an estimator
 based on the TI-distance between sets of observations is necessarily greater
 than or equal to that of estimators based on the distance between individual
 points.
 
\end_layout

\begin_layout Standard
Because the computational complexity of TI-based estimators is higher than
 that of traditional estimators we will develop search heuristics allowing
 us to confine the TI analysis to subsets of the observations which are
 likely to provide useful results.
 We will develop an ensemble system capable of applying TI analysis to multiple
 subsets and combining the results of these analyses.
 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Intro motivation and decision-making
\end_layout

\end_inset


\end_layout

\begin_layout Section
Formal Setting
\end_layout

\begin_layout Standard
We use the notation of Vapnik - given three components:
\end_layout

\begin_layout Enumerate
A generator (G) of random vectors 
\begin_inset Formula $x\in\mathbb{R}^{n}$
\end_inset

, drawn independently from a fixed but unknown probability distribution
 function 
\begin_inset Formula $F(x)$
\end_inset


\end_layout

\begin_layout Enumerate
A supervisor (S) who returns an output value 
\begin_inset Formula $y$
\end_inset

 to every input vector 
\begin_inset Formula $x$
\end_inset

, according to a conditional distribution function 
\begin_inset Formula $F(y|x)$
\end_inset

, also fixed but unknown
\end_layout

\begin_layout Enumerate
A learning machine (LM) capable of implementing a set of functions 
\begin_inset Formula $\varphi(x,\alpha),\ \alpha\in\Lambda$
\end_inset

, where 
\begin_inset Formula $\Lambda$
\end_inset

 is a set of parameters
\end_layout

\begin_layout Standard
Our goal is to choose the function which best approximates the supervisor's
 response, given a set of vector observations:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
X & =\vec{x}_{1},...,\vec{x}_{\ell}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$X$"
description "Set of observations to be evaluated"

\end_inset


\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$x_i$"
description "Individual observations"

\end_inset


\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$\\ell$"
description "The number of observations "

\end_inset


\end_layout

\begin_layout Standard
We choose between potential functions based on the empirical risk function
 using the loss (discrepancy) 
\begin_inset Formula $L(y,f(x,\alpha))$
\end_inset

 between the response 
\begin_inset Formula $y$
\end_inset

 for a given value of 
\begin_inset Formula $x$
\end_inset

 and the predicted value 
\begin_inset Formula $f(x,\alpha)$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
R_{\text{emp}}(\alpha) & =\frac{1}{\ell}\sum_{i=1}^{\ell}L(y_{i},f(\vec{x}_{i},\alpha))\\
 & =\frac{1}{\ell}\sum_{i=1}^{\ell}Q(z_{i},\alpha)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$R_\\text{emp}(\\alpha)$"
description "Empirical Risk "

\end_inset


\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$L(\\cdot)$"
description "Loss function"

\end_inset


\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$Q(\\cdot)$"
description "Loss Function"

\end_inset


\end_layout

\begin_layout Standard
We define our problem as one of estimating a Probability Density Functions
 (PDF), so we define the set of observations as a random variable of arbitrary
 dimensions:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
X & =(\Omega,\mathcal{F},\mathcal{P})\\
\Omega & \in\mathbb{R}^{d}\\
X & =[\vec{x}_{1},...,\vec{x}_{\ell}]\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$\\Omega$"
description "Abstract space of a random variable"

\end_inset


\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$\\mathcal{F}$"
description "Set of events for a random variable"

\end_inset


\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$\\mathcal{P}$"
description "Probability measure for a random variable"

\end_inset


\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$\\mathbb{R}^d$"
description "The set of real d-dimensional numbers"

\end_inset


\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$\\vec{x}$"
description "A vector observation of a random variable"

\end_inset


\end_layout

\begin_layout Standard
Our objective is to develop an estimate 
\begin_inset Formula $\varphi(x:\ X)$
\end_inset

 of the probability of the given point 
\begin_inset Formula $x$
\end_inset

 given a set of observations 
\begin_inset Formula $X$
\end_inset

 assuming some minimal uncertainty 
\begin_inset Formula $\xi$
\end_inset

 in the data:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi(\vec{x}:\ X) & \longmapsto\Pr(\vec{x}|X)\pm\xi\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$\\varphi(\\cdot)$"
description "A probability density function estimator"

\end_inset


\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$\\Pr(\\cdot)$"
description "Probability"

\end_inset


\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$\\xi$"
description "Slack variable"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Organize as follows: 1)Introduction and formal setting 2) Distance measure
 3) Parzen Estimator and SV Estimator 4) TI Entropy measure 5) Ensemble
 System 6) Motivated Decision Making
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Reorganize paper: 1) definition of similarity between subsets 2) probability
 estimation over subsets 3) algorithm for choosing subsets, A1) SVM, A2)
 ensemble system
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Part
Estimation
\end_layout

\begin_layout Chapter
Transformation Invariant Parzen Windows
\end_layout

\begin_layout Section
Parzen Windows for i.i.d.
 Data
\end_layout

\begin_layout Standard
Our task is to estimate the probability of a given vector 
\begin_inset Formula $\vec{x}$
\end_inset

 in the abstract space 
\begin_inset Formula $\Omega$
\end_inset

 based on a set of observations 
\begin_inset Formula $X$
\end_inset

.
 One method of accomplishing this is by using the Parzen Window (PW) method.
 We choose the Parzen Window method because it allows us to estimate probabiliti
es of unordered sets, provided they have an addition operation and a kernel
 function exists to provide a distance metric.
 The basic operation of the PW method is to estimate the probability of
 a point based on the sum of the distance from that point to each point
 in a set of prior observations.
 The Parzen Window approach to probability density function (PDF) estimation
 is as follows; given a set of prior observations 
\begin_inset Formula $X$
\end_inset

 and a kernel function 
\begin_inset Formula $K_{\gamma}(\cdot,\cdot)$
\end_inset

 with width parameter 
\begin_inset Formula $\gamma$
\end_inset

, the probability of a point 
\begin_inset Formula $\vec{x}$
\end_inset

 is determined by :
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi(\vec{x}:\ X) & =\sum_{i}^{\ell}\frac{1}{\ell}K_{\gamma}(\vec{x},\vec{x}_{i})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$K_\\gamma (x,y)$"
description "Kernel function"

\end_inset


\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$\\gamma$"
description "Kernel width parameter"

\end_inset


\end_layout

\begin_layout Standard
Multiple kernel functions exist, in this paper we will use the Radial Basis
 Function (RBF) kernel:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
K_{\gamma}\left(\vec{x},\vec{y}\right) & =\prod_{\upsilon=1}^{d}\frac{1}{\gamma\sqrt{2\pi}}e^{-\frac{1}{\gamma}\|x^{\nu},y^{\nu}\|^{2}}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$\\|\\cdot,\\cdot\\|$"
description "Distance metric"

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $\|\cdot,\cdot\|$
\end_inset

 is some metric, for instance the 
\begin_inset Formula $L^{2}$
\end_inset

 distance:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\|x,y\| & =\left(x-y\right)^{2}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
This approach is useful in the context of a set of observations drawn i.i.d.
 from a static PDF, however it is unable to address transformation invariance.
 Transformation invariance (TI) refers to data-sets in which one or multiple
 PDF's occur in various transformed states within the data-set, for example
 a given sound (described by a known PDF) could be repeated multiple times
 in an audio recording, or a given image could appear in multiple locations
 in a larger image.
 While the PW method can generate an estimate in the presence of data generated
 by transformed PDF's, its inability to recognize multiple instances of
 a single PDF limits its rate of convergence.
 
\end_layout

\begin_layout Section
Contextual Estimation
\end_layout

\begin_layout Standard
The crucial distinction between i.i.d data from a static PDF and data which
 exhibits TI is that when estimating the probability of a point, you must
 consider to context of the point as well as the location of the point in
 
\begin_inset Formula $\Omega$
\end_inset

.
 In this paper we will establish the context of 
\begin_inset Formula $x$
\end_inset

 by defining a "neighborhood" of points around 
\begin_inset Formula $x$
\end_inset

 which we will refer to as a window 
\begin_inset Formula $w$
\end_inset

 on 
\begin_inset Formula $X$
\end_inset

.
 Because a TI analysis may be applicable to some dimensions of 
\begin_inset Formula $\Omega$
\end_inset

 and not other, we will define the set of dimensions for which TI analysis
 is used as 
\begin_inset Formula $D$
\end_inset

, the the set of dimensions 
\emph on
not 
\emph default
used for TI analysis as 
\begin_inset Formula $\tilde{D}$
\end_inset

, and the set of all dimensions of 
\begin_inset Formula $\Omega$
\end_inset

 as 
\begin_inset Formula $D^{X}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
D^{X} & =[0,...,d]\\
D & \subseteq D^{X}\\
\tilde{D} & =[n\in D^{X}|\ n\notin D]\\
\vec{x}_{i} & \longmapsto w_{i}^{D}\\
w_{i}^{D} & =[x_{i}^{n}|\ n\in D]\\
w_{i}^{n} & =x_{i}^{n}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
While the window 
\begin_inset Formula $w$
\end_inset

 describes the 
\emph on
location 
\emph default
of a window, we still must define its extents.
 We will do so through the use of a windowing kernel function 
\begin_inset Formula $\omega(\cdot)$
\end_inset

 parametrized by some variable 
\begin_inset Formula $\alpha$
\end_inset

 which returns a value describing the degree of inclusion of an arbitrary
 point and 
\begin_inset Formula $x$
\end_inset

 in the window 
\begin_inset Formula $w$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\omega_{\alpha}(w,x) & \Rightarrow[0,\infty)\\
\int_{-\infty}^{\infty}\omega_{\alpha}(w,x)dx_{i} & =1\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can use any kernel function for 
\begin_inset Formula $\omega(\cdot)$
\end_inset

, however we assume that the windowing function has a peak at 
\begin_inset Formula $w_{i}=[x_{j}^{n}|\ n\in D]$
\end_inset

 and that it drops off as 
\begin_inset Formula $\left\Vert w_{i}-[x_{j}^{n}|\ n\in D]\right\Vert \rightarrow\pm\infty$
\end_inset

.
 Notice that we use a real-valued rather than Boolean inclusion metric -
 this allows us to "smear" the context of a given window into adjacent areas
 of 
\begin_inset Formula $X^{D}$
\end_inset

.
\end_layout

\begin_layout Section
Parzen Windows for Transformation-Invariant Data
\end_layout

\begin_layout Standard
Because we must establish a context for TI data, we must think of the set
 of observations 
\begin_inset Formula $X$
\end_inset

 as part of both the problem definition and the solution.
 This means that we can no longer simply calculate the kernel distance between
 
\begin_inset Formula $x$
\end_inset

 and each of the observations in 
\begin_inset Formula $X$
\end_inset

 independently - we must compare the 
\emph on
context
\emph default
 of 
\begin_inset Formula $x$
\end_inset

 with contexts of 
\begin_inset Formula $X$
\end_inset

.
 This requires a kernel function capable of comparing two 
\emph on
sets of points
\emph default
.
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
\begin_inset Formula \begin{align*}
\mathcal{K}_{\gamma}\left(X_{i},X_{j}\right) & =\frac{1}{\gamma\sqrt{2\pi}}e^{-\frac{1}{\gamma}\|X_{i},X_{j}\|}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can simplify this equation by observing that we are not actually dealing
 with two sets; we're dealing with two windows 
\begin_inset Formula $w_{n}$
\end_inset

 and 
\begin_inset Formula $w_{m}$
\end_inset

 within 
\begin_inset Formula $X$
\end_inset

:
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
\begin_inset Formula \begin{align*}
\mathcal{K}_{\gamma}\left(w_{n}^{X},w_{m}^{X}\right) & =\frac{1}{\gamma\sqrt{2\pi}}e^{-\frac{1}{\gamma}\|w_{n}^{X},w_{n}^{X}\|}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can extend this basic result to multiple dimensions by using the tensor
 product of the kernel values.
 In this context we must distinguish between TI dimensions and non-TI dimensions
, as the distance metric will be different for e
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
ach
\family default
\series default
\shape default
\size default
\emph default
\bar default
\noun default
\color inherit
:
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
\begin_inset Formula \begin{align*}
\mathcal{K}_{\gamma}\left(w_{n}^{X},w_{m}^{Y}:\ D\right) & =\prod_{\nu\in D}\frac{1}{\gamma\sqrt{2\pi}}e^{-\frac{1}{\gamma}\|w_{n}^{X},w_{n}^{Y}:\ \nu\|}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
There are multiple divergence measures available which can be used to define
 a "distance" between two sets.
 We will later show the importance of the distance metric 
\begin_inset Formula $\|\cdot,\cdot\|$
\end_inset

 being integrable; for this reason we will use the Pearson Divergence as
 our distance metric when comparing sets.
 In order to accommodate linear transformations, we add a 
\begin_inset Formula $d\times d$
\end_inset

 transformation matrix 
\begin_inset Formula $\mathbf{A}$
\end_inset

 and a 
\begin_inset Formula $d\times1$
\end_inset

 shift matrix 
\begin_inset Formula $\mathbf{b}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\|X^{\nu},Y^{\nu}\| & =\sum_{x^{\nu}\in\{X\cup Y\}}\left(\frac{\varphi(x^{\nu}:\ \mathbf{A}^{\nu}X^{\nu}+\mathbf{b}_{\nu})}{\varphi(x^{\nu}:\ Y^{\nu})}-1\right)^{2}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Because the Pearson Divergence is a summation, we can control the influence
 of each point by scaling it using the windowing function:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\|w_{n}^{X},w_{m}^{X}:\ \nu\| & =\sum_{i=1}^{\ell}\omega_{\alpha}(w_{n}^{\nu},x_{i}^{\nu})\left(\frac{\varphi(x_{i}^{\nu}:\ w_{m}^{D},\mathbf{A}X+\mathbf{b})}{\varphi(x_{i}^{\nu}:\ w_{m}^{D},X)}-1\right)^{2}\\
\varphi(x^{\nu}:\ w_{n}^{D},X) & =\sum_{i=1}^{\ell}\frac{\omega_{\alpha}(w_{n}^{\nu},x_{i}^{\nu})}{\sum_{j=1}^{\ell}\omega_{\alpha}(w_{n}^{\nu},x_{j}^{\nu})}K_{\gamma}(x^{\nu},x_{i}^{\nu})\\
 & =\sum_{i=1}^{\ell}\ddot{\omega}_{\alpha}(w_{n}^{\nu},x_{i}^{\nu},X)\ K_{\gamma}(x^{\nu},x_{i}^{\nu})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
These two matrix transformations are used to shift, scale, rotate, shear
 or mirror the window 
\begin_inset Formula $w_{n}^{D}$
\end_inset

 of 
\begin_inset Formula $X$
\end_inset

.
 The first transformation matrix 
\begin_inset Formula $\mathbf{A}$
\end_inset

 is an 
\begin_inset Formula $d\times d$
\end_inset

 matrix.
 The linear operator 
\begin_inset Formula $\mathbf{A}X$
\end_inset

 allows us to scale, rotate, shear, and mirror 
\begin_inset Formula $X$
\end_inset

 depending on the matrix values of 
\begin_inset Formula $\mathbf{A}$
\end_inset

.
 The second transformation matrix 
\begin_inset Formula $\mathbf{b}$
\end_inset

 is a 
\begin_inset Formula $d\times1$
\end_inset

 matrix; adding these terms together allows us to shift 
\begin_inset Formula $X$
\end_inset

 along any axis based on the values of 
\begin_inset Formula $\mathbf{b}$
\end_inset

.
 
\end_layout

\begin_layout Standard
One approach to these transformations is to explicitly determine values
 for the two matrices and to determine the distance 
\begin_inset Formula $\|\cdot,\cdot\|$
\end_inset

 using these values.
 A more robust approach is to integrate over all possible values of 
\begin_inset Formula $(\mathbf{A},\mathbf{b}):$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\|w_{n}^{X},w_{m}^{X}:\ \nu\| & =\sum_{i=1}^{\ell}\omega_{\alpha}(w_{n}^{\nu},x_{i}^{\nu})\int\int_{-\infty}^{\infty}\left(\frac{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},\mathbf{A}X+\mathbf{b})}{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},X^{\nu})}-1\right)^{2}d\mathbf{A}d\mathbf{b}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
This approach allows us to compare the distance between 
\emph on
any
\emph default
 linear transformation 
\begin_inset Formula $\mathbf{A}X+\mathbf{b}$
\end_inset

 and 
\begin_inset Formula $X$
\end_inset

, a far more powerful and less computationally demanding approach.
 Doing so requires that we calculate the following integral:
\end_layout

\begin_layout Standard
\begin_inset Formula \[
\int\int_{-\infty}^{\infty}\left(\frac{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},\mathbf{A}X+\mathbf{b})}{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},X^{\nu})}-1\right)^{2}d\mathbf{A}d\mathbf{b}\]

\end_inset


\end_layout

\begin_layout Standard
Because 
\begin_inset Formula $(\mathbf{A},\mathbf{b})$
\end_inset

 is a pair of matrix transformation, we must integrate the previous equation
 element-wise:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\end{align*}

\end_inset


\begin_inset Formula \begin{align*}
\int\int_{-\infty}^{\infty}\left(\frac{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},\mathbf{A}X+\mathbf{b})}{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},X^{\nu})}-1\right)^{2}d\mathbf{A}d\mathbf{b} & =\int...\int_{-\infty}^{\infty}\left(\frac{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},\mathbf{A}X+\mathbf{b})}{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},X^{\nu})}-1\right)^{2}d\mathbf{A}_{\nu,0},...,d\mathbf{A}_{\nu,d}d\mathbf{b}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Explain all this shit below
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
f([x^{0},...,x^{d}]:\ a,b,c,f,h) & =\left(a\ \exp\left(-b\left(\left(x^{d}\right)^{2}+x^{d}\sum_{i=1}^{d-1}x^{i}c^{i}+f\right)\right)-h\right)^{2}\\
\int...\int f([x^{0},...,x^{d}]:\ a,b,c,f,h)\ dx^{0},...,dx^{d} & =\int...\int f\left([x^{0},...,x^{d-1}]:\ \frac{\sqrt{\frac{\pi}{2}}a^{2}}{\sqrt{b}},-\frac{b}{2},-2bf,0\right)\ dx^{0},...,dx^{d-1}\\
 & \qquad\qquad+\int f\left([x^{0},...,x^{d-1}]:\ \frac{-2a\sqrt{\pi}}{\sqrt{b}},-\frac{b}{4},-4f,0\right)\ dx^{0},...,dx^{d-1}\\
\int f([x^{0}]:\ a,b,f,h)\ dx^{0} & =\frac{\sqrt{\frac{\pi}{2}}a^{2}}{\sqrt{b}}\exp\left(-\frac{1}{2}b^{2}f\right)-\frac{2a\sqrt{\pi}}{\sqrt{b}}\exp\left(-bf\right)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\int\int_{-\infty}^{\infty}\left(\frac{\varphi(x^{\nu}:\ w_{n}^{\nu},\mathbf{A}X+\mathbf{b})}{\varphi(x^{\nu}:\ w_{n}^{\nu},X)}-1\right)^{2}d\mathbf{A}d\mathbf{b} & =\int...\int\left(\frac{\varphi\left(x^{\nu}:\ w_{n}^{\nu},\left[\mathbf{b}_{\nu}+\sum_{n=1}^{|D|}\mathbf{A}_{\nu,n}x_{i}^{n}|\ x_{i}\in X\right]\right)}{\varphi(x^{\nu}:\ w_{n}^{\nu},X)}-1\right)^{2}d\mathbf{A}d\mathbf{b}\\
 & =\int...\int f([x^{0},...,x^{d}]:\ a,b,c,f,h)\ dx^{0},...,dx^{d}d\mathbf{b}_{\nu}\\
a & =\frac{\sum_{i=1}^{\ell}\ddot{\omega}_{\alpha}(w_{n}^{\nu},x_{i}^{\nu},X)}{\sum_{i=1}^{\ell}\ddot{\omega}_{\alpha}(w_{n}^{\nu},x_{i}^{\nu},X)\ \exp\left(-\frac{1}{\gamma}\left(x^{\nu}-x_{i}^{\nu}\right)^{2}\right)}\\
b & =\frac{1}{\gamma}\\
c & =???\\
f & =\left(x^{\nu}\right)^{2}-2x^{\nu}\mathbf{b}_{\nu}+\mathbf{b}_{\nu}^{2}\\
h & =1\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Make a note that for d not in D, A_dd=0, b=0
\end_layout

\end_inset


\end_layout

\begin_layout Section
Performance
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Big-O
\end_layout

\end_inset


\end_layout

\begin_layout Section
Multiple Data Sources
\end_layout

\begin_layout Standard
Consider the case where data from multiple data sources contributes to our
 set of observations 
\begin_inset Formula $X$
\end_inset

, for instance the data drawn from a microphone and a video camera.
 Let us assume that both input sources are timestamped, but the sampling
 frequency is different for each source and that the vector data points
 have different dimensionality.
 We will refer to observations of the former as 
\begin_inset Formula $X=(\Omega^{X},\mathcal{F}^{X},\mathcal{P}^{X})$
\end_inset

 and the latter as 
\begin_inset Formula $Y=(\Omega^{Y},\mathcal{P}^{Y},\mathcal{F}^{Y})$
\end_inset

.
 In this situation we can treat the time-stamp as a "shared" dimension,
 but all other dimensions of the two vectors are independent.
 It is clear that if we intend to establish a PDF of the joint probability
 space 
\begin_inset Formula $(\Omega^{Y,X},\mathcal{P}^{Y,X},\mathcal{F}^{Y,X})$
\end_inset

, we must treat each dimension in 
\begin_inset Formula $\Omega^{X}$
\end_inset

 and 
\begin_inset Formula $\Omega^{Y}$
\end_inset

 as orthonormal to each other.
 The fact that both event spaces share a time dimension means that a TI
 analysis over the two time dimensions is likely to produce useful results.
 
\end_layout

\begin_layout Standard
The most straightforward way to handle this situation is to assume that
 vector observations constitute sparse matrices; for any given dimension
 of an observation 
\begin_inset Formula $\vec{x}$
\end_inset

, the value can either be a real number or null:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
x^{\nu} & \in[\mathbb{R},\textrm{Ø}]\end{align*}

\end_inset

 In this case we only include operations between real-valued dimensions
 in our analysis.
 We can easily accommodate the shared time dimension by including the two
 time dimensions in our TI analysis.
 This allows us to consider not only the situation where both inputs are
 timestamped with accurate clocks, but the situation where the two clocks
 are independently inaccurate and some transformation is required for them
 to show the same time.
\end_layout

\begin_layout Section
Single Channel Summary
\end_layout

\begin_layout Standard
We have developed a PDF estimation technique which allows us to take advantage
 of TI data.
 The solution uses a novel distance metric to compare the similarity between
 two sets of points in the context of arbitrary linear transformations of
 one set.
 The solution proposed is restricted to observations with shared dimensionality,
 however it imposes no restrictions on which dimensions are TI.
 The types of transformations considered by the proposed solution are restricted
 to linear matrix transformations shifts.
 In the next section we will extend the solution to cases where multiple
 "channels" of data are present allowing us to handle TI between observations
 with non-shared dimensions.
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi(\vec{x}:\ X) & =\sum_{i=1}^{\ell}\frac{1}{\ell}\ \mathcal{K}_{\gamma}(w^{D},w_{i}^{D},\{\vec{x}\cup X\})\\
\mathcal{K}_{\gamma}\left(w_{n}^{X},w_{m}^{X}:\ D\right) & =\prod_{\nu\in\tilde{D}}\frac{1}{\gamma\sqrt{2\pi}}e^{-\frac{1}{\gamma}\left(x_{n}^{\nu}-x_{m}^{\nu}\right)^{2}}\prod_{\nu\in D}\frac{1}{\gamma\sqrt{2\pi}}e^{-\frac{1}{\gamma}\|w_{n}^{X},w_{n}^{X}:\ \nu\|}\\
\|w_{n}^{X},w_{m}^{X}:\ \nu\| & =???\\
\ddot{\omega}_{\alpha}(w_{n}^{\nu},x_{i}^{\nu},X) & =\frac{\omega_{\alpha}(w_{n}^{\nu},x_{i}^{\nu})}{\sum_{j=1}^{\ell}\omega_{\alpha}(w_{n}^{\nu},x_{j}^{\nu})}\end{align*}

\end_inset


\end_layout

\begin_layout Chapter
Support Vector Optimizations
\end_layout

\begin_layout Standard
The Parzen Window method is neither sparse nor computationally efficient,
 and as the number of observations grows, these deficiencies quickly become
 prohibitive.
 We now investigate the use of Support Vector Machines to generate estimates.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Refer to big-O
\end_layout

\end_inset


\end_layout

\begin_layout Section
Generalized Parzen-SVM 
\end_layout

\begin_layout Standard
Support Vector Machines (SVM) are often used
\begin_inset Note Note
status open

\begin_layout Plain Layout
ref?
\end_layout

\end_inset

 to estimate probability distributions by solving the related problem of
 estimating the cumulative distribution function of the random variable
 in question.
\begin_inset Note Note
status open

\begin_layout Plain Layout
This isn't really the essence of SVM - put more verbiage in the intro regarding
 what SVM's are, why they work, and why they're superior to other approaches
 (say, neural networks)
\end_layout

\end_inset

 This reduces the problem to one of estimating a non-linear mapping from
 observations to cumulative distribution values, which can be formulated
 as an optimization problem over a linear operator equation.
 Unfortunately, these methods depend on the ability to calculate an empirical
 distribution for each observation:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{equation}
F_{\ell}(x)=\frac{1}{\ell}\sum_{i}\theta(x-x_{i})\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\theta(x)$
\end_inset

 is the indicator function.
 To evaluate this function, the abstract space 
\begin_inset Formula $\Omega$
\end_inset

 must be ordered.
 While we have described a distance metric over 
\begin_inset Formula $\Omega$
\end_inset

, it is not clear what a meaningful ordering relation would be.
\end_layout

\begin_layout Standard
Rather than calculating the cumulative probability distribution of 
\begin_inset Formula $X$
\end_inset

, we begin with the assumption that the PW estimate of the probability distribut
ion is acceptably accurate and attempt to minimize the difference between
 the Support Vector (SV) estimate and the PW estimate.
 In this spirit, we will use a modification of the PW estimator which substitute
s a set of weights 
\begin_inset Formula $\beta$
\end_inset

 for the normalizing constant 
\begin_inset Formula $\frac{1}{\ell}$
\end_inset

 in the PW equation:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi(\vec{x}:\ \beta,X) & =\sum_{i=1}^{\ell}\beta_{i}\mathcal{K}_{\gamma}(w^{X},w_{i}^{X}:\ D)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The support vector approach requires that we define an optimization problem
 
\begin_inset Formula $W(\beta)$
\end_inset

 to determine the value of 
\begin_inset Formula $\beta$
\end_inset

.
 This optimization problem will determine which observations (or as we shall
 see, windows) will be used in estimations and which can be discarded as
 redundant or irrelevant information.
 The result of the optimization problem will be that a substantial number
 of multipliers 
\begin_inset Formula $\beta_{i}$
\end_inset

 will be 
\begin_inset Formula $0$
\end_inset

, allowing us to omit the windows defined by these points in the prediction
 phase.
 We define the optimization problem as minimizing the square loss between
 the SV and PW estimates over some set of observations 
\begin_inset Formula $X$
\end_inset

.
 The set of weights used in the Support Vector estimation must have a discrete
 number of elements; for simplicity we choose to assign a weight to each
 window defined by the time value of an observation in the training set
 and the constant parameter 
\begin_inset Formula $\alpha$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
W(\beta:\ X) & \longmapsto\min_{\beta}\sum_{i=1}^{\ell}\left(\varphi(\vec{x}_{i}:\ X)-\varphi(\vec{x}_{i}:\ \beta,X)\right)^{2}+\beta\Omega(\lambda,X)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Discuss regularizier
\end_layout

\end_inset


\end_layout

\begin_layout Standard
For the optimization problem, we check the difference between the two estimates
 at windows defined by the observations 
\begin_inset Formula $X$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Discuss the equations below
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Update all these kernel notations
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\sum_{i=1}^{\ell}\left(\varphi(\vec{x}_{i}:\ X)-\varphi(\vec{x}_{i}:\ \beta,X)\right)^{2} & =\sum_{i=1}^{\ell}\left(\varphi(\vec{x}_{i}:\ X)\right)^{2}-2\left(\varphi(\vec{x}_{i}:\ X)\varphi(\vec{x}_{i}:\ \beta,X)\right)+\left(\varphi(\vec{x}_{i}:\ \beta,X)\right)^{2}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
 & =\sum_{i=1}^{\ell}\left(\sum_{j=1}^{\ell}\frac{1}{\ell}K_{\gamma}(w_{i}^{D},w_{j}^{D},X)\right)^{2}-2\left(\sum_{j=1}^{\ell}\frac{1}{\ell}\mathcal{K}_{\gamma}(w_{i}^{D},w_{j}^{D},X)\right)\left(\sum_{j=1}^{\ell}\beta_{j}\mathcal{K}_{\gamma}(w_{i}^{D},w_{j}^{D},X)\right)\\
 & \qquad\qquad\qquad+\left(\sum_{j=1}^{\ell}\beta_{j}\mathcal{K}_{\gamma}(w_{i}^{D},w_{j}^{D},X)\right)^{2}\\
 & =\sum_{i=1}^{\ell}\sum_{\begin{array}{c}
j=1\\
k=1\end{array}}^{\ell}\frac{1}{\ell^{2}}\mathcal{K}_{\gamma}(w_{i}^{D},w_{j}^{D},X)\mathcal{K}_{\gamma}(w_{i}^{D},w_{k}^{D},X)-2\sum_{\begin{array}{c}
j=1\\
k=1\end{array}}^{\ell}\frac{1}{\ell}\mathcal{K}_{\gamma}(w_{i}^{D},w_{j}^{D},X)\beta_{j}\mathcal{K}_{\gamma}(w_{i}^{D},w_{k}^{D},X)\\
 & \qquad\qquad\qquad+\sum_{\begin{array}{c}
j=1\\
k=1\end{array}}^{\ell}\beta_{j}\mathcal{K}_{\gamma}(w_{i}^{D},w_{j}^{D},X)\mathcal{K}_{\gamma}(w_{i}^{D},w_{k}^{D},X)\\
 & =\sum_{\begin{array}{c}
i=1\\
j=1\\
k=1\end{array}}^{\ell}\beta_{j}\beta_{k}\mathcal{K}_{\gamma}(w_{i}^{D},w_{j}^{D},X)\mathcal{K}_{\gamma}(w_{i}^{D},w_{k}^{D},X)-\sum_{\begin{array}{c}
i=1\\
j=1\\
k=1\end{array}}^{\ell}\frac{2\beta_{j}}{\ell}\mathcal{K}_{\gamma}(w_{i}^{D},w_{j}^{D},X)\mathcal{K}_{\gamma}(w_{i}^{D},w_{jk}^{D},X)\\
 & \qquad\qquad\qquad+\sum_{\begin{array}{c}
i=1\\
j=1\\
k=1\end{array}}^{\ell}\frac{1}{\ell^{2}}\mathcal{K}_{\gamma}(w_{i}^{D},w_{j}^{D},X)\mathcal{K}_{\gamma}(w_{i}^{D},w_{k}^{D},X)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Because this is a minimization problem we can eliminate the last term (changing
 
\begin_inset Formula $\beta$
\end_inset

 won't affect its value).
 Substituting our optimization problem becomes:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
W(\beta:\ X) & \longmapsto\min_{\beta}\sum_{\begin{array}{c}
i=1\\
j=1\\
k=1\end{array}}^{\ell}\beta_{j}\beta_{k}\mathcal{K}_{\gamma}(w_{i}^{X},w_{j}^{X}:\ D)\mathcal{K}_{\gamma}(w_{i}^{X},w_{k}^{X}:\ D)\\
 & \qquad\qquad\qquad-\sum_{\begin{array}{c}
i=1\\
j=1\\
k=1\end{array}}^{\ell}\frac{2\beta_{j}}{\ell}\mathcal{K}_{\gamma}(w_{i}^{X},w_{j}^{X}:\ D)\mathcal{K}_{\gamma}(w_{i}^{X},w_{k}^{X}:\ D)+\lambda\Omega(\beta,X)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\text{subject to}\quad & \beta_{i}\ge0,\ \sum\beta=1\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Shouldn't the second term only have one kernel function? If not combine
 the first two terms
\end_layout

\end_inset


\end_layout

\begin_layout Chapter
Ensemble System
\end_layout

\begin_layout Standard
We now discuss creating a system composed of multiple estimators.
 It is well known that using a combination of estimates drawn from different
 models of an underlying phenomenon tends to increase the prediction accuracy
 of the hybrid system.
 We will begin by establishing an explanation for this phenomenon based
 on the concepts of VC Entropy and the uniform bounds on convergence of
 learning processes.
 We will then develop a method of quantifying the rate of convergence of
 an individual estimator, and show how this quantification can be used to
 build an optimal ensemble system of estimators.
 The basic question we will address is 
\emph on
how does one choose sets of dimension which will benefit from TI analysis,
 and how do we control the computational demands of an ensemble system?
\end_layout

\begin_layout Section
VC Entropy and Bounds on the Rate of Convergence
\end_layout

\begin_layout Standard
We begin by describing the VC entropy of a set of estimators using their
 risk values 
\begin_inset Formula $Q(x:\ \alpha)$
\end_inset

 defined by the set of parameters 
\begin_inset Formula $\alpha$
\end_inset

.
 Given a set of observations 
\begin_inset Formula $X=[x_{1},...,x_{\ell}]$
\end_inset

, we can construction a set of 
\begin_inset Formula $\ell$
\end_inset

-dimensional vectors
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
q(\alpha) & =[Q(x_{1},\alpha),...,Q(x_{\ell},\alpha)]\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Each vector describes the loss of a given element of 
\begin_inset Formula $\alpha$
\end_inset

 for the observations 
\begin_inset Formula $X$
\end_inset

.
 We define the minimum number of vectors required to "cover" 
\begin_inset Formula $q(\alpha)$
\end_inset

 with some arbitrarily small measure of closeness 
\begin_inset Formula $\varepsilon$
\end_inset

 as 
\begin_inset Formula $N^{\Lambda}(\varepsilon:x_{1},...,x_{\ell})$
\end_inset

.
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
For example, if 
\begin_inset Formula $q(\alpha)=[1,2,4,1]$
\end_inset

, 
\begin_inset Formula $N^{\Lambda}(X)=3$
\end_inset


\end_layout

\end_inset

 Using this value, we calculate the VC Entropy 
\begin_inset Formula $H^{\Lambda}(X)$
\end_inset

 of the set of functions 
\begin_inset Formula $Q(x,\alpha)$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
H^{\Lambda}(\varepsilon:\ell) & =\ln N^{\Lambda}(\varepsilon:x_{1},...,x_{\ell})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The VC Entropy essentially describes the number of observations in 
\begin_inset Formula $X$
\end_inset

 required to describe the PDF 
\begin_inset Formula $\mathcal{P}$
\end_inset

, based on the assumption that if multiple points in 
\begin_inset Formula $X$
\end_inset

 are 
\begin_inset Formula $\varepsilon$
\end_inset

-close to each other, we can eliminate all but one in our estimator.
 The VC Entropy is distribution-specific; it depends on the specific set
 of vectors 
\begin_inset Formula $q(\alpha)$
\end_inset

.
 In order to generate distribution-independent bounds, we establish the
 growth function 
\begin_inset Formula $G^{\Lambda}(\ell)$
\end_inset

 which describes the maximal value of 
\begin_inset Formula $H^{\Lambda}(\ell)$
\end_inset

 for any distribution given the set of estimators defined by 
\begin_inset Formula $Q(x:\ \alpha)$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
G^{\Lambda}(\ell) & =\ln\sup_{x_{1},...,x_{\ell}}N^{\Lambda}(x_{1},...,x_{\ell})\\
H^{\Lambda}(\ell) & \le G^{\Lambda}(\ell)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
It can be shown that the following equations hold true with probability
 
\begin_inset Formula $(1-\eta)$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\Psi & =4\frac{G^{\Lambda}\left(2\ell\right)-\ln\left(\eta/4\right)}{\ell}\\
R(\alpha) & \le R_{\text{emp}}(\alpha)+\frac{\Psi}{2}\left(1+\sqrt{1+\frac{4R_{\text{emp}}(\alpha)}{\Psi}}\right)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
This equation describes the upper bound on the risk of estimators from the
 set 
\begin_inset Formula $Q(x:\ \alpha)$
\end_inset

 for 
\begin_inset Formula $\ell$
\end_inset

 observations, when the empirical risk is equal to 
\begin_inset Formula $R_{\text{emp }}(\alpha)$
\end_inset

.
 It can be further shown that the growth function is bounded by
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
G^{\Lambda} & \le h\left(\ln\frac{\ell}{h}+1\right)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $h$
\end_inset

 describes the VC Dimension of the estimator, defined as the maximum number
 of vectors that can be linearly separated by the estimator (in the case
 of binary estimators) or as the VC Dimension of the set of indicators 
\begin_inset Formula $I(x,\alpha,\beta)$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
I(x,\alpha,\beta) & =\theta(Q(x:\ \alpha)-\beta),\ \alpha\in\Lambda,\ \beta\in(0,1)\\
\theta(x) & =\begin{cases}
0 & \quad\text{if}\ x<0,\\
1 & \quad\text{if}\ x\ge0\end{cases}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In other words the VC Dimension of a real-valued estimator is determined
 by the maximum number of vectors which can be enclosed by a region with
 radius 
\begin_inset Formula $1-\beta$
\end_inset

.
 In practical terms, this means that the VC Dimension is defined by the
 granularity of the estimator 
\begin_inset Formula $Q(x:\ \alpha)$
\end_inset

.
 Recall that PDF's are bounded by 
\begin_inset Formula $(0,1)$
\end_inset

; this means that each dimension of any loss vector 
\begin_inset Formula $q(\alpha_{n})$
\end_inset

 must be between 
\begin_inset Formula $(0,1)$
\end_inset

.
 Therefore the VC Dimension of an estimator is determined by the maximum
 number of regions with radius 
\begin_inset Formula $1-\beta$
\end_inset

 which can be defined on the interval 
\begin_inset Formula $(0,1)$
\end_inset

 in 
\begin_inset Formula $\ell$
\end_inset

 dimensions.
 In the case of SVM estimators, the value 
\begin_inset Formula $h$
\end_inset

 can be determined after optimizing for 
\begin_inset Formula $\beta$
\end_inset

 as the ratio of Support Vectors to 
\begin_inset Formula $\ell$
\end_inset

.
\end_layout

\begin_layout Section
Bounds of Convergence for TI Analysis
\end_layout

\begin_layout Standard
The growth function is used to characterize the worst-case performance for
 a specific type of estimator; we now show that the worst-case performance
 of an estimator capable of TI analysis is upper bounded by the growth function.
 Consider the PDF generated by a given estimator 
\begin_inset Formula $\varphi(x:\ \alpha_{n})$
\end_inset

 and two loss functions; the loss function 
\begin_inset Formula $Q(x:\ \alpha)$
\end_inset

 defined by the distance between 
\begin_inset Formula $\varphi(x:\ \alpha_{n})$
\end_inset

 and 
\begin_inset Formula $X$
\end_inset

, and the loss function 
\begin_inset Formula $Q_{TI}(x:\ \alpha)$
\end_inset

 defined by the TI distance between the same.
 It can easily be shown that 
\begin_inset Formula $Q(x:\ \alpha)$
\end_inset

 is a special case of 
\begin_inset Formula $Q_{TI}(x:\ \alpha)$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
Q(x:\ \alpha) & =Q_{TI}(x:\ \alpha),\quad\mathbf{A}=I,\ \mathbf{b}=0\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Recall that TI estimators are generated from the integral of the distance
 between two sets under transformations.
 We can therefore construct the following inequality:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\|X,Y\| & \ge\int\|X,\mathbf{A}Y+\mathbf{b}\|d\mathbf{A}d\mathbf{b}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
It is clear therefore that the TI loss will be less than or equal to the
 distance loss, and that the growth function for a given closeness parameter
 will be less for the TI estimator than the distance estimator.
 
\end_layout

\begin_layout Section
Bayesian Model Averaging Ensemble Machine
\end_layout

\begin_layout Standard
We now develop a method of combining multiple estimators into a single learning
 machine.
 Our discussion of TI analysis has assumed that the distance metric is integrate
d over some set of dimensions 
\begin_inset Formula $D$
\end_inset

.
 In the case of high-dimensional data-sets the computational demands of
 integrating over set set of all dimensions in 
\begin_inset Formula $X$
\end_inset

 may outweigh the utility of doing so.
 We instead consider using multiple partitions 
\begin_inset Formula $D^{n}$
\end_inset

 of 
\begin_inset Formula $D^{X}$
\end_inset

 to generate partial estimators.
 We can further extend the flexibility of the ensemble system by restricting
 each partial estimator to a subset of observations 
\begin_inset Formula $X^{n}\subseteq X$
\end_inset

.
 We therefore define a set of partial estimators:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi^{n}(x:\ X^{n},D^{n}) & \longmapsto\Pr(x|X^{n})\approx\Pr(x|X)\\
X^{n} & \subseteq X\\
D^{n} & \subseteq D^{X}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
With associated risk bounds
\begin_inset Foot
status open

\begin_layout Plain Layout
In the case of Parzen Estimators we can set the empirical risk to 0, in
 the case of SVM estimators we can set the empirical risk to the minimal
 value of the optimization problem.
\end_layout

\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\Psi^{n} & =4\frac{G^{\Lambda}\left(2|X^{n}|\right)-\ln\left(\eta/4\right)}{|X^{n}|}\\
R^{n}(\alpha) & \le R_{\text{emp}}^{n}(\alpha)+\frac{\Psi}{2}\left(1+\sqrt{1+\frac{4R_{\text{emp}}^{n}(\alpha)}{\Psi}}\right)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Consider the case of multiple partial estimators which makes estimates of
 
\begin_inset Formula $\Pr(x|X)$
\end_inset

 which we would like to combine.
 Consider the two resulting estimates of the probability of a given point
 
\begin_inset Formula $x$
\end_inset

.
 Using Bayesian Model Averaging (BMA) we can average the estimators weighted
 by their respective confidence interval
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Technically, they are being weighted by the probability that each estimator
 is accurate given 
\begin_inset Formula $X$
\end_inset

.
 Given a confidence interval, the relative probability that each estimate
 is accurate is determined by the confidence interval of the estimators.
 In this context, the concepts of risk and confidence interval are interchangeab
le.
\end_layout

\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
If that footnote is correct, it's odd that we need to normalize this.
 And if we don't need to normalize it, how do we account for a thousand
 estimators with decent confidence interval being combined?
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\Pr(x|X) & \approx\sum_{n}\Pr(x|\varphi^{n},X)\Pr(\varphi^{n}|X)\\
 & \approx\frac{1}{\sum_{n}1-R^{n}(\alpha)}\sum_{n}\varphi^{n}(x:\ X^{n},D^{n})(1-R^{n}(\alpha))\end{align*}

\end_inset


\end_layout

\begin_layout Section
Merging Estimators with Shared Dimensional Sets
\end_layout

\begin_layout Standard
This result allows us to create hybrid estimates based on a set of estimators
 regardless of the dimensional sets used by the estimators or the subsets
 of 
\begin_inset Formula $X$
\end_inset

 used by the estimators.
 We now consider a similar situation; combining the estimates of estimators
 based on the same dimensional set.
 In this context it is possible to to generate an estimator using the union
 of the observations from the two original estimators.
 This approach has a significant benefit over the BMA approach described
 above; it allows the hybrid estimator to generate estimates using the joint
 entropy of the observations, rather than the posterior probability of the
 marginal entropy of the two estimators.
 If we describe the entropy of two estimators as 
\begin_inset Formula $H(X^{1})$
\end_inset

 and 
\begin_inset Formula $H(X^{2})$
\end_inset

, the entropy of the union of these two subsets is lower bounded by the
 sum of the marginal entropies:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
H(X^{1}\cap X^{2}) & \ge H(X^{1})+H(X^{2})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Unfortunately we cannot simply combine the two subsets 
\begin_inset Formula $X^{1}$
\end_inset

 and 
\begin_inset Formula $X^{2}$
\end_inset

; doing so would violate the i.i.d.
 requirement of the PW estimator.
 To demonstrate this, consider a situation in which both subsets are drawn
 randomly from 
\begin_inset Formula $X$
\end_inset

 within some bounds 
\begin_inset Formula $(a^{1},b^{1})$
\end_inset

 and 
\begin_inset Formula $(a^{2},b^{2})$
\end_inset

 defined along some dimension of 
\begin_inset Formula $X$
\end_inset

 (ie we draw 
\begin_inset Formula $n$
\end_inset

 observations from 
\begin_inset Formula $X$
\end_inset

 from a specific time window).
 Within the context of each estimator the i.i.d.
 constraints are met within the defined bounds, however combining these
 two sets will only produce i.i.d.
 data if 
\begin_inset Formula $a^{1}=a^{2},\ b^{1}=b^{2}$
\end_inset

.
 
\end_layout

\begin_layout Standard
Consider the requirement of i.i.d.
 data in PW estimators; the probability of a given point is determined by
 the sum of the kernel distance to each observation used by the estimator.
 More observations in a given region increases the probability estimate
 for any point near that region.
 Let us assume that the bounds of one estimator are contained in and smaller
 than the bounds of a second:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
a^{1} & <a^{2}\\
b^{1} & >b^{2}\\
|X^{1}| & =|X^{2}|\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In this case, a PW estimator would incorrectly generate elevated probability
 estimates in the region 
\begin_inset Formula $(a^{2},b^{2})$
\end_inset

 and lowered estimates in the compliment.
 We have already seen how SVM estimators achieve performance optimization
 by adjusting the weight 
\begin_inset Formula $\beta$
\end_inset

 given to each observation; we now propose a similar weighting mechanism
 
\begin_inset Formula $\rho(n)$
\end_inset

 which adjusts the influence of each point in the union of the two sets
 
\begin_inset Formula $X^{1}$
\end_inset

 and 
\begin_inset Formula $X^{2}$
\end_inset

 so that the estimates of a PW estimator based on the union of two i.i.d.
 data sets remain accurate estimates of the underlying PDF.
 We now show that the weighting mechanism must be based on the risk of the
 two estimators; given two estimators 
\begin_inset Formula $\varphi^{n}(x:\ X^{n},D^{i})$
\end_inset

 and 
\begin_inset Formula $\varphi^{m}(x:\ X^{m},D^{i})$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi(x:\ X,D) & =\sum_{i=1}^{\ell}\frac{1}{\ell}K_{\gamma}(x,x_{i})\\
\varphi^{n,m}(x:\ X^{n}\cap X^{m}:D^{i}) & =\frac{\varphi^{n}(x:\ X^{n},D^{i})(1-R^{n}(\alpha))+\varphi^{n}(x:\ X^{n},D^{i})(1-R^{m}(\alpha))}{2-R^{n}(\alpha)-R^{m}(\alpha)}\\
 & =\frac{(1-R^{n}(\alpha))}{2-R^{n}(\alpha)-R^{m}(\alpha)}\sum_{x_{i}\in X^{n}}\frac{1}{|X^{n}|}K_{\gamma}(x,x_{i})+\frac{(1-R^{m}(\alpha))}{2-R^{n}(\alpha)-R^{m}(\alpha)}\sum_{x_{i}\in X^{m}}\frac{1}{|X^{m}|}K_{\gamma}(x,x_{i})\\
 & =\sum_{x_{i}\in X^{n}\cup X^{m}}\rho(x_{i}:\ \varphi^{n},\varphi^{m})\frac{1}{|X^{n}|+|X^{m}|}K_{\gamma}(x,x_{i})\\
\rho(x:\ \varphi^{n},\varphi^{m}) & =\begin{cases}
\frac{(1-R^{n}(\alpha))}{|X^{n}|\left(2-R^{n}(\alpha)-R^{m}(\alpha)\right)} & \quad x\in X^{n},x\notin X^{m}\\
\frac{(1-R^{m}(\alpha))}{|X^{m}|\left(2-R^{n}(\alpha)-R^{m}(\alpha)\right)} & \quad x\notin X^{n},x\in X^{m}\\
\frac{(1-R^{n}(\alpha))}{|X^{n}|\left(2-R^{n}(\alpha)-R^{m}(\alpha)\right)}+\frac{(1-R^{m}(\alpha))}{|X^{m}|\left(2-R^{n}(\alpha)-R^{m}(\alpha)\right)} & \quad x\in X^{n},x\in X^{m}\end{cases}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
This can be extended to SVM estimators:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi^{n,m}(x:\ \beta,X) & =\sum_{x_{i}\in X^{n}\cup X^{m}}\beta_{i}\rho(x:\ \varphi^{n},\varphi^{m})K_{\gamma}(x,x_{i})\\
W(\beta:\ X) & \longmapsto\min_{\beta}\sum_{\begin{array}{c}
x_{i}\in X^{n}\cup X^{m}\\
x_{j}\in X^{n}\cup X^{m}\\
x_{k}\in X^{n}\cup X^{m}\end{array}}\beta_{j}\beta_{k}\rho(x_{j}:\ \varphi^{n},\varphi^{m})\rho(x_{k}:\ \varphi^{n},\varphi^{m})K_{\gamma}(x_{i},x_{j})K_{\gamma}(x_{i},x_{k})\\
 & \qquad\qquad\qquad-\sum_{\begin{array}{c}
x_{i}\in X^{n}\cup X^{m}\\
x_{j}\in X^{n}\cup X^{m}\end{array}}\frac{2\beta_{j}}{\ell}\rho(x_{j}:\ \varphi^{n},\varphi^{m})K_{\gamma}(x_{i},x_{j})+\lambda\Omega(\beta,X^{n}\cup X^{m})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
I don't think the second term is correct - work this through the equations.
 Also make sure the second term only needs one kernel term (note in SV section)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Note that both sets being combined must be i.i.d.; this means that single observati
ons in isolation cannot be added.
 The minimum number of points in a set required for the set to constitute
 i.i.d.
 data is determined by the number of dimensions in the dimensional set.
 The risk value 
\begin_inset Formula $R(\alpha)$
\end_inset

 is also a worst-case scenario, rather than an exact measure; the more points
 in a given subset.
 This can be accommodated by combining sets with sufficient observations
 that the contribution of the empirical risk is greater than the contribution
 of the growth function.
 In general terms, the more observations in the combined sets, the more
 accurate the weighting term 
\begin_inset Formula $\rho(\cdot)$
\end_inset

 will be.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Show a second iteration of this process
\end_layout

\end_inset


\end_layout

\begin_layout Section
Computational Considerations in Subset Selection
\end_layout

\begin_layout Standard
In general, computational demands will vary with different classes of estimators.
 TI estimators have far higher computational cost than point-based estimators.
 We assume that there exist more classes of estimators than are necessary
 to produce a given risk for a given set of observation, which leaves us
 with the task of selecting which estimators to apply to an estimation problem
 and how to assign observations to the selected estimators.
 To make these decisions, we develop a selection heuristic based on the
 costs and benefits of using a given estimator.
\end_layout

\begin_layout Standard
The basic approach we will describe is an iterative one; we first select
 an i.i.d.
 subset 
\begin_inset Formula $X'$
\end_inset

 of 
\begin_inset Formula $X$
\end_inset

, then add the subset to one or more estimators from the set of possible
 estimators based on some heuristic.
 At each iteration we update our selection heuristic based on the results
 of the previous addition of 
\begin_inset Formula $X'$
\end_inset

.
 This approach allows us to control both the set of estimators used and
 the observations assigned to each estimator; more importantly it allows
 us to do so based on the nature of the observations 
\begin_inset Formula $X$
\end_inset

.
 We will show that it is possible to build a heuristic which requires no
 additional computation, allowing us to simultaneously build estimators
 and optimize subsequent iterations.
\end_layout

\begin_layout Standard
The simplest portion of the heuristic to define is the cost of using an
 estimator.
 The computational complexity of estimators can generally be determined
 
\emph on
a priori
\emph default
 as a function of the number and dimensionality of the estimator.
 In some cases optimizations exist which are data-dependent; in these cases
 we will assume a worst-case scenario for additional observations.
 We define the cost function for a given estimator as 
\begin_inset Formula $c(n,X)$
\end_inset

 where 
\begin_inset Formula $n$
\end_inset

 denotes the number of observations which will be added and 
\begin_inset Formula $X$
\end_inset

 denotes the observations used by the estimator.
\end_layout

\begin_layout Standard
The benefit portion of the heuristic can be easily constructed from previous
 work.
 For any estimator, the utility of the estimator is described by the risk
 associated with the estimator.
 In generating estimates our primary goal is to produce accurate estimates,
 and the risk function 
\begin_inset Formula $R(\alpha)$
\end_inset

 describes the lowest possible accuracy of a given estimator.
 It is clear therefore that the utility of adding observations to an estimator
 is determined by the change in the expected risk as a result of adding
 observations; estimators which we expect to gain a high reduction in risk
 should be preferred over estimators which we expect to gain a small reduction
 in risk.
 Recall that the maximal risk is determined by the number of observations
 used by the estimator, the empirical risk of the estimator, and the estimator's
 growth function; all three of these values are known for a given estimator
 without additional computation
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
The empirical risk for an SVM estimator is the minimal value of the optimization
 problem.
 The empirical risk of a Parzen Estimator can be assumed to be 0.
\end_layout

\end_inset

.
 We can therefore define the benefit function for a given estimator as 
\begin_inset Formula $b(n,X)$
\end_inset

 where 
\begin_inset Formula $n$
\end_inset

 denotes the number of observations which will be added and 
\begin_inset Formula $X$
\end_inset

 denotes the observations used by the estimator:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
b(n,X) & =R(\alpha)-R(\alpha_{n})\\
R(\alpha_{n}) & =R_{\text{emp}}(\alpha)+n+\frac{\Psi_{n}}{2}\left(1+\sqrt{1+\frac{4R_{\text{emp}}(\alpha)+4n}{\Psi_{n}}}\right)\\
\Psi_{n} & =4\frac{G^{\Lambda}\left(2\left(|X|+n\right)\right)-\ln\left(\eta/4\right)}{|X|+n}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can now define our heuristic 
\begin_inset Formula $h(n,X)$
\end_inset

 as the difference of the benefit and the cost, scaled by some parameter
 
\begin_inset Formula $\lambda$
\end_inset

 which controls the trade-off between accuracy and performance:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
h(n,X) & =b(n,X)-\lambda c(n,X)\end{align*}

\end_inset


\end_layout

\begin_layout Section
Hierarchical Ensemble Estimators
\end_layout

\begin_layout Standard
The ensemble system presented above is formulated in the context of traditional
 point-based probability estimators (as opposed to set-based TI estimators).
 The equations also hold in the context of combining estimates from point-based
 and set-based estimators, in fact we can construct a system using multiple
 layers of hierarchical information - each level taking into account a larger
 set of observations.
 
\end_layout

\begin_layout Standard
Hierarchical systems allow us to implement data compression.
 While it is possible to compare all possible weighted subsets of a set
 of observations, in practice the computational demands of doing so quickly
 become prohibitive.
 Hierarchical systems allow us to break such an analysis into a set of simpler
 analysis, each of which implements a compression algorithm to eliminate
 redundant information.
 As a result, each layer in the hierarchy is able to operate in subset of
 the abstract space defined by the results of the lower layer.
\end_layout

\begin_layout Standard
Conceptually, our hierarchical system is defined at the lowest level by
 the vector observations 
\begin_inset Formula $X$
\end_inset

.
 Estimators defined in this hierarchical layer operate based on point-to-point
 comparisons, as is the case in standard SVM algorithms.
 The second layer within the hierarchy is defined by TI estimators; these
 estimators operate based on comparisons between different windows defined
 on 
\begin_inset Formula $X$
\end_inset

 by some windowing function 
\begin_inset Formula $\omega(\cdot)$
\end_inset

.
 The nature of the windowing function itself isn't important; the significant
 attribute of estimators in this layer are that they compare windows defined
 by 
\emph on
single points 
\emph default
and some windowing parameter 
\begin_inset Formula $\alpha$
\end_inset

.
 We can think of these two layers (the point-based and window-based estimators)
 as a pair; each operates based on points defined in 
\begin_inset Formula $X$
\end_inset

 - the distinguishing characteristic between them is that the former compares
 single points while the latter compares sets of points.
 To add additional layers to the hierarchy we introduce a new concept; abstract
 vectors.
 Abstract vectors allow us to compare subsets of 
\begin_inset Formula $X$
\end_inset

 using windows defined by 
\emph on
multiple 
\emph default
points.
\end_layout

\begin_layout Standard
We define an abstract vector (AV) as a representation 
\begin_inset Formula $y_{n}$
\end_inset

 of 
\begin_inset Formula $X$
\end_inset

 in some vicinity 
\begin_inset Formula $x_{n}$
\end_inset

 based on an estimator 
\begin_inset Formula $\varphi$
\end_inset

, which we assume to be an SVM estimator.
 The dimensionality of an AV is defined by the number of SV's in its estimator
 
\begin_inset Formula $\varphi$
\end_inset

; each SV is mapped to a single dimension in 
\begin_inset Formula $y_{n}$
\end_inset

.
 The value of a dimension mapped to a given SV 
\begin_inset Formula $x_{i}$
\end_inset

 is defined by the kernel distance between 
\begin_inset Formula $X$
\end_inset

 in the vicinity of 
\begin_inset Formula $x_{i}$
\end_inset

 and the SV 
\begin_inset Formula $x_{n}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
y_{n} & =[y_{n}^{1},...,y_{n}^{|X_{SV}|}]\\
X_{SV} & =[x_{i}:\ \beta_{i}>\epsilon]\\
y_{n}^{i} & =K(x_{n},x_{i})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We treat SV's in different estimators as orthonormal; each SV in each estimator
 is mapped to a unique dimension of an AV.
 Because we can treat AV's as sparse data-sets
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
A given AV can be represented by a pair of tuples defined by a SV index
 and a kernel distance.
 Since SV's are optimized to minimize overlap, we can assume that in most
 cases the number of SV's which are 
\begin_inset Formula $\epsilon$
\end_inset

-close to a given region of 
\begin_inset Formula $X$
\end_inset

 will be small.
 It is conceivable that large numbers of high-dimensional observations in
 
\begin_inset Formula $X$
\end_inset

 could be compressed to a single SV:K tuple.
\end_layout

\end_inset

 the conversion of observations from 
\begin_inset Formula $\Omega^{X}\rightarrow\Omega^{Y}$
\end_inset

 vastly reduces the computation demands of subsequent hierarchical layers.
 This process can be seen as developing optimal code-books for a given data-set
 and compressing observations using this code-book.
 The beauty of this approach is that lower layers not only provide optimal
 code-books for higher layers, the process of discovering the optimal code-book
 simultaneously allows the lower layer to generate estimates.
 
\end_layout

\begin_layout Standard
We can now elaborate the nature of the third and fourth layers of our hierarchy;
 given a set of AV's constructed from estimators in layers one and two,
 we construct a new random variable 
\begin_inset Formula $Y$
\end_inset

 and treat it in the same manner as we did 
\begin_inset Formula $X$
\end_inset

.
 In this sense the hierarchical system is both hierarchical and iterative;
 each layer pair defines a new random variable which becomes the data on
 which subsequent layers are built.
 Between each pair of layers, the SV's act as a "bridge" allowing us to
 translate patterns between layer pairs:
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
The regularizing term in this equation eliminates the requirement that the
 sum of an estimated AV's dimension be 1.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\Pr(x|\ y) & \approx\frac{1}{\sum_{i}y^{i}}\sum_{x_{i}\in X_{SV}}y^{i}K(x,x_{i})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In this way, estimates generated in higher layers can be integrated into
 the BMA estimator by translating them into the abstract space of 
\begin_inset Formula $X$
\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Part
Choice
\end_layout

\begin_layout Chapter
Prediction and Conditional Prediction
\end_layout

\begin_layout Standard
Now that we have developed a robust architecture for estimating the probability
 of a point, we turn our attention to the inverse problem; predicting observatio
ns which conform the the PDF, possibly under some set of conditions.
 In this sense, we are shifting our focus from probability fields to points.
 In general, when we refer to "prediction", we will be referring to the
 generation of points, as opposed to "estimation", by which we mean the
 generation of probability fields.
\end_layout

\begin_layout Standard
We will frame the prediction task as one of first constructing a suitable
 PDF, and then extracting a set of predictions.
 We will begin with the case of the PDF generated by the estimation technique
 developed in the previous sections and discuss a general method for generating
 predictions.
 We will then investigate various types of conditional PDF's and extend
 our prediction technique to these conditional PDF's.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Reorganize this entire section to be based on various method of generating
 
\begin_inset Formula $\rho$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Generalized Prediction
\end_layout

\begin_layout Standard
We begin by considering the case where we wish to determine a set of random
 variates 
\begin_inset Formula $\bar{X}$
\end_inset

;
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
We focus on random variates to retain the probabilistic nature of the estimate.
 There are other potential approaches, for instance determining the point
 with the highest estimated PDF.
 Random variates further allow us to make predictions in the context of
 TI estimators - such estimators operate on sets of points.
\end_layout

\end_inset

 we refer to this set as a prediction of 
\begin_inset Formula $X$
\end_inset

.
 We consider the case where an estimate 
\begin_inset Formula $\varphi$
\end_inset

 of the probability 
\begin_inset Formula $\mathcal{P}$
\end_inset

 exists, generated from some set of observations 
\begin_inset Formula $X=[x_{1},...,x_{\ell}]$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi(x:\ X) & \longmapsto\Pr(x|X)=\mathcal{P}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We will generate random variates using the Inverse Transform Sampling (ITS)
 method.
 The ITS method allows the generation of a random variate by transforming
 an observation 
\begin_inset Formula $z$
\end_inset

 drawn from a uniform distribution 
\begin_inset Formula $Z\in(0,1)$
\end_inset

 into a set of predictions which conform to the PDF in question
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
In this paper, we will always use the random variable 
\begin_inset Formula $Z$
\end_inset

 to refer to a variable drawn from a uniform distribution over various ranges.
 For instance, if we define the range as 
\begin_inset Formula $Z\in[0,1]$
\end_inset

, then the random variable 
\begin_inset Formula $Z$
\end_inset

 will have a uniform distribution over the two points 0 and 1.
\end_layout

\end_inset

.
 The general approach is to determine the inverse of the PDF's cumulative
 distribution function (CDF).
 Since the CDF is bounded by 
\begin_inset Formula $(0,1)$
\end_inset

, uniform observations drawn from 
\begin_inset Formula $(0,1)$
\end_inset

 can be mapped to appropriate values in the CDF (and thus the PDF).
 We define a prediction function 
\begin_inset Formula $\phi(z:\ \varphi)$
\end_inset

 which implements the ITS method:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\phi(z:\ \varphi) & =\text{CDF}_{\varphi}^{-1}(z)\\
\text{CDF}_{\varphi}(z) & =\int_{-\infty}^{x}\varphi(z)dx\\
z & \in(0,1)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Unfortunately, there is no analytical solution to the inverse CDF of either
 a Parzen or SVM estimator.
 Recall that the PW estimator is defined as
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi(x:\ X) & =\sum_{i=1}^{\ell}\frac{1}{\ell}K_{\gamma}(x,x_{i})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can think of the PW estimator as the sum of the probabilities of each
 observation
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\Pr(x|X) & =\sum_{i=1}^{\ell}\frac{1}{\ell}\Pr(x|x_{i})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can generate random variates by summing random variates drawn from each
 kernel function:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\phi(z:\ \varphi) & =\sum_{i=1}^{\ell}\phi(z:\ x_{i})\\
\phi(z:\ x_{i}) & =\begin{cases}
\phi(z:\ K_{\gamma}(x,x_{i})) & z=i\\
\emptyset & \text{otherwise}\end{cases}\\
Z & \in[1,...,\ell]\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In the case of the RBF kernel, multiple methods exist to generate random
 variates 
\begin_inset Formula $\phi(z:\ K_{\gamma}(x,y))$
\end_inset

.
 In the context of SVM estimators, the prediction function can take advantage
 of the fact that some observations have been eliminated from the estimator.
 Recall that SVM coefficients 
\begin_inset Formula $\beta$
\end_inset

 reflect the entropy of a given observation; observations with large 
\begin_inset Formula $\beta$
\end_inset

 values have high similarity to other observations.
 Rather than selecting observations at random, we can select observations
 at random, weighted by their coefficients.
 This allows us to generate random deviates without using non-SV observations.
 We can treat the SVM estimator as a similar sum of probabilities
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\Pr(x|X) & =\sum_{i=1}^{\ell}\beta_{i}\Pr(x|x_{i})\\
\phi(z:\ \varphi) & =\sum_{i=1}^{\ell}\phi(z:\ \beta_{i},x_{i})\\
\phi(z:\ \beta_{i},x_{i}) & =\begin{cases}
\phi(z:\ K_{\gamma}(x,x_{i})) & \sum_{j=1}^{i}\beta_{j}\le z<\sum_{j=1}^{\ell}\beta_{j}-\sum_{j=i+1}^{\ell}\beta_{j}\\
\emptyset & \text{otherwise}\end{cases}\\
Z & \in\left(0,\sum_{i=1}^{\ell}\beta_{i}\right)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Generating random variates from TI estimators is less straightforward.
 In the case of a TI estimator, each window over the observations 
\begin_inset Formula $X$
\end_inset

 constitutes an observation analogous to 
\begin_inset Formula $x_{i}$
\end_inset

 in the PW and SVM estimators.
 Using the prediction method developed above, we can easily generate a random
 variate for a given window.
 The nature of TI analysis dictates that there are an infinite number of
 mappings from the random variate generated for a given window over 
\begin_inset Formula $X$
\end_inset

 and the abstract space 
\begin_inset Formula $\Omega$
\end_inset

.
 In order to generate a prediction, we must choose a specific affine transformat
ion defined by 
\begin_inset Formula $(\mathbf{A},\mathbf{b})$
\end_inset

.
\end_layout

\begin_layout Standard
To do so, consider the nature of the TI metric.
 The TI metric is defined as the integral over all possible values of 
\begin_inset Formula $(\mathbf{A},\mathbf{b})$
\end_inset

 of the Pearson divergence of the probability of a point in the context
 of a window and a transformed window
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\|w_{n}^{X},w_{m}^{X}:\ \nu\| & =\int\int\sum_{i=1}^{\ell}\omega_{\alpha}(w_{n}^{\nu},x_{i}^{\nu})\left(\frac{\varphi(x_{i}^{\nu}:\ w_{m}^{X},\mathbf{A}X+\mathbf{b})}{\varphi(x_{i}^{\nu}:\ w_{m}^{X},X)}-1\right)^{2}d\mathbf{A}d\mathbf{b}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Rather than evaluating this over the integral of all possible values of
 
\begin_inset Formula $(\mathbf{A},\mathbf{b})$
\end_inset

, we can formulate an equivalent process; select two sets of points in the
 windows 
\begin_inset Formula $w_{n}$
\end_inset

 and 
\begin_inset Formula $w_{m}$
\end_inset

 which define a unique transformation between the two windows
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
In order to define a unique transformation, it is sufficient to select 
\begin_inset Formula $|D|+1$
\end_inset

 points, where 
\begin_inset Formula $D$
\end_inset

 is the set of dimensions used in a given TI estimator.
 One point is used to align the two sets by shifting, and the other 
\begin_inset Formula $|D|$
\end_inset

 points are used to define the scale and rotation alignment.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\mathbf{A}X_{n}+\mathbf{b} & =X_{m}\\
f(X_{n},X_{m}) & \longmapsto\mathbf{b}=\left(X_{n}\right)_{1}-\left(X_{m}\right)_{1}\\
g(X_{n},X_{m}) & \longmapsto\mathbf{A}=\left(X_{n}\right)_{i\neq1}\left(X_{m}\right)_{i\neq1}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $(X_{n})_{1}$
\end_inset

 denotes the first element of 
\begin_inset Formula $X_{n}$
\end_inset

 and 
\begin_inset Formula $(X_{n})_{i\neq1}$
\end_inset

 denotes all the elements of 
\begin_inset Formula $X_{n}$
\end_inset

 except the first element.
 Observe that the following is equivalent to the TI metric
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\|w_{n}^{X},w_{m}^{X}:\ \nu\| & =\frac{1}{|X_{n},X_{m}\in X|}\sum_{X_{n},X_{m}\in X}\sum_{i=1}^{\ell}\omega_{\alpha}(w_{n}^{\nu},x_{i}^{\nu})\left(\frac{\varphi\left(x_{i}^{\nu}:\ w_{m}^{X},f(X_{n},X_{m})X+g(X_{n},X_{m})\right)}{\varphi(x_{i}^{\nu}:\ w_{m}^{X},X)}-1\right)^{2}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In essence, this function reduces the search space to the set of transformations
 defined by all subsets of 
\begin_inset Formula $X$
\end_inset

 which define a unique transformation.
 This is analogous to checking the SVM optimization problem only at the
 set of observations (rather than integrating over all possible values of
 
\begin_inset Formula $x$
\end_inset

).
\end_layout

\begin_layout Standard
Using the above definition of the TI metric, we can randomly select values
 of 
\begin_inset Formula $(\bar{\mathbf{A}},\bar{\mathbf{b}})$
\end_inset

 by randomly selecting sets 
\begin_inset Formula $\bar{X}_{n}$
\end_inset

 and 
\begin_inset Formula $\bar{X}_{m}$
\end_inset

 and evaluating 
\begin_inset Formula $f(\bar{X}_{n},\bar{X}_{m})$
\end_inset

 and 
\begin_inset Formula $g(\bar{X}_{n},\bar{X}_{m})$
\end_inset

.
 The problem of predicting values for TI estimators can therefore be reduced
 to the process of predicting a random variate in a given window and selecting
 the transformation sets 
\begin_inset Formula $\bar{X}_{n}$
\end_inset

 and 
\begin_inset Formula $\bar{X}_{m}$
\end_inset

.
 The window's random variate is transformed into a prediction by applying
 the transformation 
\begin_inset Formula $f(\bar{X}_{n},\bar{X}_{m})\bar{x}+g(\bar{X}_{n},\bar{X}_{m})$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\phi(\vec{z}_{1}\vec{z}_{2},z_{3},z_{4}:\ \varphi^{D}) & =f(\bar{X}_{n},\bar{X}_{m})\phi(z_{3}:\ w_{4})+g(\bar{X}_{n},\bar{X}_{m})\\
\phi(z:\ w) & =\begin{cases}
\phi(z:\ K_{\gamma}(x,x_{i})) & \sum_{j=1}^{i}\beta_{j}\le z<\sum_{j=1}^{\ell}\beta_{j}-\sum_{j=i+1}^{\ell}\beta_{j}\\
\emptyset & \text{otherwise}\end{cases}\\
\bar{X}_{n} & =[x_{z_{1}^{1}},...,x_{z_{1}^{|D|}}]\\
\bar{X}_{n} & =[x_{z_{2}^{1}},...,x_{z_{2}^{|D|}}]\\
Z_{1},Z_{2} & \in\mathbb{N}^{|D|},\ 1\le Z_{1}^{d}\le\ell\\
Z_{3},Z_{4} & \in[1,...,\ell]\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
You probably need to define 'in a window' better for selecting points.
 Points should probably be randomly selected based on their inclusion in
 a window.
\end_layout

\end_inset


\end_layout

\begin_layout Section
Ensemble Predictions
\end_layout

\begin_layout Section
Dimension-Conditional Prediction
\end_layout

\begin_layout Standard
We now consider conditional probability distributions.
 Conditional distributions describe the probability of points in 
\begin_inset Formula $\Omega$
\end_inset

 in a given context.
 We can view the estimation problem as the process of developing a conditional
 distribution where the context is the set of observations 
\begin_inset Formula $X$
\end_inset

.
 We now refine our treatment of the estimation problem to include both the
 set of observations 
\begin_inset Formula $X$
\end_inset

 and some context in which we are estimating.
 Our task is to restrict the estimation task to some subset 
\begin_inset Formula $\bar{\Omega}$
\end_inset

 of 
\begin_inset Formula $\Omega$
\end_inset

, where the difference between the two abstract spaces is a set of 
\emph on
given
\emph default
 values.
 This is to say we wish to estimate the probability of 
\begin_inset Formula $x\in\Omega$
\end_inset

, given some set of observations 
\begin_inset Formula $\bar{X}$
\end_inset

.
\end_layout

\begin_layout Standard
Conditional probability is defined as
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\Pr(A|B) & =\frac{\Pr(A\cap B)}{\Pr(B)}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Depending on how we define the events 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

, the conditional probability will allow us to predict values of 
\begin_inset Formula $X$
\end_inset

 in different contexts.
 We begin by considering the situation where the two events describe two
 disjoint dimensional sets 
\begin_inset Formula $\tilde{D}$
\end_inset

 and 
\begin_inset Formula $\bar{D}$
\end_inset

 .
 In this case the prediction task can be described as making predictions
 of 
\begin_inset Formula $\tilde{x}\in X^{\tilde{D}}$
\end_inset

 in the following conditional probability distribution:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\Pr(X^{\tilde{D}}=\tilde{x}\ |\ X^{\bar{D}}=\bar{x}) & =\frac{\Pr(X^{\tilde{D}}=\tilde{x}\ \cap\ X^{\bar{D}}=\bar{x})}{\Pr(X^{\bar{D}}=\bar{x})}\\
 & =\frac{\Pr(X^{\tilde{D}\cap\bar{D}}=\tilde{x}\cap\bar{x})}{\Pr(X^{\bar{D}}=\bar{x})}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Determining this distribution requires us to determine the probability of
 
\begin_inset Formula $\bar{x}$
\end_inset

 and 
\begin_inset Formula $\tilde{x}\cap\bar{x}$
\end_inset

, restricted to the dimensions for which these two points are defined.
 Recall that our estimation algorithm is defined as the product of the kernel
 distance between each vector dimension
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi(\vec{x}:\ \beta,X) & =\sum_{i=1}^{\ell}\beta_{i}K_{\gamma}(\vec{x},\vec{x}_{i})\\
K_{\gamma}\left(\vec{x},\vec{y}\right) & =\prod_{\upsilon=1}^{d}\frac{1}{\gamma\sqrt{2\pi}}e^{-\frac{1}{\gamma}\|x^{\nu},y^{\nu}\|^{2}}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can therefore determine 
\begin_inset Formula $\Pr(X^{\tilde{D}\cap\bar{D}})$
\end_inset

 and 
\begin_inset Formula $\Pr(X^{\bar{D}})$
\end_inset

 by restricting the estimator to the appropriate dimensions
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
For estimating 
\begin_inset Formula $\Pr(X^{\tilde{D}\cap\bar{D}})$
\end_inset

, we use a single point 
\begin_inset Formula $x$
\end_inset

, for which 
\begin_inset Formula $x^{d}=\tilde{x},\ d\in\tilde{D}$
\end_inset

 and 
\begin_inset Formula $x^{d}=\tilde{x},\ d\in\tilde{D}$
\end_inset

.
\end_layout

\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi(\vec{x}:\ \beta,X,D) & =\sum_{i=1}^{\ell}\beta_{i}K_{\gamma}(\vec{x},\vec{x}_{i}:\ D)\\
K_{\gamma}\left(\vec{x},\vec{y}:\ D\right) & =\prod_{\upsilon\in D}\frac{1}{\gamma\sqrt{2\pi}}e^{-\frac{1}{\gamma}\|x^{\nu},y^{\nu}\|^{2}}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We now consider generating random deviates from the conditional probability
 distribution.
 As before, our objective is to generate deviates from each observation
 and transform them into predictions using a transformation which conforms
 to our probability distribution.
 In this case, some dimensional values of are determined by 
\begin_inset Formula $\bar{x}$
\end_inset

; our task is to generate deviates for the dimensional values 
\begin_inset Formula $\tilde{D}$
\end_inset

.
 We can frame the problem as one of selecting an observation 
\begin_inset Formula $x_{i}$
\end_inset

, such that the probability of selecting any given 
\begin_inset Formula $x_{i}$
\end_inset

 equals the conditional probability of 
\begin_inset Formula $x_{i}$
\end_inset

 given 
\begin_inset Formula $\bar{D}$
\end_inset

.
 To do this we establish a parameter 
\begin_inset Formula $\rho_{i}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\rho_{i} & =\frac{\varphi(x_{i}:\ \beta,X,\tilde{D}\cap\bar{D})}{\varphi(x_{i}:\ \beta_{i},X,\bar{D})}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The parameter 
\begin_inset Formula $\rho$
\end_inset

 is a generalization of the process used previously with 
\begin_inset Formula $\frac{1}{\ell}$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

; we select observations such that the probability of selecting a given
 observation is equal to the probability of the observation occurring in
 the estimate.
 In the case of PW estimators, each observation is treated as equally probable.
 In the case of SVM estimators, the weight 
\begin_inset Formula $\beta$
\end_inset

 can be interpreted as the probability of the associated point, given the
 other observations.
 We therefore define the conditional prediction equation as
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\phi(z:\ \varphi,\hat{x},\tilde{D}) & =\sum_{i=1}^{\ell}\phi(z:\ \rho_{i},x_{i},\tilde{D})\\
\phi(z:\ \rho_{i},x_{i},\tilde{D}) & =\begin{cases}
[\phi(z:\ K_{\gamma}(x^{d},x_{i}^{d})):\ d\in\tilde{D}] & \quad\sum_{j=1}^{i}\rho_{j}\le z<\sum_{j=1}^{\ell}\rho_{j}-\sum_{j=i+1}^{\ell}\rho_{j}\\
\emptyset & \text{\quad otherwise}\end{cases}\\
Z & \in\left(0,\sum_{i=1}^{\ell}\rho_{i}\right)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Extending this to TI estimators is trivial; rather than selecting an observation
 for which to generate a random variate we select a window and proceed as
 before.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Is this true? The selection of transform parameters may need to take the
 CDF into consideration.
\end_layout

\end_inset


\end_layout

\begin_layout Section
Set-Conditional Prediction
\end_layout

\begin_layout Standard
Because TI estimators are contingent on the distance between sets of observation
s, we can consider conditional probability distributions where one of the
 events is a set of observations.
 In this case, rather than comparing two windows over the observations 
\begin_inset Formula $X$
\end_inset

, we consider windows over some set of observations 
\begin_inset Formula $\bar{X}$
\end_inset

 and the set of observations 
\begin_inset Formula $X$
\end_inset

.
 Here, we define two events 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

.
 The first event is the occurrence of 
\begin_inset Formula $x$
\end_inset

, and the second event is the occurrence of the set of observations 
\begin_inset Formula $\bar{X}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\Pr(A=x\ |\ B=\bar{X}) & =\frac{\Pr(A=x\ \cap\ B=\bar{X})}{\Pr(B=\bar{X})}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can reduce the numerator to the probability of the set 
\begin_inset Formula $\bar{X}\cup x$
\end_inset

, which leaves us with the problem of determining the probability of some
 arbitrary set given the observations 
\begin_inset Formula $X$
\end_inset

.
 Because we are dealing with TI estimators, we can treat both 
\begin_inset Formula $\bar{X}$
\end_inset

 and 
\begin_inset Formula $\bar{X\cup x}$
\end_inset

 as single points and evaluate the probability of those points.
 We can define 
\begin_inset Formula $\rho$
\end_inset

 as
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\rho_{i} & =\frac{\varphi(w_{i}:\ \beta,\bar{X}\cup x,X,D)}{\varphi(w_{i}:\ \beta,\bar{X},X,D)}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
In the TI SVM optimization, you used two windows; make sure that using a
 single window here doesn't cause problems
\end_layout

\end_inset


\end_layout

\begin_layout Section
Discrete Iterative Prediction
\end_layout

\begin_layout Standard
Consider the following scenario; two estimators based on subsets of 
\begin_inset Formula $X$
\end_inset

 have determined that there exists a high probability of the conditional
 probability 
\begin_inset Formula $B|A$
\end_inset

 and 
\begin_inset Formula $C|B$
\end_inset

.
 We would like to generate conditional predictions given the occurrence
 of 
\begin_inset Formula $A$
\end_inset

.
 It is likely that the first estimator will predict 
\begin_inset Formula $B$
\end_inset

, due to the high conditional probability of 
\begin_inset Formula $B|A$
\end_inset

, however the probability of predicting 
\begin_inset Formula $C$
\end_inset

 will be the marginal probability of 
\begin_inset Formula $C$
\end_inset

, which which in this instance we will assume to be low.
 In this case, the prediction task has failed to incorporate the information
 in the second prediction.
\end_layout

\begin_layout Standard
The obvious solution to this problem is to make two iterative predictions
 
\begin_inset Formula $\bar{X}_{1}$
\end_inset

 and 
\begin_inset Formula $\bar{X}_{2}$
\end_inset

.
 The first prediction is likely to include both 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

.
 We formulate the second prediction as a conditional prediction not on 
\begin_inset Formula $A$
\end_inset

, but on 
\begin_inset Formula $\bar{X}_{1}$
\end_inset

 (which we will assume contains 
\begin_inset Formula $B$
\end_inset

).
 The second prediction therefore is likely to include 
\begin_inset Formula $A$
\end_inset

, 
\begin_inset Formula $B$
\end_inset

, and 
\begin_inset Formula $C$
\end_inset

 - the desired result.
\end_layout

\begin_layout Standard
The utility of iterative prediction is not limited to the case of multiple
 partial estimators; the same problem is possible with TI estimators.
 Because TI estimators are context-sensitive, the prediction of a TI estimator
 window may constitute an appropriate context for different window.
 As with the first example, iterative prediction does not necessarily affect
 the conditional risk of a given prediction, however it is possible that
 a broader spectrum of predictions will be generated.
 We therefore develop an iterative prediction algorithm.
 At each iteration of the prediction algorithm, the results of the previous
 iteration are used as a conditional set
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\phi(z:\ \varphi,\bar{X}_{i-1}) & \longmapsto\bar{X}_{i}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In this case, the PDF of 
\begin_inset Formula $\varphi$
\end_inset

 is uniform across iterations - the only difference between iterations is
 the conditional set.
 The iterative predictor described constitutes a Markov Process with stationary
 distribution 
\begin_inset Formula $\varphi$
\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Get rid of this squelching shit - it duplicates the conditional prediction
 functionality (I think)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
It is possible that successive prediction iterations generate predictions
 whose PDF does not converge.
 In other cases the number of iterations required for convergence will be
 undesirably high.
 We now develop a method to control the rate of convergence.
 We can describe the divergence between iterations as the conditional risk
 of the predictions
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
|\bar{X}_{1},\bar{X}_{2}| & =R_{c}(\bar{X}_{1},\bar{X}_{2})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We assume that the conditional risk of both predictions relative to 
\begin_inset Formula $X$
\end_inset

 is the same:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
R_{c}(\bar{X}_{1},X) & \approx R_{c}(\bar{X}_{2},X)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Since both estimates are drawn with from the PDF of 
\begin_inset Formula $\varphi$
\end_inset

, we know that the conditional risk of each prediction is upper bounded
 by the risk of the estimator
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
R_{c}(\bar{X}_{1},X) & \le R(X)\\
R_{c}(\bar{X}_{2},X) & \le R(X)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can therefore state that the conditional risk of the two predictions
 is upper bounded by the risk of 
\begin_inset Formula $\varphi$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
|\bar{X}_{1},\bar{X}_{2}| & \le R(\varphi)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can now state that the divergence between predictions is determined by
 the risk of the estimators from which the predictions were generated.
 Controlling the convergence rate of iterative predictions requires controlling
 the risk of the underlying estimator.
 For a given random variable 
\begin_inset Formula $X$
\end_inset

, we cannot legitimately change the risk.
 The empirical risk is determined by 
\begin_inset Formula $X$
\end_inset

 and the maximal risk is determined by the estimator and number of observations.
 We can, however, 
\emph on
simulate
\emph default
 a lower risk value by increasing the "contrast" of the estimator 
\begin_inset Formula $\varphi$
\end_inset

.
 In general, risk refers to the extent to which 
\begin_inset Formula $X$
\end_inset

 is truly random.
 As the risk increases the spread of observations along 
\begin_inset Formula $\Omega$
\end_inset

 increases, and thus the PDF estimate of 
\begin_inset Formula $X$
\end_inset

 becomes more homogeneous.
 Simulating reduced risk can be accomplished by decreasing the homogeneity
 of 
\begin_inset Formula $\varphi$
\end_inset

; accentuating it's peaks and deepening its valleys.
 The simplest way of doing this is to raise each probability estimate to
 some power 
\begin_inset Formula $\eta>1$
\end_inset

.
 Points with lower probability will be decreased more than points with higher
 probability.
 The net result is to decrease the width parameter 
\begin_inset Formula $\gamma$
\end_inset

 of the estimator.
 We will refer to this process as squelching.
\end_layout

\begin_layout Standard
Generating estimates from squelched data is possible, however it require
 re-normalizing the resulting PDF.
 Fortunately in the context of prediction this is not necessary - we can
 simply squelch 
\begin_inset Formula $\rho$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula $ $
\end_inset


\begin_inset Formula \begin{align*}
\phi(z:\ \eta,\varphi,\hat{x},\tilde{D}) & =\sum_{i=1}^{\ell}\phi(z:\ \left(\rho_{i}\right)^{\eta},x_{i},\tilde{D})\\
\phi(z:\ \rho_{i},x_{i},\tilde{D}) & =\begin{cases}
[\phi(z:\ K_{\gamma}(x^{d},x_{i}^{d})):\ d\in\tilde{D}] & \quad\sum_{j=1}^{i}\rho_{j}\le z<\sum_{j=1}^{\ell}\rho_{j}-\sum_{j=i+1}^{\ell}\rho_{j}\\
\emptyset & \text{\quad otherwise}\end{cases}\\
Z & \in\left(0,\sum_{i=1}^{\ell}\left(\rho_{i}\right)^{\eta}\right)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
This is possible because 
\begin_inset Formula $\rho$
\end_inset

 is only used to distinguish the probability of selecting points for generating
 random variates; the actual value of 
\begin_inset Formula $\rho$
\end_inset

 is inconsequential.
\end_layout

\begin_layout Standard
Controlling the convergence rate of an iterative prediction involves making
 a trade-off between the robustness of the solution and the computational
 requirements of determining a convergent prediction - large values of 
\begin_inset Formula $\eta$
\end_inset

 are equivalent to single iterations.
 
\end_layout

\begin_layout Section
Continuous Iterative Prediction
\end_layout

\begin_layout Standard
We have described the generation of random variates as a process in which
 a set of random variates is generated at each iterative step.
 We can take a different approach to the prediction task and formulate equivalen
t results by assuming that the generation of random variates is a continuous
 process.
 The iterative approach implies a temporal processing structure; in order
 for formulate a continuous approach we must explicitly define the temporal
 aspect of the process.
 In the continuous approach, the time 
\begin_inset Formula $t_{i}$
\end_inset

 at which a random variate is generated is recorded, and each variate has
 a 
\begin_inset Quotes eld
\end_inset

lifetime
\begin_inset Quotes erd
\end_inset

 denoted as the duration 
\begin_inset Formula $\tau$
\end_inset

.
 The set of predictions at a given point in time 
\begin_inset Formula $t$
\end_inset

 is described by the set of variates generated before 
\begin_inset Formula $t$
\end_inset

 and which 
\begin_inset Quotes eld
\end_inset

expire
\begin_inset Quotes erd
\end_inset

 after 
\begin_inset Formula $t$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\phi(z:\ t) & \longmapsto\bar{x}^{t}\\
\bar{X}^{t} & =\left[\bar{x}^{t_{i}}:\ t\le t_{i}<t+\tau\right]\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We ensure the distribution of 
\begin_inset Formula $\bar{X}$
\end_inset

 conforms to the distribution of 
\begin_inset Formula $\varphi$
\end_inset

 by controlling the rate at which random variates are generated.
 We refer to the generation of random variates as the 
\begin_inset Quotes eld
\end_inset

emission
\begin_inset Quotes erd
\end_inset

 of random variates.
 For a given emitter, the intervals between emissions are selected randomly
 from the interval 
\begin_inset Formula $(0,\frac{\kappa}{\rho})$
\end_inset

, where 
\begin_inset Formula $\kappa$
\end_inset

 is some scaling constant which controls the system's emission rate.
\end_layout

\begin_layout Standard
If we do not update 
\begin_inset Formula $\rho$
\end_inset

 values, the result of the continuous prediction approach at any point in
 time will coincide with the iterative approach.
 The utility of the continous approach is that it can be implemented in
 a distributed manner without the requirement of synchronization between
 iterations.
 
\end_layout

\begin_layout Standard
There are multiple methods for handling changes in an emitter's 
\begin_inset Formula $\rho$
\end_inset

.
 One is to eliminate any current variates from the estimator and generate
 new ones with the new emission rate.
 Another approach is to simply adjust the emission rate going forward.
 The former option requires the ability to remove variates from the prediction
 set, while the influence of the transition in the latter is not immediately
 available to the system.
 
\end_layout

\begin_layout Section
Performance Considerations
\end_layout

\begin_layout Standard
Evaluating values of 
\begin_inset Formula $\rho$
\end_inset

 can be computationally expensive.
 In an ideal continuous predictive system, each time a new variate was generated
 the 
\begin_inset Formula $\rho$
\end_inset

 values of each emitter would be immediately updated.
 In practice this requires evaluating kernel distances between each new
 variate and each SV, then computing the conditional probabilities.
 Marginal changes in an emitter's 
\begin_inset Formula $\rho$
\end_inset

 value will produce marginal shifts in the distribution of 
\begin_inset Formula $\bar{X}$
\end_inset

, but since 
\begin_inset Formula $\bar{X}$
\end_inset

 is a probabalistic prediction it is possible 
\begin_inset Quotes eld
\end_inset

noise
\begin_inset Quotes erd
\end_inset

 resulting from the risk of 
\begin_inset Formula $\varphi$
\end_inset

 will be more significant than marginal changes in the emission rate.
 A simple method of reducing the computation demands of iterative prediction
 is prioritize emitters in the neighborhood of emitters whose emission rate
 has been changed significantly.
 Fortunately, the kernel matrix for each SV must be computed during the
 optimization process, so using these kernel distances to evaluate the priority
 of evaluating a given SV's 
\begin_inset Formula $\rho$
\end_inset

 value does not require additional computation if the kernel matrix is cached.
 We can formalize this concept by assuming that an iterative process selects
 SV's for 
\begin_inset Formula $\rho$
\end_inset

 evaluation by choosing the SV whose priority value 
\begin_inset Formula $\psi(\cdot)$
\end_inset

 is the greatest:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\psi(x:\ X,\triangle\rho) & =\sum_{x_{i}\in X}\triangle\rho_{i}K_{\gamma}(x,x_{i})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $\triangle\rho$
\end_inset

 is the most recent change in 
\begin_inset Formula $\rho_{i}$
\end_inset

 for each observation 
\begin_inset Formula $x_{i}$
\end_inset

.
 In general terms, this approach allows us to evaluate the neighborhood
 of SV's where a significant change in 
\begin_inset Formula $\rho$
\end_inset

 has been observed before moving on to randomly selecting SV's.
\end_layout

\begin_layout Section
Hierarchical Considerations
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
I had originally planned to say that we only pass values up when they change,
 but the more I think about that the less I like it.
 Doing so requries that we have absolute certainty that the value has been
 unchanged between outputs, which in our case isn't necessarily so - especially
 if we're optimizing which SV's get updated.
 At the same time, outputting after updates isn't a great idea either -
 not i.i.d.
 if the SV selection is optimized.
 We get the same problem from outputting at emission - we want the upper
 layers to have an accurate 'view' of the processes below, outputting at
 emission would increase the number of points with large rho (which isn't
 needed as rho describes the emission rate).
 So I think the best way to handle this is to either take the state of the
 entire system at some sampling rate, or possibly allow each SV to randomly
 output at a uniform rate.
 
\end_layout

\end_inset


\end_layout

\begin_layout Chapter
Motivated Decision-Making
\end_layout

\begin_layout Standard
Up to this point, our discussion has focused on data analysis.
 We now turn our attention to volitive systems; systems which have the ability
 influence the the probability distribution 
\begin_inset Formula $\mathcal{P}$
\end_inset

 of the observation space 
\begin_inset Formula $\Omega$
\end_inset

, and in which certain types of local probability distributions are preferred
 over others.
 
\end_layout

\begin_layout Section
Actions and Incentives
\end_layout

\begin_layout Standard
We assume that such a system influences 
\begin_inset Formula $\mathcal{P}$
\end_inset

 through actions which are discrete and quantifiable.
 Each action is therefore described as a vector 
\begin_inset Formula $\vec{a}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\vec{a}_{i} & =\left[a_{i}^{1},...,a_{i}^{\pi}\right]\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In order to correlate actions with changes in 
\begin_inset Formula $\mathcal{P}$
\end_inset

, we treat each action as an observation of 
\begin_inset Formula $X$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
X & =(\Omega,\mathcal{F},\mathcal{P})\\
\Omega & \in\mathbb{R}^{d+\pi}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In this case, our observations are of dimension 
\begin_inset Formula $d+\pi$
\end_inset

, the first 
\begin_inset Formula $d$
\end_inset

 dimensions describe the system's 'environment' and the last 
\begin_inset Formula $\pi$
\end_inset

 describe the system's "actions".
 
\end_layout

\begin_layout Standard
In order to choose between possible actions, the system must prefer certain
 states of the input space 
\begin_inset Formula $\Omega$
\end_inset

 over others.
 We describe these preferred states as the system's using a function 
\begin_inset Formula $m_{\theta}(x)$
\end_inset

 we'll refer to as the motivator with control parameter 
\begin_inset Formula $\theta$
\end_inset

.
 For a given dimension of 
\begin_inset Formula $\Omega$
\end_inset

, the motivator function returns a positive real value describing the system's
 preference for the state 
\begin_inset Formula $x^{i}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
m_{\theta}(x^{i}) & \in\mathbb{R}^{+}\\
m_{\theta}(x^{i})>1 & \longmapsto\text{preferred state}\\
m_{\theta}(x^{i})<1 & \longmapsto\text{discouraged state}\\
m_{\theta}(x^{i})=1 & \longmapsto\text{no preference}\end{align*}

\end_inset


\end_layout

\begin_layout Section
Motivated Prediction
\end_layout

\begin_layout Standard
Before discussing motivated prediction, let us lay out a few assumptions
 we will make regarding the architecture used for estimation and prediction.
 The first assumption is that at least one dimension of the abstract space
 describes time.
 Second, we assume that the estimator 
\begin_inset Formula $\varphi$
\end_inset

 includes at least one TI estimator.
 Finally, we assume that the prediction function uses the Random Variate
 Set method.
 
\end_layout

\begin_layout Standard
It is difficult to talk about motivated decision making without assuming
 that the motivated system has access to time data.
 In general terms, motivation is the process of correlating actions with
 consequences and choosing actions which will produce desirable consequences.
 The concept of motivation itself assumes that there will be some change
 in the system's 
\begin_inset Quotes eld
\end_inset

environment
\begin_inset Quotes erd
\end_inset

 as a result of taking specific actions, an assumption inherently based
 on a temporal view of the probability space.
 While explicit discussion of time will be minimized for the sake of general
 solutions, it is worth noting that estimation and prediction contexts will
 often refer to varying behaviors of 
\begin_inset Formula $X$
\end_inset

 at different points in time.
\end_layout

\begin_layout Standard
We split the motivated decision making process into two general categories;
 motivated prediction and choice.
 This division is not necessary, however it provides a clean separation
 between functions; the prediction task is to explore potential system states
 and the choice task is to select actions from the available predictions.
 The prediction task as described in the previous section involved exploring
 possible sets of observations in order to learn something about the PDF
 of 
\begin_inset Formula $\varphi$
\end_inset

 and its nature in different contexts.
 Motivated prediction constitutes the same general process, however our
 objective now is to learn the consequences of potential actions.
 We can now quantify a given prediction's utility based on the amount of
 information it contains regarding the correspondance between actions and
 consequences, and our task is to modify the prediction process to be biased
 towards exploring the nature of 
\begin_inset Formula $\varphi$
\end_inset

 in these contexts.
\end_layout

\begin_layout Standard
We begin by quantifying the utility of a given prediction 
\begin_inset Formula $\bar{x}$
\end_inset

.
 We wish to quantify the extent to which an estimate consitutes either a
 preferred or discouraged point in 
\begin_inset Formula $\Omega$
\end_inset

.
 Because we wish our system to both strive for preferred states and avoid
 discouraged states, points which correspond to either are have utility
 in the prediction task.
 We therefore describe the utility 
\begin_inset Formula $u(x)$
\end_inset

 of a point as the average of the absolute value of the motivational state
 of each dimension in the point
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
u_{\theta}(x) & =\frac{1}{|\tilde{D}|}\sum_{d\in\tilde{D}}|m_{\theta}(x^{d})|\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can extend this to TI estimators by weighting each point by its membership
 in the window
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
u_{\theta}(w) & =\frac{1}{\sum_{x_{i}\in X}\omega(w,x_{i})}\sum_{x_{i}\in X}\omega(w,x_{i})u_{\theta}(x_{i})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Evaluating the utility of a prediction is less straightforward.
 Because predictions describe potential states (rather than observed states),
 we can no know based solely on the prediction its utility.
 We must evaluate the utility of a prediction in the context not only of
 previous observations, but of the other sets in 
\begin_inset Formula $\bar{X}$
\end_inset


\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Recall the conditional prediction scenario where the conditional probabilities
 
\begin_inset Formula $A|B$
\end_inset

 and 
\begin_inset Formula $B|C$
\end_inset

 are known to be high, but an iterative predictor will fail to predict 
\begin_inset Formula $C$
\end_inset

.
 This situation applies to utility as well; if the utility of 
\begin_inset Formula $C$
\end_inset

 is high, we would like the utility of 
\begin_inset Formula $A$
\end_inset

 to also be high, since we know that the conditional probability 
\begin_inset Formula $A|C$
\end_inset

 is high.
\end_layout

\end_inset

.
 We therefore adopt an iterative approach to determining the utility of
 a prediction.
 We begin by evaluating the utility of a prediction using the utility of
 each observation and the conditional probability of the prediction given
 the observation
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
u_{\theta}^{1}(\bar{x}) & =\sum_{x_{i}\in X}u_{\theta}(x_{i})\varphi(x:\ x_{i})+\sum_{w_{i}\in X}u_{\theta}(w_{i})\varphi(w:\ w_{i})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $w$
\end_inset

 refers to the window defined by 
\begin_inset Formula $x$
\end_inset

.
 Our general approach is to ensure that for a point 
\begin_inset Formula $\bar{x}_{i}$
\end_inset

 with high utility, any other points which 
\begin_inset Formula $\bar{x}_{i}$
\end_inset

 is conditional upon also are assigned high utility; if it's useful to keep
 
\begin_inset Formula $\bar{x}_{i}$
\end_inset

, it is also useful to keep any points which increase the probability of
 predicting 
\begin_inset Formula $\bar{x}_{i}$
\end_inset

.
 We then use the conditional probabilities of the other estimates given
 
\begin_inset Formula $\bar{x}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
u_{\theta}^{i}(\bar{x}) & =\sum_{\bar{x}_{i}\in\bar{X}}u_{\theta}^{i-1}(\bar{x}_{i})\frac{\varphi(\bar{x}_{i}:\ \bar{X})}{\varphi(\bar{x}_{i}:\ \bar{X}\vee\bar{x})}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
As this iterative step updates the utility of each observation, it can be
 evaluated for as many iterations are necessary to provide a suitable level
 of accuracy.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Re-frame for emission
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Returning to the concept of motivated prediction, it is clear that in the
 context of an iterative predictor we would like to emphasize prediction
 in a given iteration based on predictions with high utility in previous
 iterations.
 While predictions are drawn from PDF's, they are not assumed to describe
 a probability density themselves, therefore there is no requirement that
 they be i.i.d.
 points.
 Selecting some predictions to pass through to subsequent iterations and
 not others does not undermine the validity of subsequent predictions; the
 validity of a given iteration is derived from the estimator generating
 it (which is unaffected by the specific set of predictions passed to a
 given iteration).
 We can view the selection process as a type of conditional prediction;
 we are creating predictions in the context of points the system considers
 useful.
 The reason we choose to implement the selection process after predictions
 have been made is that prior to generating a prediction it is uncertain
 exacly what the conditional utility between predictions will be.
 
\end_layout

\begin_layout Standard
We have refined our understanding of the motivated prediction process; the
 prediction task constitutes selecting points of interest from a set of
 predictions and passing them to future iterations of the prediction process.
 
\end_layout

\begin_layout Section
Choice
\end_layout

\begin_layout Standard
We have now developed a robust architecture for estimating correlation between
 observations, generating predictions from that estimate, and evaluating
 the consequences of actions contained in the predictions.
 The final step is to chose specific actions to take.
 This choice reduces to a simple matter of selecting the action with the
 greatest expected correlation with preferred states of 
\begin_inset Formula $\Omega$
\end_inset

, determined by the motivation function 
\begin_inset Formula $m_{\theta}(\cdot)$
\end_inset

 at a given time 
\begin_inset Formula $t$
\end_inset


\begin_inset Foot
status collapsed

\begin_layout Plain Layout
We assume that the time 
\begin_inset Formula $t$
\end_inset

 describes the time at which the selection takes place.
 The ability to increase the probability of selecting an action in the future
 is provided by through iterative prediction.
\end_layout

\end_inset

.
 
\end_layout

\begin_layout Standard
It cannot be assumed that a prediction at time 
\begin_inset Formula $t$
\end_inset

 exists, so we use the windowing function to select between actions in the
 vicinity of 
\begin_inset Formula $t$
\end_inset

.
 We select from the prediction actions 
\begin_inset Formula $\bar{A}$
\end_inset

 the action 
\begin_inset Formula $\ddot{a}$
\end_inset

 with the greatest expected correlation with preferred states, scaled by
 each action's inclusion in the window
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\ddot{a}^{t} & =\max_{\bar{a}_{i}\in\bar{A}}\omega_{\gamma}(t,a)\ u_{\theta}(a_{i})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
If this was a regression function the output would be a lot smoother.
 Just make sure you don't end up between peaks.
\end_layout

\end_inset


\end_layout

\begin_layout Section
Curiosity
\end_layout

\begin_layout Standard
Without the ability to take action, a system's accuracy and efficiency for
 a given data-set is limited by the algorithm it uses and the computational
 resources available to it.
 Systems with the ability to influence the observations from which they
 make estimates, on the other hand, can take advantage of this ability to
 increase both their accuracy and performance.
 Before we can discuss the mechanisms by which this is possible, we must
 first develop a more rigorous understanding of these two objectives; accuracy
 and efficiency.
\end_layout

\begin_layout Standard
Our system's accuracy can be described as the empirical loss resulting from
 the SVM optimization process.
 This is an attractive metric as it can be easily computed after optimization
 by subtracting the regularizer term.
 In this case we assume the PW estimate represents the minimal possible
 risk of the system and measure the efficiency of the SVM estimator based
 on its divergence from the PW estimator.
 We can therefore quantify the system's accuracy after 
\begin_inset Formula $\ell$
\end_inset

 observations as the empirical risk 
\begin_inset Formula $R_{\text{emp}}(\ell)$
\end_inset

.
\end_layout

\begin_layout Standard
The efficiency of the system is determined by the amount of computation
 required to generate estimates, which depends on the number of support
 vectors.
 We can therefore describe the system's efficiency as the inverse of the
 number of support vectors 
\begin_inset Formula $|SV|^{-2}$
\end_inset

.
 As the number of SV's grows the computational requirements of estimating
 point's probabilities grows with the size of the kernel matrix ( which
 contains 
\begin_inset Formula $|SV|^{2}$
\end_inset

 elements).
\end_layout

\begin_layout Standard
We can now establish the following metric for the system's performance after
 
\begin_inset Formula $\ell$
\end_inset

 observations
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
p(\ell:\ \varphi) & =\frac{R_{\text{emp}}(\ell)}{|SV_{\ell}|^{2}}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $SV_{\ell}$
\end_inset

 is the set of support vectors after 
\begin_inset Formula $\ell$
\end_inset

 observations.
 The system can be motivated to increase its performance by including 
\begin_inset Formula $p$
\end_inset

 as a system input and motivating positive values
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Make sure p is stationary here - if it's not motivating any specific value
 won't be useful
\end_layout

\end_inset

.
\end_layout

\begin_layout Chapter
Conclusion
\end_layout

\begin_layout Standard
Eat it, bitches
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
nocite{Moreno03}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
bibliographystyle{plain}
\end_layout

\end_inset


\end_layout

\begin_layout Chapter
\start_of_appendix
Results
\end_layout

\begin_layout Section
Eunite Competition Data
\end_layout

\begin_layout Section
Santa Fe Data
\end_layout

\begin_layout Section
CATS Benchmark Data
\end_layout

\begin_layout Section
Results Summary
\end_layout

\begin_layout Chapter
Discussion of Existing Work
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

%http://en.wikipedia.org/wiki/Expectation-maximization_algorithm
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

%http://en.wikipedia.org/wiki/Stationary_process
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

%http://en.wikipedia.org/wiki/Ergodicity
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

%http://en.wikipedia.org/wiki/Mixing_(mathematics)
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

%http://en.wikipedia.org/wiki/Lyapunov_exponent
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

%http://en.wikipedia.org/wiki/Recurrence_quantification_analysis
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

%http://en.wikipedia.org/wiki/Recurrence_plot
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

%http://en.wikipedia.org/wiki/Autoregressive_fractionally_integrated_moving_averag
e
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

%http://en.wikipedia.org/wiki/Autocorrelation
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

%
\backslash
url{http://en.wikipedia.org/wiki/Linear_discriminant_analysis}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Hidden Markov Model
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

% cannot account for future states - only capable of prediction
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

% weak, short-term memory
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Box-Jenkins
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

% intended for simplistic processes with well-understood stationarity and
 periodicity
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

% http://en.wikipedia.org/wiki/Box-Jenkins
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Spectral Analysis
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

% assumes some type of frequency-domain decomposition.
  Frequency-domain signal representations do not do a very good job predicting
 time-domain values.
 
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Shrinking-
\begin_inset Formula $\epsilon$
\end_inset

 SVM Regression
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

% theoretical foundation weak; only compensates for the relevance of recent
 data.
  See Markhov problem
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Chapter
SVM Details & Optimizations
\end_layout

\begin_layout Section
Quadratic Optimization Problem
\end_layout

\begin_layout Section
Support Vector Decomposition 
\end_layout

\begin_layout Standard
\begin_inset Marginal
status collapsed

\begin_layout Plain Layout
This section is probably better as an appendix
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Due to the simplicity of the constraints in the optimization problem, it
 is possible to use the decomposition method of Osuna to reduce the memory
 requirements of the Parzen-SVM algorithm.
\end_layout

\begin_layout Subsection
 Sub-Problem Definition 
\end_layout

\begin_layout Standard
The decomposition algorithm breaks 
\begin_inset Formula $X$
\end_inset

 into two working sets 
\begin_inset Formula $B,N$
\end_inset

, and attempts to optimize 
\begin_inset Formula $B$
\end_inset

 while keeping 
\begin_inset Formula $N$
\end_inset

 fixed.
 This results in the following iterative optimization problem where 
\begin_inset Formula $\boldsymbol{\beta}^{k}$
\end_inset

 denotes the result of the previous iteration:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
W(\boldsymbol{\beta}_{B}) & =\frac{1}{2}\begin{bmatrix}\boldsymbol{\beta}_{B}^{T} & (\boldsymbol{\beta}_{N}^{k})^{T}\end{bmatrix}\begin{bmatrix}P_{BB} & P_{BN}\\
P_{NB} & P_{NN}\end{bmatrix}\begin{bmatrix}\boldsymbol{\beta}_{B}\\
\boldsymbol{\beta}_{N}^{k}\end{bmatrix}-\begin{bmatrix}q_{B}^{T} & q_{N}^{T}\end{bmatrix}\begin{bmatrix}\boldsymbol{\beta}_{B}\\
\boldsymbol{\beta}_{N}^{k}\end{bmatrix}\\
 & =\frac{1}{2}\boldsymbol{\beta}_{B}^{T}P_{BB}\boldsymbol{\beta}_{B}-(-q_{B}+P_{BN}\boldsymbol{\beta}_{N}^{k})^{T}\boldsymbol{\beta}_{B}\\
 & =\frac{1}{2}\begin{bmatrix}\beta_{i} & \beta_{j}\end{bmatrix}\begin{bmatrix}P_{ii} & P_{ij}\\
P_{ij} & P_{jj}\end{bmatrix}\begin{bmatrix}\beta_{i}\\
\beta_{j}\end{bmatrix}-(-q_{B}+P_{BN}\boldsymbol{\beta}_{N}^{k})^{T}\begin{bmatrix}\beta_{i}\\
\beta_{j}\end{bmatrix}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{equation}
\text{subject to}\quad0\le\beta_{i},\beta_{j},\quad\beta_{i}+\beta_{j}=1-\mathbf{1}^{T}\boldsymbol{\beta}_{N}^{k}\end{equation}

\end_inset


\end_layout

\begin_layout Subsection
 Working Set Selection 
\end_layout

\begin_layout Standard
Select
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align}
 & i\in\text{arg}\max_{t}\left\{ -\nabla f(\boldsymbol{\beta}^{k})_{t}\ |\quad t\in I(\boldsymbol{\beta}^{k})\right\} \\
 & j\in\text{arg}\min_{t}\left\{ -\frac{b_{it}^{2}}{a_{it}}\ |\quad t\in I(\boldsymbol{\beta}^{k}),\quad-\nabla f(\boldsymbol{\beta}^{k})_{t}<-\nabla f(\boldsymbol{\beta}^{k})_{i}\right\} \end{align}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset ERT
status open

\begin_layout Plain Layout

% This needs to be checked for the new optimization scenario
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align}
I(\boldsymbol{\beta}) & \equiv\{t\ |\quad\beta_{t}<1\quad\text{or}\quad\beta_{t}>0\}\\
 & a_{it}=P_{ii}+P_{tt}-2P_{it}\\
 & \bar{a}_{it}=\begin{cases}
a_{it} & \text{if}\ a_{it}>0\\
\delta & \text{otherwise}\end{cases}\\
 & b_{it}=-\nabla f(\boldsymbol{\beta}^{k})_{i}+\nabla f(\boldsymbol{\beta}^{k})_{t}\\
\nabla f(\boldsymbol{\beta})_{i} & \equiv P_{i}\boldsymbol{\beta}-q_{i}\end{align}

\end_inset


\end_layout

\begin_layout Subsection
Stopping Condition 
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{equation}
\max_{i\in I(\boldsymbol{\alpha}^{k})}-\nabla f(\boldsymbol{\alpha})_{i}+\min_{j\in I(\boldsymbol{\alpha}^{k})}\nabla f(\boldsymbol{\alpha})_{j}\le\epsilon\end{equation}

\end_inset


\end_layout

\begin_layout Section
Cascade SVM
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "Hazan08"

\end_inset


\end_layout

\begin_layout Section
Parallel SVM Decomposition
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "Graf04"

\end_inset


\end_layout

\begin_layout Chapter
Further Research
\end_layout

\begin_layout Section
Data Pre-Processing
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

% logistic function using mean and sd to put most training points between
 .1 and .9
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

% logistic function from delta using mean and sd in same way if data non-station
ary
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

% iterative integration process until stationary data found ?
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Performance
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "Research/research.bib"
options "plain"

\end_inset


\end_layout

\end_body
\end_document
