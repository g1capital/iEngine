#LyX 1.6.2 created this file. For more info see http://www.lyx.org/
\lyxformat 345
\begin_document
\begin_header
\textclass amsbook
\begin_preamble



\usepackage{amsfonts}
\end_preamble
\use_default_options false
\begin_modules
theorems-ams
\end_modules
\language english
\inputencoding auto
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\paperfontsize 10
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry true
\use_amsmath 1
\use_esint 0
\cite_engine basic
\use_bibtopic false
\paperorientation portrait
\leftmargin 1.5in
\topmargin 1in
\rightmargin 1.5in
\bottommargin 1.25in
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\author "" 
\author "" 
\end_header

\begin_body

\begin_layout Title
Acting Machines
\end_layout

\begin_layout Author
Ryan Michael
\end_layout

\begin_layout Standard
\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset nomencl_print
LatexCommand printnomenclature

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Chapter
Introduction
\end_layout

\begin_layout Standard
Wikipedia defines 
\begin_inset Quotes eld
\end_inset

Machine Learning
\begin_inset Quotes erd
\end_inset

 as 
\emph on
a scientific discipline that is concerned with the design and development
 of algorithms that allow computers to learn based on data
\emph default
.
 Machine learning deals with the development of Learning Machines (LM's)
 capable of autonomously generating probabalistic models using sets of observati
ons.
 This text builds upon the foundation of Machine Learning to develop an
 Acting Machine (AM); a learning machine capable of interacting with with
 its environment in a motivated way.
 
\end_layout

\begin_layout Standard
The acting machine is built from two basic operations; a learning machine
 capable of developing models of the AM's environment based on a set of
 observations and a volitive algorithm which generates specific actions
 based on a set of motivational parameters.
 We will refer to these two operations as 
\begin_inset Quotes eld
\end_inset

estimation
\begin_inset Quotes erd
\end_inset

 and and 
\begin_inset Quotes eld
\end_inset

choice
\begin_inset Quotes erd
\end_inset

.
 The term estimation refers to the probabalistic nature of the model.
 In statistical terms the generation of a model is framed as the estimation
 of an unknown probability distribution function (PDF) based on a set of
 observations.
 The term choice refers to the process of selecting a 
\emph on
specific
\emph default
 action from the set of 
\emph on
possible
\emph default
 actions.
 This selection process is informed by a set of motivational parameters
 which quantify the types of outcomes the AM seeks to cause by a given selection.
 This text is organized into two parts; the first develops a robust estimation
 procedure, and the second develops the choice procedure.
 
\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Part
Estimation
\end_layout

\begin_layout Standard
Estimation is the process by which a set of observations of a random variable
 are used to generate an estimate of the unknown probability distribution
 of the random variable.
 The approach to estimation we will use generates an estimate of the probability
 of a specific point based on a set of observations.
 In order to estimate the probablility of such a point, we will establish
 a method of measuring the distance from the point to each of the given
 observations.
 The closer the point whose probability is being estimated lies to the set
 of observations, the higher the estimated probability of the point will
 be.
 The intuitive principle behind this approach is that for a sample of a
 random variable, the higher the probability in a given area, the more observati
ons we will see in that area.
\end_layout

\begin_layout Standard
The estimation chapters are organized as follows; Chapter 2 defines the
 metric which will be used to determine the 
\begin_inset Quotes eld
\end_inset

closeness
\begin_inset Quotes erd
\end_inset

 of two points, Chapter 3 applies this metric to a PDF estimate function
 called the Parzen Window estimator, Chapter 4 develops an equivalent function
 which requires less computational resources to generate estimates, and
 Chapter 5 discusses methods of integrating multiple estimators into an
 ensemble system.
\end_layout

\begin_layout Section*
Formal Setting: Estimation
\end_layout

\begin_layout Standard
We define the estimation problem as the generation of a Probability Density
 Functions which describes a random process 
\begin_inset Formula $X$
\end_inset

.
 The random process takes values in a domain defined by its abstract space
 
\begin_inset Formula $\Omega$
\end_inset

 which is limited to the set of real numbers 
\begin_inset Formula $\mathbb{R}$
\end_inset

 of dimension 
\begin_inset Formula $d$
\end_inset

.
 We define the set of events over the abstract space a 
\begin_inset Formula $\mathcal{F}$
\end_inset

, which we will assume to be the Borel 
\begin_inset Formula $\sigma$
\end_inset

-algebra 
\begin_inset Formula $\mathcal{B}$
\end_inset

 over 
\begin_inset Formula $\Omega$
\end_inset

.
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Generally, the Borel 
\begin_inset Formula $\sigma$
\end_inset

-algebra is the set of all possible contiguous subsets of 
\begin_inset Formula $\mathbb{R}^{d}$
\end_inset

.
 The event space 
\begin_inset Formula $\mathcal{F}$
\end_inset

 therefore includes any interval of the abstract space.
\end_layout

\end_inset

 Finally, we assume there exists a probability measure 
\begin_inset Formula $\mathcal{P}$
\end_inset

 defined for each element of 
\begin_inset Formula $\mathcal{F}$
\end_inset

; the estimation task is to generate an estimate of 
\begin_inset Formula $\mathcal{P}$
\end_inset

 for any point in 
\begin_inset Formula $\Omega$
\end_inset

 given 
\begin_inset Formula $\ell$
\end_inset

 independant and identitically distributed (i.i.d.) sample data points 
\begin_inset Formula $x_{1},...,x_{\ell}$
\end_inset

 are given:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
X & =(\Omega,\mathcal{F},\mathcal{P})\\
\Omega & \in\mathbb{R}^{d}\\
\mathcal{F} & =\mathcal{B}(\Omega)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
X & =[\vec{x}_{1},...,\vec{x}_{\ell}]\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$\\Omega$"
description "Abstract space of a random variable"

\end_inset


\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$\\mathcal{F}$"
description "Set of events for a random variable"

\end_inset


\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$\\mathcal{P}$"
description "Probability measure for a random variable"

\end_inset


\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$\\mathbb{R}^d$"
description "The set of real d-dimensional numbers"

\end_inset


\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$\\vec{x}$"
description "A vector observation of a random variable"

\end_inset


\end_layout

\begin_layout Standard
Our objective is to develop an estimate 
\begin_inset Formula $\varphi(x:\ X)$
\end_inset

 of the probability of the point 
\begin_inset Formula $x$
\end_inset

 given a set of observations 
\begin_inset Formula $X$
\end_inset

 assuming some minimal uncertainty 
\begin_inset Formula $\xi$
\end_inset

 in the data:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi(\vec{x}:\ X) & \longmapsto\Pr(\vec{x}|X)\pm\xi\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$\\varphi(\\cdot)$"
description "A probability density function estimator"

\end_inset


\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$\\Pr(\\cdot)$"
description "Probability"

\end_inset


\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$\\xi$"
description "Slack variable"

\end_inset


\end_layout

\begin_layout Standard
We will develop methods of estimation using kernel distance functions 
\begin_inset Formula $K_{\gamma}(x,y)$
\end_inset

 which transform the distance 
\begin_inset Formula $\|\cdot,\cdot\|$
\end_inset

 between two points into a more suitable distance for probability estimation.
 The kernel distance between a point and itself is defined as 1, and the
 cumulative distance between any point and 
\begin_inset Formula $\Omega$
\end_inset

 is defined as 1.
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
K_{\gamma}(x,y) & =f(\|x,y\|)\\
K_{\gamma}(x,x) & =1\\
\int_{\Omega}K_{\gamma}(x,y)dy & =1\end{align*}

\end_inset


\end_layout

\begin_layout Chapter
Set Metrics
\end_layout

\begin_layout Standard
We begin our discussion of estimation by considering the nature of the observati
ons 
\begin_inset Formula $X$
\end_inset

.
 The most significant element of the AM approach to estimation is that we
 will assume there exists 
\begin_inset Quotes eld
\end_inset

local structure
\begin_inset Quotes erd
\end_inset

 to the set of observations 
\begin_inset Formula $X$
\end_inset

.
 More specifically, we assume that there are similarities between the local
 distribution of 
\begin_inset Formula $\mathcal{P}$
\end_inset

 in different 
\begin_inset Quotes eld
\end_inset

neighborhoods
\begin_inset Quotes erd
\end_inset

.
 We will see in Chapter 3 that such similarities allow us to estimate probabilit
ies, and in Chapter 4 that such similarities allow us to reduce the computationa
l demands of estimation.
 We therefore develop a formal understanding of a 
\begin_inset Quotes eld
\end_inset

neighborhood
\begin_inset Quotes erd
\end_inset

 as well as a metric between two 
\begin_inset Quotes eld
\end_inset

neighborhoods
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Section
Windowing
\end_layout

\begin_layout Standard
We define neighborhoods using two parameters; the location of the neighborhood
 and the width of the neighborhood.
 We will restrict our attention to neighborhoods whose location is defined
 by a point 
\begin_inset Formula $x\in X$
\end_inset

, and use the parameter 
\begin_inset Formula $\alpha$
\end_inset

 to describe the width of a neighborhood.
 We describe points 
\begin_inset Formula $x_{i}\in X$
\end_inset

 as being 
\begin_inset Quotes eld
\end_inset

included in
\begin_inset Quotes erd
\end_inset

 a neighborhood, and describe the extent to which a point 
\begin_inset Formula $x_{i}$
\end_inset

 is included in a neighborhood using a value bounded by 
\begin_inset Formula $(0,\infty)$
\end_inset

.
 We do so through the use of a windowing kernel function 
\begin_inset Formula $\omega_{\alpha}(\cdot)$
\end_inset

 which returns a the extent to which an observation 
\begin_inset Formula $x_{i}$
\end_inset

 is included in the window 
\begin_inset Formula $w$
\end_inset

 defined by 
\begin_inset Formula $x$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\omega_{\alpha}(w,x_{i}) & \Rightarrow(0,\infty)\\
\int_{-\infty}^{\infty}\omega_{\alpha}(w,x_{i})dx_{i} & =1\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can use any kernel function for 
\begin_inset Formula $\omega(\cdot)$
\end_inset

, however we assume that the windowing function has a peak at 
\begin_inset Formula $\omega_{\alpha}(w,x)$
\end_inset

 and that it drops off as 
\begin_inset Formula $\left\Vert x-x_{i}\right\Vert \rightarrow\infty$
\end_inset

.
 
\end_layout

\begin_layout Section
Set Divergence
\end_layout

\begin_layout Standard
Multiple methods exist to generate PDF estimates from a set of observations
 (indeed we will rely on two such methods), however these approaches generally
 require a distance metric 
\begin_inset Formula $\|\cdot,\cdot\|$
\end_inset

 defined over the abstract space 
\begin_inset Formula $\Omega$
\end_inset

.
 In the context of defining the distance between two points, we can use
 the 
\begin_inset Formula $L^{1}$
\end_inset

 (manhattan) distance or the 
\begin_inset Formula $L^{2}$
\end_inset

 (euclidian) distance:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\|x,y\|^{L^{1}} & =\sum_{d}\left|x^{d}-y^{d}\right|\\
\|x,y\|^{L^{2}} & =\sqrt{\sum_{d}\left(x^{d}-y^{d}\right)^{2}}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
These metrics are restricted to distances between points.
 Developing a metric for comparing two neighborhoods is therefore treated
 as developing a metric for comparing two windows.
 There are multiple divergence measures available which can be used to define
 a "distance" between two sets.
 We will use the general class of f-divergences, which define the divergence
 between two probability distributions.
 We will use an estimation function 
\begin_inset Formula $\varphi$
\end_inset

 based on two sets of observations 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 as our two probability distributions.
 It will later be shown the importance of the distance metric 
\begin_inset Formula $\|\cdot,\cdot\|$
\end_inset

 being integrable; for this reason we will use the Pearson Divergence as
 our distance metric
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\|X,Y\| & =\sum_{x\in\{X\cup Y\}}\left(\frac{\varphi(x:\ X)}{\varphi(x:\ Y)}-1\right)^{2}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Our interest is in comparing two windows over a given set.
 This introduces a complication; windows over a single set of observations
 will diverge as the window locations diverge, and the distance between
 two sets of observations does not describe a useful measure of the similarity
 between two windows.
 For this reason we introduce affine transformations to one of the windows.
 Affine transformations describe a class of linear transformations defined
 by two parameters 
\begin_inset Formula $(\mathbf{A},\mathbf{b})$
\end_inset

.
 The affine transformation of a set 
\begin_inset Formula $X$
\end_inset

 is defined as
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
f(X:\ \mathbf{A},\mathbf{b}) & =\mathbf{A}X+\mathbf{b}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In other words, the transformation matrix 
\begin_inset Formula $\mathbf{A}$
\end_inset

 scales, rotates, and shears 
\begin_inset Formula $X$
\end_inset

 while the transformation vector 
\begin_inset Formula $\mathbf{b}$
\end_inset

 shifts it.
 The objective of affine transformations is to determine the divergence
 between windows under multiple possible transformations.
 We would like the divergence measure to reflect all possible transformations
 and describe the average 
\emph on
potential 
\emph default
divergence between two windows.
 One approach to this is to explicitly determine values for the two matrices
 and to determine the distance 
\begin_inset Formula $\|\cdot,\cdot\|$
\end_inset

 using these values.
 Because the Pearson Divergence is a summation, we can control the influence
 of each point by scaling it using the windowing function:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\|w_{X},w_{X}:\ \nu\| & =\sum_{i=1}^{\ell}\omega_{\alpha}(w_{\nu},x_{\nu})\left(\frac{\varphi(x_{\nu}:\ w_{D},\mathbf{A}X+\mathbf{b})}{\varphi(x_{i}^{\nu}:\ w_{D},X)}-1\right)^{2}\\
\varphi(x^{\nu}:\ w_{n}^{D},X) & =\sum_{i=1}^{\ell}\frac{\omega_{\alpha}(w_{n}^{\nu},x_{i}^{\nu})}{\sum_{j=1}^{\ell}\omega_{\alpha}(w_{n}^{\nu},x_{j}^{\nu})}K_{\gamma}(x^{\nu},x_{i}^{\nu})\\
 & =\sum_{i=1}^{\ell}\ddot{\omega}_{\alpha}(w_{n}^{\nu},x_{i}^{\nu},X)\ K_{\gamma}(x^{\nu},x_{i}^{\nu})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\mathbf{A}X_{n}+\mathbf{b} & =X_{m}\\
f(X_{n},X_{m}) & \longmapsto\mathbf{b}=\left(X_{n}\right)_{1}-\left(X_{m}\right)_{1}\\
g(X_{n},X_{m}) & \longmapsto\mathbf{A}=\left(X_{n}\right)_{i\neq1}\left(X_{m}\right)_{i\neq1}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Work this through as a summation over partitions of 
\begin_inset Formula $X$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
A more robust approach is to integrate over all possible values of 
\begin_inset Formula $(\mathbf{A},\mathbf{b}):$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\|w_{n}^{X},w_{m}^{X}:\ \nu\| & =\sum_{i=1}^{\ell}\omega_{\alpha}(w_{n}^{\nu},x_{i}^{\nu})\int\int_{-\infty}^{\infty}\left(\frac{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},\mathbf{A}X+\mathbf{b})}{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},X^{\nu})}-1\right)^{2}d\mathbf{A}d\mathbf{b}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
This approach allows us to compare the distance between 
\emph on
any
\emph default
 linear transformation 
\begin_inset Formula $\mathbf{A}X+\mathbf{b}$
\end_inset

 and 
\begin_inset Formula $X$
\end_inset

, a far more powerful and less computationally demanding approach.
 Doing so requires that we calculate the following integral:
\end_layout

\begin_layout Standard
\begin_inset Formula \[
\int\int_{-\infty}^{\infty}\left(\frac{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},\mathbf{A}X+\mathbf{b})}{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},X^{\nu})}-1\right)^{2}d\mathbf{A}d\mathbf{b}\]

\end_inset


\end_layout

\begin_layout Standard
Because 
\begin_inset Formula $(\mathbf{A},\mathbf{b})$
\end_inset

 is a pair of matrix transformation, we must integrate the previous equation
 element-wise:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\int\int_{-\infty}^{\infty}\left(\frac{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},\mathbf{A}X+\mathbf{b})}{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},X^{\nu})}-1\right)^{2}d\mathbf{A}d\mathbf{b} & =\int...\int_{-\infty}^{\infty}\left(\frac{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},\mathbf{A}X+\mathbf{b})}{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},X^{\nu})}-1\right)^{2}d\mathbf{A}_{\nu,0},...,d\mathbf{A}_{\nu,d}d\mathbf{b}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Explain all this shit below
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
f([x^{0},...,x^{d}]:\ a,b,c,f,h) & =\left(a\ \exp\left(-b\left(\left(x^{d}\right)^{2}+x^{d}\sum_{i=1}^{d-1}x^{i}c^{i}+f\right)\right)-h\right)^{2}\\
\int...\int f([x^{0},...,x^{d}]:\ a,b,c,f,h)\ dx^{0},...,dx^{d} & =\int...\int f\left([x^{0},...,x^{d-1}]:\ \frac{\sqrt{\frac{\pi}{2}}a^{2}}{\sqrt{b}},-\frac{b}{2},-2bf,0\right)\ dx^{0},...,dx^{d-1}\\
 & \qquad\qquad+\int f\left([x^{0},...,x^{d-1}]:\ \frac{-2a\sqrt{\pi}}{\sqrt{b}},-\frac{b}{4},-4f,0\right)\ dx^{0},...,dx^{d-1}\\
\int f([x^{0}]:\ a,b,f,h)\ dx^{0} & =\frac{\sqrt{\frac{\pi}{2}}a^{2}}{\sqrt{b}}\exp\left(-\frac{1}{2}b^{2}f\right)-\frac{2a\sqrt{\pi}}{\sqrt{b}}\exp\left(-bf\right)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\int\int_{-\infty}^{\infty}\left(\frac{\varphi(x^{\nu}:\ w_{n}^{\nu},\mathbf{A}X+\mathbf{b})}{\varphi(x^{\nu}:\ w_{n}^{\nu},X)}-1\right)^{2}d\mathbf{A}d\mathbf{b} & =\int...\int\left(\frac{\varphi\left(x^{\nu}:\ w_{n}^{\nu},\left[\mathbf{b}_{\nu}+\sum_{n=1}^{|D|}\mathbf{A}_{\nu,n}x_{i}^{n}|\ x_{i}\in X\right]\right)}{\varphi(x^{\nu}:\ w_{n}^{\nu},X)}-1\right)^{2}d\mathbf{A}d\mathbf{b}\\
 & =\int...\int f([x^{0},...,x^{d}]:\ a,b,c,f,h)\ dx^{0},...,dx^{d}d\mathbf{b}_{\nu}\\
a & =\frac{\sum_{i=1}^{\ell}\ddot{\omega}_{\alpha}(w_{n}^{\nu},x_{i}^{\nu},X)}{\sum_{i=1}^{\ell}\ddot{\omega}_{\alpha}(w_{n}^{\nu},x_{i}^{\nu},X)\ \exp\left(-\frac{1}{\gamma}\left(x^{\nu}-x_{i}^{\nu}\right)^{2}\right)}\\
b & =\frac{1}{\gamma}\\
c & =???\\
f & =\left(x^{\nu}\right)^{2}-2x^{\nu}\mathbf{b}_{\nu}+\mathbf{b}_{\nu}^{2}\\
h & =1\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Make a note that for d not in D, A_dd=0, b=0
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Re-write this whole section, moving parts to the PW portion
\end_layout

\end_inset


\end_layout

\begin_layout Chapter
Parzen Window Estimators
\end_layout

\begin_layout Section
Parzen Windows for i.i.d.
 Data
\end_layout

\begin_layout Standard
Our task is to estimate the probability of a given vector 
\begin_inset Formula $\vec{x}$
\end_inset

 in the abstract space 
\begin_inset Formula $\Omega$
\end_inset

 based on a set of observations 
\begin_inset Formula $X$
\end_inset

.
 One method of accomplishing this is by using the Parzen Window (PW) method.
 We choose the Parzen Window method because it allows us to estimate probabiliti
es of unordered sets, provided they have an addition operation and a kernel
 function exists to provide a distance metric.
 The basic operation of the PW method is to estimate the probability of
 a point based on the sum of the distance from that point to each point
 in a set of prior observations.
 The Parzen Window approach to probability density function (PDF) estimation
 is as follows; given a set of prior observations 
\begin_inset Formula $X$
\end_inset

 and a kernel function 
\begin_inset Formula $K_{\gamma}(\cdot,\cdot)$
\end_inset

 with width parameter 
\begin_inset Formula $\gamma$
\end_inset

, the probability of a point 
\begin_inset Formula $\vec{x}$
\end_inset

 is determined by :
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi(\vec{x}:\ X) & =\sum_{i}^{\ell}\frac{1}{\ell}K_{\gamma}(\vec{x},\vec{x}_{i})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$K_\\gamma (x,y)$"
description "Kernel function"

\end_inset


\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$\\gamma$"
description "Kernel width parameter"

\end_inset


\end_layout

\begin_layout Standard
Multiple kernel functions exist, in this paper we will use the Radial Basis
 Function (RBF) kernel:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
K_{\gamma}\left(\vec{x},\vec{y}\right) & =\prod_{\upsilon=1}^{d}\frac{1}{\gamma\sqrt{2\pi}}e^{-\frac{1}{\gamma}\|x^{\nu},y^{\nu}\|^{2}}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$\\|\\cdot,\\cdot\\|$"
description "Distance metric"

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $\|\cdot,\cdot\|$
\end_inset

 is some metric, for instance the 
\begin_inset Formula $L^{2}$
\end_inset

 distance:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\|x,y\| & =\left(x-y\right)^{2}\end{align*}

\end_inset


\end_layout

\begin_layout Section
Parzen Windows for Transformation-Invariant Data
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
re-write this to refer to previous section
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Because we must establish a context for TI data, we must think of the set
 of observations 
\begin_inset Formula $X$
\end_inset

 as part of both the problem definition and the solution.
 This means that we can no longer simply calculate the kernel distance between
 
\begin_inset Formula $x$
\end_inset

 and each of the observations in 
\begin_inset Formula $X$
\end_inset

 independently - we must compare the 
\emph on
context
\emph default
 of 
\begin_inset Formula $x$
\end_inset

 with contexts of 
\begin_inset Formula $X$
\end_inset

.
 This requires a kernel function capable of comparing two 
\emph on
sets of points
\emph default
.
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
\begin_inset Formula \begin{align*}
\mathcal{K}_{\gamma}\left(X_{i},X_{j}\right) & =\frac{1}{\gamma\sqrt{2\pi}}e^{-\frac{1}{\gamma}\|X_{i},X_{j}\|}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can simplify this equation by observing that we are not actually dealing
 with two sets; we're dealing with two windows 
\begin_inset Formula $w_{n}$
\end_inset

 and 
\begin_inset Formula $w_{m}$
\end_inset

 within 
\begin_inset Formula $X$
\end_inset

:
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
\begin_inset Formula \begin{align*}
\mathcal{K}_{\gamma}\left(w_{n}^{X},w_{m}^{X}\right) & =\frac{1}{\gamma\sqrt{2\pi}}e^{-\frac{1}{\gamma}\|w_{n}^{X},w_{n}^{X}\|}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can extend this basic result to multiple dimensions by using the tensor
 product of the kernel values:
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
\begin_inset Formula \begin{align*}
\mathcal{K}_{\gamma}\left(w_{n}^{X},w_{m}^{Y}:\ D\right) & =\prod_{\nu\in D}\frac{1}{\gamma\sqrt{2\pi}}e^{-\frac{1}{\gamma}\|w_{n}^{X},w_{n}^{Y}:\ \nu\|}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
There are multiple divergence measures available which can be used to define
 a "distance" between two sets.
 We will later show the importance of the distance metric 
\begin_inset Formula $\|\cdot,\cdot\|$
\end_inset

 being integrable; for this reason we will use the Pearson Divergence as
 our distance metric when comparing sets.
 In order to accommodate linear affine transformations, we add a 
\begin_inset Formula $d\times d$
\end_inset

 transformation matrix 
\begin_inset Formula $\mathbf{A}$
\end_inset

 and a 
\begin_inset Formula $d\times1$
\end_inset

 shift matrix 
\begin_inset Formula $\mathbf{b}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\|X^{\nu},Y^{\nu}\| & =\sum_{x^{\nu}\in\{X\cup Y\}}\left(\frac{\varphi(x^{\nu}:\ \mathbf{A}^{\nu}X^{\nu}+\mathbf{b}_{\nu})}{\varphi(x^{\nu}:\ Y^{\nu})}-1\right)^{2}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Because the Pearson Divergence is a summation, we can control the influence
 of each point by scaling it using the windowing function:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\|w_{n}^{X},w_{m}^{X}:\ \nu\| & =\sum_{i=1}^{\ell}\omega_{\alpha}(w_{n}^{\nu},x_{i}^{\nu})\left(\frac{\varphi(x_{i}^{\nu}:\ w_{m}^{D},\mathbf{A}X+\mathbf{b})}{\varphi(x_{i}^{\nu}:\ w_{m}^{D},X)}-1\right)^{2}\\
\varphi(x^{\nu}:\ w_{n}^{D},X) & =\sum_{i=1}^{\ell}\frac{\omega_{\alpha}(w_{n}^{\nu},x_{i}^{\nu})}{\sum_{j=1}^{\ell}\omega_{\alpha}(w_{n}^{\nu},x_{j}^{\nu})}K_{\gamma}(x^{\nu},x_{i}^{\nu})\\
 & =\sum_{i=1}^{\ell}\ddot{\omega}_{\alpha}(w_{n}^{\nu},x_{i}^{\nu},X)\ K_{\gamma}(x^{\nu},x_{i}^{\nu})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
These two matrix transformations are used to shift, scale, rotate, shear
 or mirror the observations in the window 
\begin_inset Formula $w_{n}^{D}$
\end_inset

 of 
\begin_inset Formula $X$
\end_inset

.
 The first transformation matrix 
\begin_inset Formula $\mathbf{A}$
\end_inset

 is a 
\begin_inset Formula $d\times d$
\end_inset

 matrix.
 The linear operator 
\begin_inset Formula $\mathbf{A}X$
\end_inset

 allows us to scale, rotate, shear, and mirror 
\begin_inset Formula $X$
\end_inset

 depending on the matrix values of 
\begin_inset Formula $\mathbf{A}$
\end_inset

.
 The second transformation matrix 
\begin_inset Formula $\mathbf{b}$
\end_inset

 is a 
\begin_inset Formula $d\times1$
\end_inset

 matrix; adding these terms together allows us to shift 
\begin_inset Formula $X$
\end_inset

 along any axis based on the values of 
\begin_inset Formula $\mathbf{b}$
\end_inset

.
 
\end_layout

\begin_layout Standard
One approach to these transformations is to explicitly determine values
 for the two matrices and to determine the distance 
\begin_inset Formula $\|\cdot,\cdot\|$
\end_inset

 using these values.
 A more robust approach is to integrate over all possible values of 
\begin_inset Formula $(\mathbf{A},\mathbf{b}):$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\|w_{n}^{X},w_{m}^{X}:\ \nu\| & =\sum_{i=1}^{\ell}\omega_{\alpha}(w_{n}^{\nu},x_{i}^{\nu})\int\int_{-\infty}^{\infty}\left(\frac{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},\mathbf{A}X+\mathbf{b})}{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},X^{\nu})}-1\right)^{2}d\mathbf{A}d\mathbf{b}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
This approach allows us to compare the distance between 
\emph on
any
\emph default
 linear transformation 
\begin_inset Formula $\mathbf{A}X+\mathbf{b}$
\end_inset

 and 
\begin_inset Formula $X$
\end_inset

, a far more powerful and less computationally demanding approach.
 Doing so requires that we calculate the following integral:
\end_layout

\begin_layout Standard
\begin_inset Formula \[
\int\int_{-\infty}^{\infty}\left(\frac{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},\mathbf{A}X+\mathbf{b})}{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},X^{\nu})}-1\right)^{2}d\mathbf{A}d\mathbf{b}\]

\end_inset


\end_layout

\begin_layout Standard
Because 
\begin_inset Formula $(\mathbf{A},\mathbf{b})$
\end_inset

 is a pair of matrix transformation, we must integrate the previous equation
 element-wise:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\end{align*}

\end_inset


\begin_inset Formula \begin{align*}
\int\int_{-\infty}^{\infty}\left(\frac{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},\mathbf{A}X+\mathbf{b})}{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},X^{\nu})}-1\right)^{2}d\mathbf{A}d\mathbf{b} & =\int...\int_{-\infty}^{\infty}\left(\frac{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},\mathbf{A}X+\mathbf{b})}{\varphi(x_{i}^{\nu}:\ w_{m}^{\nu},X^{\nu})}-1\right)^{2}d\mathbf{A}_{\nu,0},...,d\mathbf{A}_{\nu,d}d\mathbf{b}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Explain all this shit below
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
f([x^{0},...,x^{d}]:\ a,b,c,f,h) & =\left(a\ \exp\left(-b\left(\left(x^{d}\right)^{2}+x^{d}\sum_{i=1}^{d-1}x^{i}c^{i}+f\right)\right)-h\right)^{2}\\
\int...\int f([x^{0},...,x^{d}]:\ a,b,c,f,h)\ dx^{0},...,dx^{d} & =\int...\int f\left([x^{0},...,x^{d-1}]:\ \frac{\sqrt{\frac{\pi}{2}}a^{2}}{\sqrt{b}},-\frac{b}{2},-2bf,0\right)\ dx^{0},...,dx^{d-1}\\
 & \qquad\qquad+\int f\left([x^{0},...,x^{d-1}]:\ \frac{-2a\sqrt{\pi}}{\sqrt{b}},-\frac{b}{4},-4f,0\right)\ dx^{0},...,dx^{d-1}\\
\int f([x^{0}]:\ a,b,f,h)\ dx^{0} & =\frac{\sqrt{\frac{\pi}{2}}a^{2}}{\sqrt{b}}\exp\left(-\frac{1}{2}b^{2}f\right)-\frac{2a\sqrt{\pi}}{\sqrt{b}}\exp\left(-bf\right)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\int\int_{-\infty}^{\infty}\left(\frac{\varphi(x^{\nu}:\ w_{n}^{\nu},\mathbf{A}X+\mathbf{b})}{\varphi(x^{\nu}:\ w_{n}^{\nu},X)}-1\right)^{2}d\mathbf{A}d\mathbf{b} & =\int...\int\left(\frac{\varphi\left(x^{\nu}:\ w_{n}^{\nu},\left[\mathbf{b}_{\nu}+\sum_{n=1}^{|D|}\mathbf{A}_{\nu,n}x_{i}^{n}|\ x_{i}\in X\right]\right)}{\varphi(x^{\nu}:\ w_{n}^{\nu},X)}-1\right)^{2}d\mathbf{A}d\mathbf{b}\\
 & =\int...\int f([x^{0},...,x^{d}]:\ a,b,c,f,h)\ dx^{0},...,dx^{d}d\mathbf{b}_{\nu}\\
a & =\frac{\sum_{i=1}^{\ell}\ddot{\omega}_{\alpha}(w_{n}^{\nu},x_{i}^{\nu},X)}{\sum_{i=1}^{\ell}\ddot{\omega}_{\alpha}(w_{n}^{\nu},x_{i}^{\nu},X)\ \exp\left(-\frac{1}{\gamma}\left(x^{\nu}-x_{i}^{\nu}\right)^{2}\right)}\\
b & =\frac{1}{\gamma}\\
c & =???\\
f & =\left(x^{\nu}\right)^{2}-2x^{\nu}\mathbf{b}_{\nu}+\mathbf{b}_{\nu}^{2}\\
h & =1\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Make a note that for d not in D, A_dd=0, b=0
\end_layout

\end_inset


\end_layout

\begin_layout Section
Performance
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Big-O
\end_layout

\end_inset


\end_layout

\begin_layout Section
Multiple Data Sources
\end_layout

\begin_layout Standard
Consider the case where data from multiple data sources contributes to our
 set of observations 
\begin_inset Formula $X$
\end_inset

, for instance the data drawn from a microphone and a video camera.
 We will refer to observations of the former as 
\begin_inset Formula $X=(\Omega^{X},\mathcal{F}^{X},\mathcal{P}^{X})$
\end_inset

 and the latter as 
\begin_inset Formula $Y=(\Omega^{Y},\mathcal{P}^{Y},\mathcal{F}^{Y})$
\end_inset

.
 In this situation all dimensions of the two vectors are independent.
 It is clear that if we intend to establish a PDF of the joint probability
 space 
\begin_inset Formula $(\Omega^{Y,X},\mathcal{P}^{Y,X},\mathcal{F}^{Y,X})$
\end_inset

, we must treat each dimension in 
\begin_inset Formula $\Omega^{X}$
\end_inset

 and 
\begin_inset Formula $\Omega^{Y}$
\end_inset

 as orthonormal to each other.
 
\end_layout

\begin_layout Standard
The most straightforward way to handle this situation is to assume that
 vector observations constitute sparse matrices; for any given dimension
 of an observation 
\begin_inset Formula $\vec{x}$
\end_inset

, the value can either be a real number or null:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
x^{\nu} & \in[\mathbb{R},\textrm{Ø}]\end{align*}

\end_inset

 In this case we only include operations between real-valued dimensions
 in our analysis.
 
\end_layout

\begin_layout Section
Single Channel Summary
\end_layout

\begin_layout Standard
We have developed a PDF estimation technique which allows us to take advantage
 of TI data.
 The solution uses a novel distance metric to compare the similarity between
 two sets of points in the context of arbitrary affine transformations of
 one set.
 The types of transformations considered by the proposed solution are restricted
 to affine transformations.
 In the next section we will develop a sparse method of estimating PDF's.
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi(\vec{x}:\ X) & =\sum_{i=1}^{\ell}\frac{1}{\ell}\ \mathcal{K}_{\gamma}(w^{D},w_{i}^{D},\{\vec{x}\cup X\})\\
\mathcal{K}_{\gamma}\left(w_{n}^{X},w_{m}^{X}:\ D\right) & =\prod_{\nu\in\tilde{D}}\frac{1}{\gamma\sqrt{2\pi}}e^{-\frac{1}{\gamma}\left(x_{n}^{\nu}-x_{m}^{\nu}\right)^{2}}\prod_{\nu\in D}\frac{1}{\gamma\sqrt{2\pi}}e^{-\frac{1}{\gamma}\|w_{n}^{X},w_{n}^{X}:\ \nu\|}\\
\|w_{n}^{X},w_{m}^{X}:\ \nu\| & =???\\
\ddot{\omega}_{\alpha}(w_{n}^{\nu},x_{i}^{\nu},X) & =\frac{\omega_{\alpha}(w_{n}^{\nu},x_{i}^{\nu})}{\sum_{j=1}^{\ell}\omega_{\alpha}(w_{n}^{\nu},x_{j}^{\nu})}\end{align*}

\end_inset


\end_layout

\begin_layout Chapter
Support Vector Optimizations
\end_layout

\begin_layout Standard
The Parzen Window method is neither sparse nor computationally efficient,
 and as the number of observations grows, these deficiencies quickly become
 prohibitive.
 We now investigate the use of Support Vector Machines to generate estimates.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Refer to big-O
\end_layout

\end_inset


\end_layout

\begin_layout Section
Generalized Parzen-SVM 
\end_layout

\begin_layout Standard
Support Vector Machines (SVM) are often used
\begin_inset Note Note
status open

\begin_layout Plain Layout
ref?
\end_layout

\end_inset

 to estimate probability distributions by solving the related problem of
 estimating the cumulative distribution function of the random variable
 in question.
\begin_inset Note Note
status open

\begin_layout Plain Layout
This isn't really the essence of SVM - put more verbiage in the intro regarding
 what SVM's are, why they work, and why they're superior to other approaches
 (say, neural networks)
\end_layout

\end_inset

 This reduces the problem to one of estimating a non-linear mapping from
 observations to cumulative distribution values, which can be formulated
 as an optimization problem over a linear operator equation.
 Unfortunately, these methods depend on the ability to calculate an empirical
 distribution for each observation:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{equation}
F_{\ell}(x)=\frac{1}{\ell}\sum_{i}\theta(x-x_{i})\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $\theta(x)$
\end_inset

 is the indicator function.
 To evaluate this function, the abstract space 
\begin_inset Formula $\Omega$
\end_inset

 must be ordered.
 While we have described a distance metric over 
\begin_inset Formula $\Omega$
\end_inset

, it is not clear what a meaningful ordering relation would be.
\end_layout

\begin_layout Standard
Rather than calculating the cumulative probability distribution of 
\begin_inset Formula $X$
\end_inset

, we begin with the assumption that the PW estimate of the probability distribut
ion is acceptably accurate and attempt to minimize the difference between
 the Support Vector (SV) estimate and the PW estimate.
 In this spirit, we will use a modification of the PW estimator which substitute
s a set of weights 
\begin_inset Formula $\beta$
\end_inset

 for the normalizing constant 
\begin_inset Formula $\frac{1}{\ell}$
\end_inset

 in the PW equation:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi_{\beta}(\vec{x}:\ X) & =\sum_{i=1}^{\ell}\beta_{i}\mathcal{K}_{\gamma}(w^{X},w_{i}^{X}:\ D)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The support vector approach requires that we define an optimization problem
 
\begin_inset Formula $W(\beta)$
\end_inset

 to determine the value of 
\begin_inset Formula $\beta$
\end_inset

.
 This optimization problem will determine which observations (or as we shall
 see, windows) will be used in estimations and which can be discarded as
 redundant or irrelevant information.
 The result of the optimization problem will be that a substantial number
 of multipliers 
\begin_inset Formula $\beta_{i}$
\end_inset

 will be 
\begin_inset Formula $0$
\end_inset

, allowing us to omit the windows defined by these points in the prediction
 phase.
 We define the optimization problem as minimizing the square loss between
 the SV and PW estimates over some set of observations 
\begin_inset Formula $X$
\end_inset

.
 The set of weights used in the Support Vector estimation must have a discrete
 number of elements; for simplicity we choose to assign a weight to each
 window defined by the time value of an observation in the training set
 and the windowing parameter 
\begin_inset Formula $\alpha$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
W(\beta:\ X) & \longmapsto\min_{\beta}\sum_{i=1}^{\ell}\left(\varphi(\vec{x}_{i}:\ X)-\varphi_{\beta}(\vec{x}_{i}:\ X)\right)^{2}+\beta\Omega(\lambda,X)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Discuss regularizier
\end_layout

\end_inset


\end_layout

\begin_layout Standard
For the optimization problem, we check the difference between the two estimates
 at windows defined by the observations 
\begin_inset Formula $X$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Discuss the equations below
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Update all these kernel notations
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\sum_{i=1}^{\ell}\left(\varphi(\vec{x}_{i}:\ X)-\varphi_{\beta}(\vec{x}_{i}:\ X)\right)^{2} & =\sum_{i=1}^{\ell}\left(\varphi(\vec{x}_{i}:\ X)\right)^{2}-2\left(\varphi(\vec{x}_{i}:\ X)\varphi_{\beta}(\vec{x}_{i}:\ X)\right)+\left(\varphi_{\beta}(\vec{x}_{i}:\ X)\right)^{2}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
 & =\sum_{i=1}^{\ell}\left(\sum_{j=1}^{\ell}\frac{1}{\ell}K_{\gamma}(w_{i}^{D},w_{j}^{D},X)\right)^{2}-2\left(\sum_{j=1}^{\ell}\frac{1}{\ell}\mathcal{K}_{\gamma}(w_{i}^{D},w_{j}^{D},X)\right)\left(\sum_{j=1}^{\ell}\beta_{j}\mathcal{K}_{\gamma}(w_{i}^{D},w_{j}^{D},X)\right)\\
 & \qquad\qquad\qquad+\left(\sum_{j=1}^{\ell}\beta_{j}\mathcal{K}_{\gamma}(w_{i}^{D},w_{j}^{D},X)\right)^{2}\\
 & =\sum_{i=1}^{\ell}\sum_{\begin{array}{c}
j=1\\
k=1\end{array}}^{\ell}\frac{1}{\ell^{2}}\mathcal{K}_{\gamma}(w_{i}^{D},w_{j}^{D},X)\mathcal{K}_{\gamma}(w_{i}^{D},w_{k}^{D},X)-2\sum_{\begin{array}{c}
j=1\\
k=1\end{array}}^{\ell}\frac{1}{\ell}\mathcal{K}_{\gamma}(w_{i}^{D},w_{j}^{D},X)\beta_{j}\mathcal{K}_{\gamma}(w_{i}^{D},w_{k}^{D},X)\\
 & \qquad\qquad\qquad+\sum_{\begin{array}{c}
j=1\\
k=1\end{array}}^{\ell}\beta_{j}\mathcal{K}_{\gamma}(w_{i}^{D},w_{j}^{D},X)\mathcal{K}_{\gamma}(w_{i}^{D},w_{k}^{D},X)\\
 & =\sum_{\begin{array}{c}
i=1\\
j=1\\
k=1\end{array}}^{\ell}\beta_{j}\beta_{k}\mathcal{K}_{\gamma}(w_{i}^{D},w_{j}^{D},X)\mathcal{K}_{\gamma}(w_{i}^{D},w_{k}^{D},X)-\sum_{\begin{array}{c}
i=1\\
j=1\\
k=1\end{array}}^{\ell}\frac{2\beta_{j}}{\ell}\mathcal{K}_{\gamma}(w_{i}^{D},w_{j}^{D},X)\mathcal{K}_{\gamma}(w_{i}^{D},w_{jk}^{D},X)\\
 & \qquad\qquad\qquad+\sum_{\begin{array}{c}
i=1\\
j=1\\
k=1\end{array}}^{\ell}\frac{1}{\ell^{2}}\mathcal{K}_{\gamma}(w_{i}^{D},w_{j}^{D},X)\mathcal{K}_{\gamma}(w_{i}^{D},w_{k}^{D},X)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Because this is a minimization problem we can eliminate the last term (changing
 
\begin_inset Formula $\beta$
\end_inset

 won't affect its value).
 Substituting our optimization problem becomes:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
W(\beta:\ X) & \longmapsto\min_{\beta}\sum_{\begin{array}{c}
i=1\\
j=1\\
k=1\end{array}}^{\ell}\beta_{j}\beta_{k}\mathcal{K}_{\gamma}(w_{i}^{X},w_{j}^{X}:\ D)\mathcal{K}_{\gamma}(w_{i}^{X},w_{k}^{X}:\ D)\\
 & \qquad\qquad\qquad-\sum_{\begin{array}{c}
i=1\\
j=1\\
k=1\end{array}}^{\ell}\frac{2\beta_{j}}{\ell}\mathcal{K}_{\gamma}(w_{i}^{X},w_{j}^{X}:\ D)\mathcal{K}_{\gamma}(w_{i}^{X},w_{k}^{X}:\ D)+\lambda\Omega(\beta,X)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\text{subject to}\quad & \beta_{i}\ge0,\ \sum\beta=1\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Shouldn't the second term only have one kernel function? If not combine
 the first two terms
\end_layout

\end_inset


\end_layout

\begin_layout Chapter
Ensemble System
\end_layout

\begin_layout Standard
We now discuss creating a system composed of multiple estimators.
 It is well known that using a combination of estimates drawn from different
 models of an underlying phenomenon tends to increase the prediction accuracy
 of the hybrid system.
 We will begin by establishing an explanation for this phenomenon based
 on the concepts of VC Entropy and the uniform bounds on convergence of
 learning processes.
 We will then develop a method of quantifying the rate of convergence of
 an individual estimator, and show how this quantification can be used to
 build an optimal ensemble system of estimators.
 The basic question we will address is 
\emph on
how does one choose sets of dimension which will benefit from TI analysis,
 and how do we control the computational demands of an ensemble system?
\end_layout

\begin_layout Section
VC Entropy and Bounds on the Rate of Convergence
\end_layout

\begin_layout Standard
We use the notation of Vapnik - given three components:
\end_layout

\begin_layout Enumerate
A generator (G) of random vectors 
\begin_inset Formula $x\in\mathbb{R}^{n}$
\end_inset

, drawn independently from a fixed but unknown probability distribution
 function 
\begin_inset Formula $F(x)$
\end_inset


\end_layout

\begin_layout Enumerate
A supervisor (S) who returns an output value 
\begin_inset Formula $y$
\end_inset

 to every input vector 
\begin_inset Formula $x$
\end_inset

, according to a conditional distribution function 
\begin_inset Formula $F(y|x)$
\end_inset

, also fixed but unknown
\end_layout

\begin_layout Enumerate
A learning machine (LM) capable of implementing a set of functions 
\begin_inset Formula $\varphi(x,\alpha),\ \alpha\in\Lambda$
\end_inset

, where 
\begin_inset Formula $\Lambda$
\end_inset

 is a set of parameters
\end_layout

\begin_layout Standard
Our goal is to choose the function which best approximates the unknown PDF,
 given a set of vector observations:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
X & =\vec{x}_{1},...,\vec{x}_{\ell}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$X$"
description "Set of observations to be evaluated"

\end_inset


\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$x_i$"
description "Individual observations"

\end_inset


\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$\\ell$"
description "The number of observations "

\end_inset


\end_layout

\begin_layout Standard
We choose between potential functions based on the empirical risk function
 using the loss (discrepancy) 
\begin_inset Formula $L(y,f(x,\alpha))$
\end_inset

 between the response 
\begin_inset Formula $y$
\end_inset

 for a given value of 
\begin_inset Formula $x$
\end_inset

 and the predicted value 
\begin_inset Formula $f(x,\alpha)$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
R_{\text{emp}}(\alpha) & =\frac{1}{\ell}\sum_{i=1}^{\ell}L(y_{i},f(\vec{x}_{i},\alpha))\\
 & =\frac{1}{\ell}\sum_{i=1}^{\ell}Q(z_{i},\alpha)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$R_\\text{emp}(\\alpha)$"
description "Empirical Risk "

\end_inset


\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$L(\\cdot)$"
description "Loss function"

\end_inset


\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "$Q(\\cdot)$"
description "Loss Function"

\end_inset


\end_layout

\begin_layout Standard
We begin by describing the VC entropy of a set of estimators using their
 risk values 
\begin_inset Formula $Q(x:\ \beta)$
\end_inset

 defined by the set of parameters 
\begin_inset Formula $\alpha$
\end_inset

.
 Given a set of observations 
\begin_inset Formula $X=[x_{1},...,x_{\ell}]$
\end_inset

, we can construction a set of 
\begin_inset Formula $\ell$
\end_inset

-dimensional vectors
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
q(\beta) & =[Q(x_{1}:\ \beta),...,Q(x_{\ell}:\ \beta)]\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Each vector describes the loss of a given element of 
\begin_inset Formula $\beta$
\end_inset

 for the observations 
\begin_inset Formula $X$
\end_inset

.
 In the context of an SVM estimator, this refers to the divergence between
 the SVM and PW estimators.
 We define the minimum number of vectors required to "cover" 
\begin_inset Formula $q(\beta)$
\end_inset

 with some arbitrarily small measure of closeness 
\begin_inset Formula $\varepsilon$
\end_inset

 as 
\begin_inset Formula $N^{\Lambda}(\varepsilon:x_{1},...,x_{\ell})$
\end_inset

.
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
For example, if 
\begin_inset Formula $q(\alpha)=[1,2,4,1]$
\end_inset

, 
\begin_inset Formula $N^{\Lambda}(X)=3$
\end_inset


\end_layout

\end_inset

 Using this value, we calculate the VC Entropy 
\begin_inset Formula $H^{\Lambda}(X)$
\end_inset

 of the set of functions 
\begin_inset Formula $Q(x:\ \beta)$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
H^{\Lambda}(\varepsilon:\ell) & =\ln N^{\Lambda}(\varepsilon:x_{1},...,x_{\ell})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
can we formalize N?
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The VC Entropy essentially describes the number of observations in 
\begin_inset Formula $X$
\end_inset

 required to describe the PDF 
\begin_inset Formula $\mathcal{P}$
\end_inset

, based on the assumption that if multiple points in 
\begin_inset Formula $X$
\end_inset

 are 
\begin_inset Formula $\varepsilon$
\end_inset

-close to each other, we can eliminate all but one in our estimator.
 The VC Entropy is distribution-specific; it depends on the specific set
 of vectors 
\begin_inset Formula $q(\beta)$
\end_inset

.
 In order to generate distribution-independent bounds, we establish the
 growth function 
\begin_inset Formula $G^{\Lambda}(\ell)$
\end_inset

 which describes the maximal value of 
\begin_inset Formula $H^{\Lambda}(\ell)$
\end_inset

 for any distribution given the set of estimators defined by 
\begin_inset Formula $Q(x:\ \beta)$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
G^{\Lambda}(\ell) & =\ln\sup_{x_{1},...,x_{\ell}}N^{\Lambda}(x_{1},...,x_{\ell})\\
H^{\Lambda}(\ell) & \le G^{\Lambda}(\ell)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
It can be shown that the following equations hold true with probability
 
\begin_inset Formula $(1-\eta)$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\Psi & =4\frac{G^{\Lambda}\left(2\ell\right)-\ln\left(\eta/4\right)}{\ell}\\
R(\beta) & \le R_{\text{emp}}(\beta)+\frac{\Psi}{2}\left(1+\sqrt{1+\frac{4R_{\text{emp}}(\beta)}{\Psi}}\right)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Make sure the R(
\backslash
beta) notation has been explained
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Can we use H in the above equation?
\end_layout

\end_inset


\end_layout

\begin_layout Standard
This equation describes the upper bound on the risk of estimators from the
 set 
\begin_inset Formula $Q(x:\ \beta)$
\end_inset

 based on the number of observations 
\begin_inset Formula $\ell$
\end_inset

 and the empirical risk 
\begin_inset Formula $R_{\text{emp }}(\beta)$
\end_inset

.
 It can be further shown that the growth function is bounded by
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
G^{\Lambda} & \le h\left(\ln\frac{\ell}{h}+1\right)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $h$
\end_inset

 describes the VC Dimension of the estimator, defined as the maximum number
 of vectors that can be linearly separated by the estimator (in the case
 of binary estimators) or as the VC Dimension of the set of indicators 
\begin_inset Formula $I(x,\beta,\vartheta)$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
I(x,\beta,\vartheta) & =\theta(Q(x:\ \beta)-\vartheta),\ \beta\in\Lambda,\ \vartheta\in(0,1)\\
\theta(x) & =\begin{cases}
0 & \quad\text{if}\ x<0,\\
1 & \quad\text{if}\ x\ge0\end{cases}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $\vartheta$
\end_inset

 is some constant.
 In other words the VC Dimension of a real-valued estimator is determined
 by the maximum number of vectors which can be enclosed by a region with
 radius 
\begin_inset Formula $1-\vartheta$
\end_inset

.
 In practical terms, this means that the VC Dimension is defined by the
 granularity of the estimator 
\begin_inset Formula $Q(x:\ \beta)$
\end_inset

.
 Recall that PDF's are bounded by 
\begin_inset Formula $(0,1)$
\end_inset

; this means that each dimension of any loss vector 
\begin_inset Formula $q(\beta_{n})$
\end_inset

 is also bounded by 
\begin_inset Formula $(0,1)$
\end_inset

.
 Therefore the VC Dimension of an estimator is determined by the maximum
 number of regions with radius 
\begin_inset Formula $1-\vartheta$
\end_inset

 which can be defined on the interval 
\begin_inset Formula $(0,1)$
\end_inset

 in 
\begin_inset Formula $\ell$
\end_inset

 dimensions.
 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Check this paragraph
\end_layout

\end_inset


\end_layout

\begin_layout Section
Bounds of Convergence for TI Analysis
\end_layout

\begin_layout Standard
The growth function is used to characterize the worst-case performance for
 a specific type of estimator; we now show that the worst-case performance
 of an estimator capable of TI analysis is upper bounded by the risk of
 a non-TI estimator defined on the same dimensional set 
\begin_inset Formula $D$
\end_inset

.
 Consider the PDF generated by a given estimator 
\begin_inset Formula $\varphi(x:\ \alpha_{n})$
\end_inset

 and two loss functions; the loss function 
\begin_inset Formula $Q(x:\ \beta)$
\end_inset

 defined by the distance between 
\begin_inset Formula $\varphi(x:\ \beta_{n})$
\end_inset

 and 
\begin_inset Formula $X$
\end_inset

, and the loss function 
\begin_inset Formula $Q_{TI}(x:\ \beta)$
\end_inset

 defined by the TI distance between the same.
 It can easily be shown that 
\begin_inset Formula $Q(x:\ \beta)$
\end_inset

 is a special case of 
\begin_inset Formula $Q_{TI}(x:\ beta$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
Q(x:\ \beta) & =Q_{TI}(x:\ \beta),\quad\mathbf{A}=I,\ \mathbf{b}=0\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Recall that TI estimators are generated from the integral of the distance
 between two sets under transformations.
 We can therefore construct the following inequality:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\|X,Y\| & \ge\int\|X,\mathbf{A}Y+\mathbf{b}\|d\mathbf{A}d\mathbf{b}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
It is clear therefore that the TI loss will be less than or equal to the
 distance loss.
 
\end_layout

\begin_layout Section
Bayesian Model Averaging Ensemble Machine
\end_layout

\begin_layout Standard
We now develop a method of combining multiple estimators into a single learning
 machine.
 Our discussion of TI analysis has assumed that the distance metric is integrate
d over some set of dimensions 
\begin_inset Formula $D$
\end_inset

.
 In the case of high-dimensional data-sets the computational demands of
 integrating over set set of all dimensions in 
\begin_inset Formula $X$
\end_inset

 may outweigh the utility of doing so.
 We instead consider using multiple partitions 
\begin_inset Formula $D^{n}$
\end_inset

 of 
\begin_inset Formula $D^{X}$
\end_inset

 to generate partial estimators.
 We can further extend the flexibility of the ensemble system by restricting
 each partial estimator to a subset of observations 
\begin_inset Formula $X^{n}\subseteq X$
\end_inset

.
 We therefore define a set of partial estimators:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi^{n}(x:\ X^{n},D^{n}) & \longmapsto\Pr(x|X^{n})\approx\Pr(x|X)\\
X^{n} & \subseteq X\\
D^{n} & \subseteq D^{X}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
With associated risk bounds:
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
In the case of Parzen Estimators we can set the empirical risk to 0, in
 the case of SVM estimators we can set the empirical risk to the minimal
 value of the optimization problem minus the regularizer term.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\Psi^{n} & =4\frac{G^{\Lambda}\left(2|X^{n}|\right)-\ln\left(\eta/4\right)}{|X^{n}|}\\
R^{n}(\beta) & \le R_{\text{emp}}^{n}(\beta)+\frac{\Psi}{2}\left(1+\sqrt{1+\frac{4R_{\text{emp}}^{n}(\beta)}{\Psi}}\right)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $|\cdot|$
\end_inset

 refers to the cardinality of a set.
 Consider the case of multiple partial estimators which make estimates of
 
\begin_inset Formula $\Pr(x|X)$
\end_inset

 which we would like to combine.
 Using Bayesian Model Averaging (BMA) we can average the estimators weighted
 by their respective risks:
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Technically, they are being weighted by the probability that each estimator
 is accurate given 
\begin_inset Formula $X$
\end_inset

.
\end_layout

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
reword this with 'Risk'
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
If that footnote is correct, it's odd that we need to normalize this.
 And if we don't need to normalize it, how do we account for a thousand
 estimators with decent confidence interval being combined?
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\Pr(x|X) & \approx\sum_{n}\Pr(x|\varphi^{n},X)\Pr(\varphi^{n}|X)\\
 & \approx\frac{1}{\sum_{n}1-R^{n}(\beta)}\sum_{n}\varphi^{n}(x:\ X^{n},D^{n})(1-R^{n}(\beta))\end{align*}

\end_inset


\end_layout

\begin_layout Section
Merging Estimators with Shared Dimensional Sets
\end_layout

\begin_layout Standard
This result allows us to create hybrid estimates based on a set of estimators
 regardless of the dimensional sets used by the estimators or the subsets
 of 
\begin_inset Formula $X$
\end_inset

 used by the estimators.
 We now consider a similar situation; combining the estimates of estimators
 in the case where the estimators share a dimensional set.
 In this context it is possible to to generate an estimator using the union
 of the observations from the two original estimators.
 This approach has a significant benefit over the BMA approach described
 above; it allows the hybrid estimator to generate estimates using the joint
 entropy of the observations, rather than the posterior probability of the
 marginal entropy of the two estimators.
 Practically speaking, this means that we can reduce the number of SV's
 required to make estimates with a given risk.
\end_layout

\begin_layout Standard
Given two estimators based on subsets 
\begin_inset Formula $X^{1}$
\end_inset

 and 
\begin_inset Formula $X^{2}$
\end_inset

, both defined over a dimensional set 
\begin_inset Formula $D$
\end_inset

, we cannot simply combine the two subsets 
\begin_inset Formula $X^{1}$
\end_inset

 and 
\begin_inset Formula $X^{2}$
\end_inset

; doing so could violate the i.i.d.
 requirement of the PW estimator.
 To demonstrate this, consider a situation in which both subsets are drawn
 randomly from 
\begin_inset Formula $X$
\end_inset

 within some bounds 
\begin_inset Formula $(a^{1},b^{1})$
\end_inset

 and 
\begin_inset Formula $(a^{2},b^{2})$
\end_inset

 defined along some dimension of 
\begin_inset Formula $D$
\end_inset

 (ie we draw 
\begin_inset Formula $n$
\end_inset

 observations from 
\begin_inset Formula $X$
\end_inset

 from a specific time window).
 Within the context of the bounds of each estimator the i.i.d.
 constraints are met, however combining these two sets will only produce
 i.i.d.
 data if 
\begin_inset Formula $a^{1}=a^{2},\ b^{1}=b^{2}$
\end_inset

.
 
\end_layout

\begin_layout Standard
Consider the requirement of i.i.d.
 data in PW estimators; the probability of a given point is determined by
 the sum of the kernel distance to each observation used by the estimator.
 More observations in a given region increases the probability estimate
 for any point near that region.
 Let us assume that the bounds of 
\begin_inset Formula $\varphi^{2}$
\end_inset

 are contained in and smaller than the bounds of 
\begin_inset Formula $\varphi^{1}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
a^{1} & <a^{2}\\
b^{1} & >b^{2}\\
|X^{1}| & =|X^{2}|\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In this case, a PW estimator would incorrectly generate elevated probability
 estimates in the region 
\begin_inset Formula $(a^{2},b^{2})$
\end_inset

 and lowered estimates in the compliment.
 We have already seen how SVM estimators achieve performance optimization
 by adjusting the weight 
\begin_inset Formula $\beta$
\end_inset

 given to each observation; we now propose a similar weighting mechanism
 
\begin_inset Formula $\rho(n)$
\end_inset

 which adjusts the influence of each point in the union of the two sets
 
\begin_inset Formula $X^{1}$
\end_inset

 and 
\begin_inset Formula $X^{2}$
\end_inset

 so that the estimates of a PW estimator based on the union of two i.i.d.
 data sets remain accurate estimates of the underlying PDF.
 
\end_layout

\begin_layout Standard
Given two estimators 
\begin_inset Formula $\varphi^{n}(x:\ X^{n},D^{i})$
\end_inset

 and 
\begin_inset Formula $\varphi^{m}(x:\ X^{m},D^{i})$
\end_inset

 which we wish to merge into a single estimator 
\begin_inset Formula $\varphi^{n,m}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi(x:\ X,D) & =\sum_{i=1}^{\ell}\frac{1}{\ell}K_{\gamma}(x,x_{i})\\
\varphi^{n,m}(x:\ X^{n}\cap X^{m}:D^{i}) & =\frac{\varphi^{n}(x:\ X^{n},D^{i})(1-R^{n}(\beta))+\varphi^{n}(x:\ X^{n},D^{i})(1-R^{m}(\beta))}{2-R^{n}(\beta)-R^{m}(\beta)}\\
 & =\frac{(1-R^{n}(\beta))}{2-R^{n}(\beta)-R^{m}(\beta)}\sum_{x_{i}\in X^{n}}\frac{1}{|X^{n}|}K_{\gamma}(x,x_{i})+\frac{(1-R^{m}(\beta))}{2-R^{n}(\beta)-R^{m}(\beta)}\sum_{x_{i}\in X^{m}}\frac{1}{|X^{m}|}K_{\gamma}(x,x_{i})\\
 & =\sum_{x_{i}\in X^{n}\cup X^{m}}\rho(x_{i}:\ \varphi^{n},\varphi^{m})\frac{1}{|X^{n}|+|X^{m}|}K_{\gamma}(x,x_{i})\\
\rho(x:\ \varphi^{n},\varphi^{m}) & =\begin{cases}
\frac{(1-R^{n}(\beta))}{|X^{n}|\left(2-R^{n}(\beta)-R^{m}(\beta)\right)} & \quad x\in X^{n},x\notin X^{m}\\
\frac{(1-R^{m}(\beta))}{|X^{m}|\left(2-R^{n}(\beta)-R^{m}(\beta)\right)} & \quad x\notin X^{n},x\in X^{m}\\
\frac{(1-R^{n}(\beta))}{|X^{n}|\left(2-R^{n}(\beta)-R^{m}(\beta)\right)}+\frac{(1-R^{m}(\beta))}{|X^{m}|\left(2-R^{n}(\beta)-R^{m}(\beta)\right)} & \quad x\in X^{n},x\in X^{m}\end{cases}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
This can be extended to SVM estimators:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi_{\beta}^{n,m}(x:\ X) & =\sum_{x_{i}\in X^{n}\cup X^{m}}\beta_{i}\rho(x:\ \varphi^{n},\varphi^{m})K_{\gamma}(x,x_{i})\\
W(\beta:\ X) & \longmapsto\min_{\beta}\sum_{\begin{array}{c}
x_{i}\in X^{n}\cup X^{m}\\
x_{j}\in X^{n}\cup X^{m}\\
x_{k}\in X^{n}\cup X^{m}\end{array}}\beta_{j}\beta_{k}\rho(x_{j}:\ \varphi^{n},\varphi^{m})\rho(x_{k}:\ \varphi^{n},\varphi^{m})K_{\gamma}(x_{i},x_{j})K_{\gamma}(x_{i},x_{k})\\
 & \qquad\qquad\qquad-\sum_{\begin{array}{c}
x_{i}\in X^{n}\cup X^{m}\\
x_{j}\in X^{n}\cup X^{m}\end{array}}\frac{2\beta_{j}}{\ell}\rho(x_{j}:\ \varphi^{n},\varphi^{m})K_{\gamma}(x_{i},x_{j})+\lambda\Omega(\beta,X^{n}\cup X^{m})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
I don't think the second term is correct - work this through the equations.
 Also make sure the second term only needs one kernel term (note in SV section)
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Note that both sets being combined must be i.i.d.; this means that single observati
ons in isolation cannot be added.
 The minimum number of points in a set required for the set to constitute
 i.i.d.
 data is determined by the number of dimensions in the dimensional set.
 The risk value 
\begin_inset Formula $R(\alpha)$
\end_inset

 is also a worst-case scenario rather than an exact measure; the more points
 in a given subset.
\begin_inset Note Note
status open

\begin_layout Plain Layout
?
\end_layout

\end_inset

 This can be accommodated by combining sets with sufficient observations
 that the contribution of the empirical risk is greater than the contribution
 of the growth function.
 In general terms, the more observations in the combined sets, the more
 accurate the weighting term 
\begin_inset Formula $\rho(\cdot)$
\end_inset

 will be.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Show a second iteration of this process
\end_layout

\end_inset


\end_layout

\begin_layout Section
Computational Considerations in Subset Selection
\end_layout

\begin_layout Standard
In general, computational demands will vary with different classes of estimators.
 TI estimators have far higher computational cost than point-based estimators.
 We assume that there exist more classes of estimators than are necessary
 to produce estimates with a given risk for a given set of observation,
 which leaves us with the task of selecting which estimators to apply to
 an estimation problem and how to assign observations to the selected estimators.
 To make these decisions, we develop a selection heuristic based on the
 costs and benefits of using a given estimator.
\end_layout

\begin_layout Standard
The basic approach we will describe is an iterative one; we first select
 an i.i.d.
 subset 
\begin_inset Formula $X'$
\end_inset

 of 
\begin_inset Formula $X$
\end_inset

, then add the subset to one or more estimators from the set of possible
 estimators based on some heuristic.
 At each iteration we update our selection heuristic based on the results
 of the previous addition of 
\begin_inset Formula $X'$
\end_inset

.
 This approach allows us to control both the set of estimators used and
 the observations assigned to each estimator; more importantly it allows
 us to do so based on the nature of the observations 
\begin_inset Formula $X'$
\end_inset

.
 We will show that it is possible to build a heuristic which requires no
 additional computation, allowing us to simultaneously build estimators
 and optimize subsequent iterations.
\end_layout

\begin_layout Standard
The simplest portion of the heuristic to define is the cost of using an
 estimator.
 The computational complexity of estimators can generally be determined
 
\emph on
a priori
\emph default
 as a function of the number and dimensionality of the observations used
 by the estimator.
 In some cases optimizations exist which are data-dependent; in these cases
 we will assume a worst-case scenario for additional observations.
 We define the cost function for a given estimator 
\begin_inset Formula $\varphi^{i}$
\end_inset

 as 
\begin_inset Formula $c(n,X^{i})$
\end_inset

 where 
\begin_inset Formula $n$
\end_inset

 denotes the number of observations which will be added and 
\begin_inset Formula $X^{i}$
\end_inset

 denotes the observations used by the estimator.
\end_layout

\begin_layout Standard
The benefit portion of the heuristic can be easily constructed from previous
 work.
 For any estimator, the utility of the estimator is described by the risk
 associated with the estimator.
 In generating estimates our primary goal is to produce accurate estimates,
 and the risk function 
\begin_inset Formula $R(\alpha)$
\end_inset

 describes the lowest possible accuracy of a given estimator.
 It is clear therefore that the utility of adding observations to an estimator
 is determined by the change in the expected risk as a result of adding
 observations; estimators which we expect to produce a high reduction in
 risk are preferred over estimators which we expect to produce a small reduction
 in risk.
 Recall that the maximal risk is determined by the number of observations
 used by the estimator, the empirical risk of the estimator, and the estimator's
 growth function; all three of these values are known for a given estimator
 without additional computation.
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
The empirical risk for an SVM estimator is the minimal value of the optimization
 problem.
 The empirical risk of a Parzen Estimator can be assumed to be 0.
\end_layout

\end_inset

 We can therefore define the benefit function for a given estimator as 
\begin_inset Formula $b(n,X^{i})$
\end_inset

 where 
\begin_inset Formula $n$
\end_inset

 denotes the number of observations which will be added and 
\begin_inset Formula $X^{i}$
\end_inset

 denotes the observations used by the estimator:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
b(n,X^{i}) & =R^{i}(\beta)-R^{i}(\beta_{n})\\
R^{i}(\beta_{n}) & =R_{\text{emp}}^{i}(\beta)+n+\frac{\Psi_{n}}{2}\left(1+\sqrt{1+\frac{4R_{\text{emp}}^{i}(\beta)+4n}{\Psi_{n}}}\right)\\
\Psi_{n} & =4\frac{G^{i}\left(2\left(|X^{i}|+n\right)\right)-\ln\left(\eta/4\right)}{|X^{i}|+n}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Mention the G^i notation
\end_layout

\end_inset


\end_layout

\begin_layout Standard
We can now define our heuristic 
\begin_inset Formula $h(n,X)$
\end_inset

 as the difference of the benefit and the cost, scaled by some parameter
 
\begin_inset Formula $\lambda$
\end_inset

 which controls the trade-off between accuracy and performance:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
h(n,X) & =b(n,X)-\lambda c(n,X)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset Formula $\frac{b}{c^{\lambda}}$
\end_inset

?
\end_layout

\end_inset


\end_layout

\begin_layout Section
Hierarchical Ensemble Estimators
\end_layout

\begin_layout Standard
The ensemble system presented above is formulated in the context of traditional
 point-based probability estimators (as opposed to set-based TI estimators).
 The equations also hold in the context of combining estimates from point-based
 and set-based estimators, in fact we can construct a system using multiple
 layers of hierarchical information - each level taking into account a larger
 set of observations.
 
\end_layout

\begin_layout Standard
Hierarchical systems allow us to implement data compression.
 While it is possible to compare all possible weighted subsets of a set
 of observations, in practice the computational demands of doing so quickly
 become prohibitive.
 Hierarchical systems allow us to break such an analysis into a set of simpler
 analysis, each of which implements a compression algorithm to eliminate
 redundant information.
 As a result, each layer in the hierarchy is able to operate in subset of
 the abstract space defined by the results of the lower layer.
\end_layout

\begin_layout Standard
Conceptually, our hierarchical system is defined at the lowest level by
 the vector observations 
\begin_inset Formula $X$
\end_inset

.
 Estimators defined in this hierarchical layer operate based on point-to-point
 comparisons, as is the case in standard SVM algorithms.
 The second layer within the hierarchy is defined by TI estimators; these
 estimators operate based on comparisons between different windows defined
 on 
\begin_inset Formula $X$
\end_inset

 by some windowing function 
\begin_inset Formula $\omega(\cdot)$
\end_inset

.
 The nature of the windowing function itself isn't important; the significant
 attribute of estimators in this layer are that they compare windows defined
 by 
\emph on
single points 
\emph default
and some windowing parameter 
\begin_inset Formula $\alpha$
\end_inset

.
 We can think of these two layers (the point-based and window-based estimators)
 as a pair; each operates based on points defined in 
\begin_inset Formula $X$
\end_inset

 - the distinguishing characteristic between them is that the former compares
 single points while the latter compares sets of points.
 To add additional layers to the hierarchy we introduce a new concept; abstract
 vectors.
 Abstract vectors allow us to compare subsets of 
\begin_inset Formula $X$
\end_inset

 using windows defined by 
\emph on
multiple 
\emph default
points.
\end_layout

\begin_layout Standard
We define an abstract vector (AV) as a representation 
\begin_inset Formula $y_{n}$
\end_inset

 of 
\begin_inset Formula $X$
\end_inset

 in some vicinity 
\begin_inset Formula $x_{n}$
\end_inset

 based on an estimator 
\begin_inset Formula $\varphi$
\end_inset

, which we assume to be an SVM estimator.
 The dimensionality of an AV is defined by the number of SV's in its estimator
 
\begin_inset Formula $\varphi$
\end_inset

; each SV is mapped to a single dimension in 
\begin_inset Formula $y_{n}$
\end_inset

.
 The value of a dimension mapped to a given SV 
\begin_inset Formula $x_{i}$
\end_inset

 is defined by the kernel distance between 
\begin_inset Formula $X$
\end_inset

 in the vicinity of 
\begin_inset Formula $x_{i}$
\end_inset

 and the SV 
\begin_inset Formula $x_{n}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
y_{n} & =[y_{n}^{1},...,y_{n}^{|X_{SV}|}]\\
X_{SV} & =[x_{i}:\ \beta_{i}>\epsilon]\\
y_{n}^{i} & =K(x_{n},x_{i})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We treat SV's in different estimators as orthonormal; each SV in each estimator
 is mapped to a unique dimension of an AV.
 Because we can treat AV's as sparse data-sets
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
A given AV can be represented by a pair of tuples defined by a SV index
 and a kernel distance.
 Since SV's are optimized to minimize overlap, we can assume that in most
 cases the number of SV's which are 
\begin_inset Formula $\epsilon$
\end_inset

-close to a given region of 
\begin_inset Formula $X$
\end_inset

 will be small.
 It is conceivable that large numbers of high-dimensional observations in
 
\begin_inset Formula $X$
\end_inset

 could be compressed to a single SV:K tuple.
\end_layout

\end_inset

 the conversion of observations from 
\begin_inset Formula $\Omega^{X}\rightarrow\Omega^{Y}$
\end_inset

 vastly reduces the computation demands of subsequent hierarchical layers.
 This process can be seen as developing optimal code-books for a given data-set
 and compressing observations using this code-book.
 The beauty of this approach is that lower layers not only provide optimal
 code-books for higher layers, the process of discovering the optimal code-book
 simultaneously allows the lower layer to generate estimates.
 
\end_layout

\begin_layout Standard
We can now elaborate the nature of the third and fourth layers of our hierarchy;
 given a set of AV's constructed from estimators in layers one and two,
 we construct a new random variable 
\begin_inset Formula $Y$
\end_inset

 and treat it in the same manner as we did 
\begin_inset Formula $X$
\end_inset

.
 In this sense the hierarchical system is both hierarchical and iterative;
 each layer pair defines a new random variable which becomes the data on
 which subsequent layers are built.
 Between each pair of layers, the SV's act as a "bridge" allowing us to
 translate patterns between layer pairs:
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
The regularizing term in this equation eliminates the requirement that the
 sum of an estimated AV's dimension be 1.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\Pr(x|\ y) & \approx\frac{1}{\sum_{i}y^{i}}\sum_{x_{i}\in X_{SV}}y^{i}K(x,x_{i})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In this way, estimates generated in higher layers can be integrated into
 the BMA estimator by translating them into the abstract space of 
\begin_inset Formula $X$
\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Part
Choice
\end_layout

\begin_layout Section*
Formal Setting: Choice
\end_layout

\begin_layout Standard
We assume that such a system influences 
\begin_inset Formula $\mathcal{P}$
\end_inset

 through actions which are discrete and quantifiable.
 Each action is therefore described as a vector 
\begin_inset Formula $\vec{a}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\vec{a}_{i} & =\left[a_{i}^{1},...,a_{i}^{\pi}\right]\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In order to correlate actions with changes in 
\begin_inset Formula $\mathcal{P}$
\end_inset

, we treat each action as an observation of 
\begin_inset Formula $X$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
X & =(\Omega,\mathcal{F},\mathcal{P})\\
\Omega & \in\mathbb{R}^{d+\pi}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In this case, our observations are of dimension 
\begin_inset Formula $d+\pi$
\end_inset

, the first 
\begin_inset Formula $d$
\end_inset

 dimensions describe the system's 'environment' and the last 
\begin_inset Formula $\pi$
\end_inset

 describe the system's "actions".
 
\end_layout

\begin_layout Standard
In order to choose between possible actions, the system must prefer certain
 states of the input space 
\begin_inset Formula $\Omega$
\end_inset

 over others.
 We describe these preferred states as the system's using a function 
\begin_inset Formula $m_{\theta}(x)$
\end_inset

 we'll refer to as the motivator with control parameter 
\begin_inset Formula $\theta$
\end_inset

.
 For a given dimension of 
\begin_inset Formula $\Omega$
\end_inset

, the motivator function returns a positive real value describing the system's
 preference for the state 
\begin_inset Formula $x^{i}$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
m_{\theta}(x^{i}) & \in\mathbb{R}\\
m_{\theta}(x^{i})>0 & \longmapsto\text{preferred state}\\
m_{\theta}(x^{i})<0 & \longmapsto\text{discouraged state}\\
m_{\theta}(x^{i})=0 & \longmapsto\text{no preference}\end{align*}

\end_inset


\end_layout

\begin_layout Chapter
Prediction and Conditional Prediction
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
OK, thinking through prediction without variates.
 The reason prediction isn't simple is that TI estimators are context sensitive,
 so the result of a prediction task can invfluence the result of a second
 prediction task.
 Thus far we've handled this by generating sets of points, and using them
 as the conditional inputs to the next iteration - in order for this to
 work without variates we would need to generate a full probability field
 (rather than simply a set of points) and then use that field to determine
 the next iterative step.
 
\end_layout

\begin_layout Plain Layout
So the first question is if the probability field is the same as the random
 variates.
 Let's assume we're at the first iteration of the process.
 In this case, the field will be identical - the field is generated relative
 to the observations, so as the number of variates increases it will converge
 on the field.
 We can use the same process we would have used in generating random variates
 to generate the resulting field.
 The random deviates are drawn from the SV's based on the probability of
 the SV (in the case of TI estimators, we also use a random transformation).
 Because of that transformation step, the probabilities of the SV's *must*
 be paired with the set generating them.
 The probability of an SV is determined by the conditional probability of
 the SV, given X.
\end_layout

\begin_layout Plain Layout
So let's assume now that we're moving to the second iterative step.
 In this case, we're evaluating the probability of each SV based on the
 generated field, and again adding random transformations.
 In this case the probability of an SV is determined by the conditional
 probability given the previous field (which is conditional on the original
 observations).
 In this case we again can't divorce the prediction from the previous prediction
, due to the TI estimators.
 OK, so let's see if we can formalize this
\end_layout

\begin_layout Plain Layout
\begin_inset Formula \begin{align*}
\Pr(\rho_{n}^{i}|\rho_{n-1}) & =\frac{\Pr(\rho_{n}^{i}\cup\rho_{n-1})}{\Pr(\rho_{n-1})}\\
\Pr(\rho_{1}) & =\bigcap_{i}\Pr(\rho_{1}^{i}|X)\\
\Pr(\rho_{1}^{i}) & =\Pr(SV_{i}|X)\\
 & =\bigcap_{x\in SV_{i}}\Pr(x)\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
OK, here lies the problem.
 We're working on determining the probability of a given rho value given
 the past one - even if we can determine this probability, we still are
 left with the problem of selecting a new value of rho.
 This is the non-linear optimization problem we've been having.
 The new value needs to be the probability of an SV given a field! Let's
 use the following notation to denote that field
\end_layout

\begin_layout Plain Layout
OK, we *have* to start with conditional sets, otherwise rho will equal beta.
 Treat these as testing observations.
 So the first iterative step is the same; determine rho based on the testing
 set (and the training set).
\end_layout

\begin_layout Plain Layout
\begin_inset Formula \begin{align*}
\varphi^{1}(x) & =\Pr(x|X)\\
 & =\sum_{i=1}^{\ell}\frac{1}{\ell}K(x,x_{i})\\
\rho_{i}^{1} & =\Pr(w_{i}|X)\\
 & =\varphi^{1}(w_{i})\\
\phi(\rho^{1}) & =?\\
\varphi^{2}(x) & =\Pr(x|\phi(\rho))\\
\varphi^{2}(x) & =\Pr(x|\varphi^{i-1})\\
\\\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Here's the challenge, how do we pivot from probability estimates to conditional
 values?
\end_layout

\begin_layout Plain Layout
If this is going to work, you need to establish a set of equivalent equations
 between what's already developed and rho sets.
 Probability fields are *not* the same as a set of observations.
 The PDF of the set of equations might match, but there is a significant
 difference.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Let's think about this from the other end.
 The basic goal is to explore sets of actions to find an action set which
 will maximize the expected reward for the system.
 We can also state that an action set is defined as a set of rho values
 and a conditional set (possibly X as the conditional set, but probably
 a previous iteration, as the result of a rho value will be different for
 different contexts).
 This means we can formulate our objective as an optimization task 
\begin_inset Formula $W(\rho)$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Formula \begin{align*}
W(\rho) & =\max_{\rho}E(r(\phi(\rho,\phi)))\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
where 
\begin_inset Formula $\phi(\rho,\phi)$
\end_inset

 is the action set given 
\begin_inset Formula $\rho$
\end_inset

 and a conditional set 
\begin_inset Formula $\phi$
\end_inset

, and 
\begin_inset Formula $r(\cdot)$
\end_inset

 is some reward function.
 This function likely needs constraints, namely that 
\begin_inset Formula $\rho$
\end_inset

 have some meaning.
\end_layout

\begin_layout Plain Layout
Let's try to get a better handle on these terms.
 We'll start by defining an action set (this is a little misleading - the
 action set contains non-action values as well) as 
\begin_inset Formula $\phi$
\end_inset

.
 In this context, the optimization problem is to determine the action set
 with the highest expected reward
\end_layout

\begin_layout Plain Layout
\begin_inset Formula \begin{align*}
W(\phi) & =\max_{\phi}E(r(\phi))\\
 & =\max_{\phi}\Pr(\phi)r(\phi)\\
 & =\max_{\phi}\varphi(\phi)r(\phi)\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
So, the question is how we control (and as a result, define) 
\begin_inset Formula $\phi$
\end_inset

.
 We can treat a probability field as the underlying field plus one dimension
 (each point's probability), so it should be possible to treat a probability
 field *as* an action set.
 Let's assume this will work, and treat 
\begin_inset Formula $\phi$
\end_inset

 as a PDF.
 Before we go and define how the PDF is determined, let's establish the
 two functions above
\end_layout

\begin_layout Plain Layout
\begin_inset Formula \begin{align*}
\varphi(\phi) & =1-\int_{\Omega}\|\varphi(x),\phi(x)\|dx\end{align*}

\end_inset

 In other words, we'll treat the probability of a field given 
\begin_inset Formula $\varphi$
\end_inset

 as the divergence between them.
 If they are completely convergent, the probability will be one, if they
 are completely divergent the probability will be 0.
 We can leave the reward function undefined, but assume that it is the integral
 over possible values
\end_layout

\begin_layout Plain Layout
\begin_inset Formula \begin{align*}
r(\phi) & =\int_{\Omega}\phi(x)r(x)dx\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
OK, so now we need to develop the actual PDF definition.
 I think we can restrict our attention to a combination of transformed previous
 observations.
 We have a couple options here, we could select transforms and observations
 and start building sets.
 
\end_layout

\begin_layout Plain Layout
One option would be to do this iteratively; we select an observation (somehow)
 then optimize the transform based on the above optimization problem.
 This could be repeated until the optimization problem stabalized.
 We could potentially also cull selections from the active set - possibly
 removing the least useful one once we've reached some threshold defined
 by the computational resources allocated to the search.
\end_layout

\begin_layout Plain Layout
This is an interesting approach, as it allows us to operate over a set of
 SV/transform pairs.
 These pairs would uniquely define an action set (no need for recursive
 references to previous iterations or whatever).
\end_layout

\begin_layout Plain Layout
We could refine this further if it were possible to encode arbitrary transforms
 into a single matrix.
 I doubt that's possible though.
 Maybe a better approach would be to maintain a set of transforms for each
 observation, and add/remove transforms as the optimization problem.
 
\end_layout

\begin_layout Plain Layout
Earlier, we had been working off of 
\begin_inset Formula $\rho$
\end_inset

.
 In this case I think it's redundant; rather than specifying the influence
 of a given SV, we simply allow it to be transformed in the same way multiple
 times.
 
\end_layout

\begin_layout Plain Layout
OK, so just to play this out, well call a given affine transform 
\begin_inset Formula $a=(n,\mathbf{A},\mathbf{b})$
\end_inset

, and the set of transforms which define an action set as 
\begin_inset Formula $A$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Formula \begin{align*}
\phi_{A}(x) & =\sum_{i=1}^{|A|}\frac{1}{|A|}K_{\gamma}(x,\mathbf{A}_{i}x_{n_{i}}+\mathbf{b}_{i})\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
This allows us to reduce our optimization task to an iterative one in which
 each step finds the otimal value for a single transform given the a set
 of transforms
\end_layout

\begin_layout Plain Layout
\begin_inset Formula \begin{align*}
W(a:\ A) & =\max_{a}\varphi(\phi_{a\cup A})r(\phi_{a\cup A})\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
We can make this even simpler by specifying beforehand how many transforms
 we want, then optimizing over that many terms
\end_layout

\begin_layout Plain Layout
\begin_inset Formula \begin{align*}
W(A) & =\max_{A}\varphi(\phi_{A})r(\phi_{A})\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
I think the existing approach can be seen as a naive method of implementing
 this optimization.
 I seriously doubt that selecting a transform is convex - multiple transforms
 could provide the same reward.
 In any case, I think having a solid foundation for what we're trying to
 do is helpful.
\end_layout

\begin_layout Plain Layout

\lyxline

\end_layout

\begin_layout Plain Layout
This is a huge fucking mess.
 I'm not sure how we evaluate the probability of a set.
 Let's go back to the actual set thing.
 We need to evaluate the joint probability of the points in the set.
 OK, give a set of points X, we can break this down into a sequence of joint
 probabilities.
 First, we define a subset of X which is the first n elements of X
\end_layout

\begin_layout Plain Layout
\begin_inset Formula \begin{align*}
X_{n} & =[x_{i}\in X,\ i<n]\\
X_{n+1} & =X_{n}\cup x_{n+1}\\
X_{0} & =\emptyset\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Now, let's start trying to evaluate the probability of the set X.
 We first break out one element of X and determine the joint probability
 of the element and the rest of X
\end_layout

\begin_layout Plain Layout
\begin_inset Formula \begin{align*}
\varphi(X) & =\varphi(x_{\ell}\cap X_{\ell-1})\\
 & =\varphi(x_{\ell}|X_{\ell-1})\varphi(X_{\ell-1})\\
 & =\varphi(x_{\ell}|X_{\ell-1})\varphi(x_{\ell-2}|X_{\ell-2})\varphi(X_{\ell-2})\\
 & \vdots\\
 & =\prod_{n=1}^{\ell}\varphi(x_{n}|X_{n-1})\\
\varphi(x|\emptyset) & =\varphi(x)\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Now, the reason this is good is that we can evaluate the conditional probability
 of a point given a set of observations using the regular old Parzen Estimator
 - right? I mean, I'm pretty sure that the parzen estimator of x given X
 can be expressed as 
\end_layout

\begin_layout Plain Layout
\begin_inset Formula \begin{align*}
\varphi_{X}(x) & =\varphi(x|X)\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
This trick will only work in the discrete case.
 Turning this into an integral doesn't make any sense.
 *But* our field is determined by a set of points - it may not be necessary.
 Let's expand that bit above
\end_layout

\begin_layout Plain Layout
\begin_inset Formula \begin{align*}
\varphi_{X}(\bar{X}) & =\prod_{n=1}^{\bar{\ell}}\varphi_{X}(x_{n}|\bar{X}_{n-1})\\
 & =\prod_{n=1}^{\bar{\ell}}\varphi_{X\cup\bar{X}_{n-1}}(x_{n})\\
 & =\prod_{n=1}^{\bar{\ell}}\sum_{i=1}^{\ell+n}\frac{1}{\ell}K(x_{n},x_{i})\\
 & =\left(\sum_{i=1}^{\ell+1}K(x_{1},x_{i})\right)\prod_{n=2}^{\bar{\ell}}\sum_{i=1}^{\ell+n}\frac{1}{\ell}K(x_{n},x_{i})\\
 & =\left(K(x_{1},x_{\ell+1})\varphi_{X}(x_{1})\right)\prod_{n=2}^{\bar{\ell}}\sum_{i=1}^{\ell+n}\frac{1}{\ell}K(x_{n},x_{i})\\
 & =\left(K(x_{1},x_{\ell+1})+\varphi_{X}(x_{1})\right)\left(\sum_{i=1}^{\ell+2}K(x_{2},x_{i})\right)\prod_{n=3}^{\bar{\ell}}\sum_{i=1}^{\ell+n}\frac{1}{\ell}K(x_{n},x_{i})\\
 & =\left(K(x_{1},x_{\ell+1})+\varphi_{X}(x_{1})\right)\left(K(x_{2},x_{\ell+1})+K(x_{2},x_{\ell+2})+\varphi_{X}(x_{2})\right)\prod_{n=3}^{\bar{\ell}}\sum_{i=1}^{\ell+n}\frac{1}{\ell}K(x_{n},x_{i})\\
 & \vdots\\
 & =\prod_{n=1}^{\bar{\ell}}\left(\varphi_{X}(\bar{x}_{n})+\varphi_{\bar{X}_{n}}(\bar{x}_{n})\right)\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
OK, so we know that we can determine the probability of a field if it's
 generated by points.
\end_layout

\begin_layout Plain Layout
Another interesting bit is that we can add a single optimal point my optimizing
 those two terms 
\begin_inset Formula $\varphi_{X}(\bar{x})+\varphi_{\bar{X}}(\bar{x})$
\end_inset

.
 This should work both ways - we should be able to add a point this way
 as well as do a leave-one-out- analysis of the weakest point and remove
 it.
 We could proably do this in parallel; take each point and see if a better
 point can be found (given the rest of the points) then use all those points.
 Maybe not actually, the problem is that we'd be completely changing the
 context, and there's no guarantee that the new context will be 'better'
 than the old one, since the relationships *between* the new contexts hasn't
 been established.
\end_layout

\begin_layout Plain Layout
Let's think about adding a new point.
 Again, the point needs to be both a SV and a transform.
 We can get a rough idea how well each SV will work by doing the integral
 over all transforms, but this might prefer points with a low broad similarity
 over points with a single peak - in this case we'd prefer to peak to any
 of the points in the broad spectrum.
 Maybe this is where uncertainty comes in - if we could evaluate both the
 average similarity *and* the uncertainty of the similarity, we could combine
 them somehow.
 Is this possible?
\end_layout

\begin_layout Plain Layout
We can certainly determine the uncertainty if we restrict the search to
 transformations defined by points - just take the sum of plogp.
 But - can we take the integral of this over transformations?
\end_layout

\begin_layout Plain Layout
\begin_inset Formula \begin{align*}
H(\varphi) & =\int\varphi(x^{T})\log\varphi(x^{T})dT\\
 & =\int\left(\sum_{i=1}^{\ell}\beta_{i}K(x,x_{i}^{T})\right)\log\left(\sum_{i=1}^{\ell}\beta_{i}K(x,x_{i}^{T})\right)dT\\
 & =\int\left(\sum_{i=1}^{\ell}\beta_{i}e^{-\frac{1}{\gamma}\|x,x_{i}^{T}\|}\right)\log\left(\sum_{i=1}^{\ell}\beta_{i}e^{-\frac{1}{\gamma}\|x,x_{i}^{T}\|}\right)dT\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Returning to the definition of entropy
\end_layout

\begin_layout Plain Layout
\begin_inset Formula \begin{align*}
H(X) & =E(I(X))\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Where I is the self-information of X.
 The conversion to the probability assumes that we're dealing with points
 in the domain - we can probably restrict this by using randomly chosed
 transform values (this would we could use a subset of possible values to
 make things a little less demanding computationally).
 In this case, we simply divide by the number of samples
\end_layout

\begin_layout Plain Layout
\begin_inset Formula \begin{align*}
H(X) & =\frac{1}{n}\sum_{i=1}^{n}I(x_{n})\\
 & =\sum_{i=1}^{n}\log(\varphi(x_{n}))\\
 & =\frac{1}{n}\log\left(\prod_{i=1}^{n}\varphi(x_{n})\right)\\
 & =\frac{1}{n}\log\left(\prod_{i=1}^{n}\sum_{j=1}^{\ell}\beta_{j}K(x_{i},x_{j})\right)\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Yeah, this doesn't really get us anywhere.
\end_layout

\begin_layout Plain Layout
We need to develop heuristics again.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
OK, working off that last set of equations to describe the probability of
 a set.
 Let's think about a different approach - we forget the SV's and transforms
 and all that, we simply select points.
 We can caluclate the impact of each point in the set, which allows us to
 update the expected reward with each addition.
 We also know easily which points to remove.
 If we re-frame this as point selection, instead of choosing an SV and a
 transformation set (d^2+d+1) we just select a point (d).
 not only that, but we can probably define a rigorous heuristic for selecting
 points.
\end_layout

\begin_layout Plain Layout
Given a set of points 
\begin_inset Formula $\bar{X}$
\end_inset

, our task is to select a new point.
 We know that the revised probability of the set will be the previous probabilit
y times the probability given X plus the probability given 
\begin_inset Formula $\bar{X}$
\end_inset

, and that the revised reward will be the point's kernel distance to each
 SV times the SV's reward (I think).
 Here's where I think we can generate a heuristic; it may be possible to
 generate a PDF which describes the probability of any point.
 Given this PDF, we can generate random deviates.
 But we can also scale the random deviate weights by the reward of each
 SV.
 This means that we'll easily generate a random point, weighted towards
 high expected reward.
 We also want to generate points which are novel, so we can probably take
 the probability of points given 
\begin_inset Formula $X\cup\bar{X}$
\end_inset

 and subtract from it the probability of points given 
\begin_inset Formula $\bar{X}$
\end_inset

.
 I don't think this will simply produce the probability of 
\begin_inset Formula $X$
\end_inset

, but I might be wrong.
 
\end_layout

\begin_layout Plain Layout
In any case, *if* this works, it seems like the ideal method of doing all
 this.
 It probably won't parallelize very well, but we could always execute multiple
 parallel searches in the same vein.
 OK, so let's try to formalize this from the start.
\end_layout

\begin_layout Plain Layout
We begin by establishing the probability of a prediction 
\begin_inset Formula $\bar{X}$
\end_inset

 with 
\begin_inset Formula $\bar{\ell}$
\end_inset

 elements, given the PDF of 
\begin_inset Formula $X$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Formula \begin{align*}
X_{n} & =[x_{i}\in X,\ i>n]\\
X_{n+1} & =X_{n}\cup x_{n+1}\\
X_{0} & =\emptyset\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Formula \begin{align*}
\varphi_{X}(\bar{X}) & =\varphi_{X}(\bar{x}_{1}\cap\bar{X}_{\bar{\ell}-1})\\
 & =\varphi_{X}(\bar{x}_{1}|\bar{X}_{\bar{\ell}-1})\varphi_{X}(\bar{X}_{\bar{\ell}-1})\\
 & =\varphi_{X}(\bar{x}_{1}|\bar{X}_{\bar{\ell}-1})\varphi(\bar{x}_{2}|\bar{X}_{\ell-2})\varphi(\bar{X}_{\ell-2})\\
 & \vdots\\
 & =\prod_{n=1}^{\ell}\varphi(\bar{x}_{n}|\bar{X}_{n-1})\\
\varphi(\bar{x}|\emptyset) & =\varphi(\bar{x})\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
We can define the estimate of 
\begin_inset Formula $x$
\end_inset

 generate from the set of observations 
\begin_inset Formula $X$
\end_inset

 as the conditional probability 
\begin_inset Formula $\Pr(x|X)$
\end_inset

.
 In this case, we simply treat 
\begin_inset Formula $X$
\end_inset

 as the union of the observations which constitute it.
 We can therefore add the observations in a given 
\begin_inset Formula $\bar{X}_{n}$
\end_inset

 to produce 
\begin_inset Formula $\varphi_{X}(\bar{x}|\bar{X}_{n})$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Formula \begin{align*}
\varphi_{X}(x) & =\varphi(x|X)\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Formula \begin{align*}
\varphi_{X}(\bar{X}) & =\prod_{n=1}^{\bar{\ell}}\varphi_{X}(\bar{x}_{n}|\bar{X}_{n-1})\\
 & =\prod_{n=1}^{\bar{\ell}}\varphi_{X\cup\bar{X}_{n-1}}(\bar{x}_{n})\\
 & =\prod_{n=1}^{\bar{\ell}}\left(\left(\sum_{i=1}^{\ell}\frac{1}{1+n}\beta_{i}K(\bar{x}_{n},x_{i})\right)+\left(\sum_{i=1}^{n}\frac{1}{\ell+n}K(\bar{x}_{n},\bar{x}_{i})\right)\right)\\
 & =\prod_{n=1}^{\bar{\ell}}(1+n)\varphi_{X}(\bar{x}_{n})+\left(1+\ell\right)\varphi_{\bar{X}_{n-1}}(\bar{x}_{n})\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
We can extend this to a set-conditional PDF by iterating
\end_layout

\begin_layout Plain Layout
\begin_inset Formula \begin{align*}
\varphi_{X}(x|\bar{X}) & =\left((1+\bar{\ell})\varphi_{X}(\bar{X})\varphi_{X}(x)\right)+\left(\left(1+\ell\right)\varphi_{X}(\bar{X})\varphi_{\bar{X}}(x)\right)\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
The PDF above describes the probability of a point given the estimate.
 Using this as the determinant of 
\begin_inset Formula $\rho$
\end_inset

 allows us to generate random devaites from the previous PDF.
 To control the novelty of deviates, we can subtract the PDF 
\begin_inset Formula $\varphi_{\bar{X}}(x)$
\end_inset

 from the PDF 
\begin_inset Formula $\varphi_{X}(\bar{X})$
\end_inset

 to generate the novel PDF 
\begin_inset Formula $\varphi_{N}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Formula \begin{align*}
\varphi_{N}(x) & =\varphi_{X}(x|\bar{X})-\lambda\varphi_{\bar{X}}(x)\\
 & =(1+\bar{\ell})\varphi_{X}(\bar{X})\varphi_{X}(x)+\left(1+\ell\right)\varphi_{X}(\bar{X})\varphi_{\bar{X}}(x)-\lambda\varphi_{\bar{X}}(x)\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Similarly, we can select points to remove from the estimate by examining
 the difference between the set and the set without the point
\end_layout

\begin_layout Plain Layout
\begin_inset Formula \begin{align*}
\triangle x & =\varphi_{X}(\bar{X})-\varphi_{X}(\bar{X}\vee x)\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
In this case, the first term will be constant, so we can reduce the difference
 to the second term
\end_layout

\begin_layout Plain Layout
\begin_inset Formula \begin{align*}
\triangle x & =\varphi_{X}(\bar{X}\vee x)\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
If we treat 
\begin_inset Formula $x$
\end_inset

 as the last term in the series, this is a fairly trivial modification
\end_layout

\begin_layout Plain Layout
\begin_inset Formula \begin{align*}
\varphi_{X}(\bar{X}\vee x) & =\prod_{n=1}^{\bar{\ell}-1}(1+n)\varphi_{X}(\bar{x}_{n})+\left(1+\ell\right)\varphi_{\bar{X}_{n-1}}(\bar{x}_{n})\\
 & =\frac{\varphi_{X}(\bar{X})}{(1+\bar{\ell})\varphi_{X}(x)+\left(1+\ell\right)\varphi_{\bar{X}\vee x}(x)}\\
 & =\frac{\varphi_{X}(\bar{X})}{(1+\bar{\ell})\varphi_{X}(x)+\left(1+\ell\right)\left(\varphi_{\bar{X}}(x)-\frac{1}{\bar{\ell}}K(x,x)\right)}\\
 & =\frac{\varphi_{X}(\bar{X})}{(1+\bar{\ell})\varphi_{X}(x)+\left(1+\ell\right)\left(\varphi_{\bar{X}}(x)-\frac{1}{\bar{\ell}}\right)}\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
In the motivated case, we can compare the delta reward
\end_layout

\begin_layout Plain Layout
\begin_inset Formula \begin{align*}
\triangle x\ r(x)\end{align*}

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
I think that takes care of choice - the utility and uncertainty heuristics
 developed earlier can be applied directly, and this is a much cleaner version
 of the algorithm
\end_layout

\begin_layout Plain Layout
What' I'm worried about now is the TI prediction approach.
 I had been picking randomly from the TI SV's weighted probability space,
 then transforming randomly given two transform sets.
 The problem with this approach is that all possible transform sets do not
 contribute equally to the probability of a TI SV being expressed in a probabili
ty measure; for this to work we must select transform sets weighted by the
 probability of the associated affine transformation.
\end_layout

\begin_layout Plain Layout
I doubt this can be determined analytically.
 It may be possible to run each integration backwards one at a time using
 random variables for each, but I'm not sure if this would produce the same
 result as running the whole thing backwards.
 The problem with doing it all at once is that each element of the transform
 matrices become independant variables, but we only have one target value;
 so you have a system of hundreds of equations and 1 known.
 If we can reverse the integration 1 element at a time, this may be preferable.
 
\end_layout

\begin_layout Plain Layout
The other possibility is randomly selecting weighted point pairs.
 Imagine we take all the points and throw them randomly in a circle (their
 radial measure determined by their probability) and flicked a wheel-of-fortune
 type selector.
 The probability of selecting a given point won't depend on the order of
 the points, so long as the probability of selecting any point on the circle
 is uniform.
 What this means, is we can select a number from 0-1, then start evaluating
 randomly selected transform points.
 Each time, the probability of the selected point gets added to a running
 sum, when a point pushes the running sum over the random number, we select
 that point.
\end_layout

\begin_layout Plain Layout
Now, I don't like this method - if we're dealing with hundreds of thousands
 of prediction points, we're going to have to sum half of them (on average)
 each time we generate a new point.
 If we can do an element-wise reversal that would reduce the computation
 to the size of the TI set, potentially a much smaller amount.
 Both these methods might be worth mentioning though...
\end_layout

\begin_layout Plain Layout
Polar coordinates?
\end_layout

\begin_layout Plain Layout
OK, thinking about reversing that integration.
 The problem is that we have a lot of variables to solve for but just one
 value, so what if we selected random values for each integrand? It may
 be possible to back them out one at a time, but we'll have to peel it like
 an onion, and each random value will have to be relevant to the layer -
 I think we'll need to choose from 0-1 for the first layer, but then choose
 from 0-? for the second.
 Maybe.
 The only reason this *might* work is that each step of the integration
 *may* be reversable by itself.
 If it works, it's going to need a computer to crunch the system of equations,
 and they're going to be fucking messy.
 Maybe there are other ways of handling the TI distance in general.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Thinking more about the prediction problem.
 I think we've developed four potential methods to select points
\end_layout

\begin_layout Enumerate
If the PDF of the distribution is integrable for x, we can use a bisection
 search to find points in the PDF with a given probability.
 For multidimensional PDF's this can be done one dimension at a time, using
 the conditional probability of previous selections.
 The PDF may or may not be integrable, but I'm afraid it isn't.
 Ideally, we would use the expected reward instead and bisect that distribution
\end_layout

\begin_layout Enumerate
If the PDF isn't integrable, we can still use the bisection search to find
 probable transformations.
 In this case, we return the the SV variate model and use the bisection
 search to determine the transformation
\end_layout

\begin_layout Enumerate
The lattice diffusion method still seems promising.
 This could be done in two ways; we could either use point probability values
 as the pressure or we could use integral values.
 One nice thing about the integral method is that it allows iterative refinement.
 I'm not sure if the point method would be work with the refinement bit
 - my guess is it wouldn't.
 Using the point method, I think we can either use a lattice or the points
 in the estimate; if we have to use a lot of points for the resolution to
 be acceptable, it's probable that using actual estimates will produce better
 results than a regular lattice - they capture the most information about
 the distribution for a given set of points.
 Another way to think about this is that if we use the points, we want to
 equalize the area between adjacent points, which means that we should be
 able to select an interstitial area weighted by it's area.
 This would require determining an adjacency matrix.
 There exist algorithms for the Delaunay triangulation with O(n log n) performan
ce, and they work by adding points one at a time, which would work well
 in our context (the time for adding a single point is O(log n) ).
 Apparently, these algorithms don't scale well with dimensionality though
 (exponential)
\end_layout

\begin_layout Enumerate
Since the scope of windows is limited by the windowing function, I think
 we can assume that points within the window width of high-value points
 have a higher probability of being high-value than random points.
 We can probably allow an existing set to bleed into adjacent areas.
 In this case we'd be selecting partially at random, and would have to expect
 than many of the generated points would need to be eliminated.
\end_layout

\begin_layout Plain Layout
An interesting way to visualize this is to imagine a 3d triangulated plane
 whose vertices are scattered randomly on the horizontal.
 The height of each vertex is an expected reward value.
 The goal is to refine the plane so that the resolution is biased towards
 the peaks.
 This idea clarifies the utility of option (4) - once we find a peak we
 expand it outward to determine where it starts to fall off.
 Option (1) allows us to randomly select peakish values, as does (2) - in
 a roundabout way.
 How can we think of the lattice diffusion method? The problem with lattice
 is that if we're just guessing at points, diffusion doesn't tell us anything
 the points don't.
 So we only really need to care about it if it's integrable, in which case
 the bisection method describes the lattice approach.
 So screw the lattices.
\end_layout

\begin_layout Plain Layout
Let's think some more about the creep approach.
 Given a point with high expected reward, we can assume that nearby points
 will also have high expected reward (possibly higher).
 There is utility in exploring the neighborhoods of such points.
 This gets complex when we consider that our prediction set is being culled
 of points with low expected reward; in this context we can't know if a
 neighborhood has already been explored and then eliminated (in which case
 there's no point in exploring it again) or if it constitutes a truly unknown
 portion of the search space.
 What would be nice is to have some measure of the uncertainty of a point
 as well as it's nearness to points with high expected reward.
 We can probably determine this, however it leaves us with another field
 to be explored - a better approach would be to start with points already
 in the prediction, then work our way out.
 In this case, we'd be estimating the uncertainty of adjacent areas.
 We don't, for example, want to explore the neighborhood of points which
 are embedded in well-known areas.
\end_layout

\begin_layout Plain Layout
We can start approaching this problem by defining the prediction density
 in the neighborhood of points.
 Points with lower density and high expected return should be investigated
 first.
 This allows us to avoid examining well understood areas, but we're still
 left with the culling problem.
 I think the simple solution here is to incorporate this into the culling
 heuristic; we need to eliminate points which are both low in expected reward
 and in areas of low density.
 This would allow us to retain the low-reward perimeter of high-reward areas.
 Doing so would increase the density of high-reward points, reducing the
 probability of checking nearby points, but ideally we could still make
 selections based on the high-reward points.
 
\end_layout

\begin_layout Plain Layout
Another benefit of the density approach is that it would tend to set an
 upper bound on the density of predictions.
 In this sense, the distribution of the prediction wouldn't match the density
 of the expected return field, but it *would* give us a decent approximation
 of that field.
 The important bit is that we can't treat the prediction set as a density.
 Another interesting bit is that in this context, it's not really useful
 to retain lots of points which provide redundant information; it would
 be useful to remove points which have lower than average uncertainty.
 So our culling algorithm needs to take three things into account; the expected
 reward of an estimate (higher is better), the adjacency to points with
 high reward (closer is better), and the uncertainty of the point (higher
 is better).
 This gives us two control variables for culling; one that controls the
 perimeter width and one that controls the average density of the prediction.
\end_layout

\begin_layout Plain Layout
Moving back to the prediction-not densities thing, I think in order to determine
 the expected reward distribution of a prediction, we need to use the regression
 of the prediction set.
 In other words, the expected reward at a given point is the weighted average
 of the prediction point's expected reward in that neighborhood.
 We could also use the actual expected return equation, but using the regression
 give us a faster computation (if the set of predictions is smaller than
 the set of SV's).
\end_layout

\begin_layout Plain Layout
OK, let's think briefly about how we choose an action to take.
 I still think the best option here is to use regression for the action
 dimensions.
 This means we need to have a uni-modal expected reward distribution at
 the time of action selection.
 In order to do this, we need to cull points which are outside the dominant
 'peak'.
 I think we can do this by establishing what I'll call the indecision metric
 (to distinguish it from the uncertainty of a point).
 The indecision metric is calculated at a given point in time for the action
 dimensions (only).
 It's calculated as the entropy, which is essentially lateral inhibition.
 We'll need to be careful to restrict indecision culling to times that are
 imminent, otherwise we end up biasing the prediction.
 Maybe this isn't such a problem really - we're only enforcing the ability
 to execute a coherent set of actions; any 'plan' which would require doing
 two things at once probably should be eliminated.
 Regardless, I think it's a bad idea to do this for all predictions.
 maybe we make this a meta-variable and let the sytem decide what to do.
 I think this is a good idea, it allows indecision to be controlled contextually.
 For example, if you commit to doing something, you're forced to make a
 decision you wouldn't otherwise have had to make at that point in time.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
OK, stepping way back to consider the basic system architecture.
 So far I've been assuming that prediction and memory are two discrete system
 facets.
 This assumption was made in order to allow the 'prediction' portion of
 the system to take different states as options were explored.
 In other words, in order to make a plan from multiple possibilities, you
 must be able to consider each possibility in isolation.
 This implies some type of quickly-changing exploration space.
\end_layout

\begin_layout Plain Layout
The problem with this is that if you have a quickly-changing prediction
 space with no inherent memory, task switching become difficult (specifically,
 switching to a previous task).
 This also seems odd in the context of remembering previous though processes.
 In the current architecture, the system would 'remember' actions which
 were taken, but not necessarily the planning which led to those actions.
 This is clearly at odds with human experience, and it makes sense that
 the planning would be remembered - it reduces the search necessary when
 a similar planning task is encountered.
 
\end_layout

\begin_layout Plain Layout
So, here's the proposition; predictions are treated the exact same way observati
ons are treated.
 This means that the SV optimization recieves prediction directly.
 There is no architectural distinction between a prediction and an observation.
 Any 'culling' of predictions must take place by the SV optimization procedure.
 The system has two processes; one which generates estimates, and one which
 generates predictions.
 No retained set of predictions.
 No removal rules.
 No elimination of indecision points.
 In this case, changing state between plans is done by modifying the SV
 multiplier.
 The benefit of this is that (if it's possible to change the multipliers
 in this way) even ideas which have been suppressed can still be active
 in the system - they just end up with a low SV multiplier (but non null).
 
\end_layout

\begin_layout Plain Layout
This raises two questions; can the SV optimization problem handle this and
 can we really treat old memories and current ideation as the same process?
 If the answer to either is 'no', there is another option; we use two optimizati
on processes; one which behaves a the existing SV one does, and another
 which implements the prediction set.
 At some point control passes from one system to another (probably gradually).
\end_layout

\begin_layout Plain Layout
Let's start with the first question.
 We'll still have a prediction algorithm, so we can ignore anything it does.
 The question is if the culling algorithm can be implemented in an SV.
 The exploration is produced through the intersection of the SVM and the
 prediction algorithm; so long as the SVM can quickly eliminate SV's, that
 elimination will influence the prediction algorithm, which will produce
 exploration (I think).
 We were talking about the culling algorithm eliminating points with low
 expected reward and far away from points with high expected reward, or
 points with low uncertainty.
 The SVM optimization already eliminates points with low uncertainty (redundancy
).
 If we think of the significance of a point in reducing loss as similar
 to the expected reward, the SVM already probably does the former as well.
 We simply need to restate the SVM problem as one of estimating expected
 reward, rather than probability.
 This may or may not be possible - it depends on how we define the expected
 reward.
 I seem to remember that being an iterative process.
 We might be able to do this in the regularizer using a set number of iterations.
 We might also be limited to two iterations if the iteration increases the
 power of the multiplier (since we're restricted to quadratic optimization).
 Think about this today...
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Now that we have developed a robust architecture for estimating the probability
 of a point, we turn our attention to the inverse problem; predicting observatio
ns which conform the the PDF, possibly under some set of conditions.
 In this sense, we are shifting our focus from probability densities to
 points.
 In general, when we refer to "prediction", we will be referring to the
 generation of points, as opposed to "estimation", by which we mean the
 generation of probability densities.
\end_layout

\begin_layout Standard
We will frame the prediction task as one of first constructing a suitable
 PDF, and then extracting a set of predictions.
 We will begin with the case of the PDF generated by the estimation technique
 developed in the previous sections and discuss a general method for generating
 predictions.
 We will then investigate various types of conditional PDF's and extend
 our prediction technique to these conditional PDF's.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Reorganize this entire section to be based on various method of generating
 
\begin_inset Formula $\rho$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Generalized Prediction
\end_layout

\begin_layout Standard
We begin by considering the case where we wish to determine a set of random
 variates 
\begin_inset Formula $\bar{X}$
\end_inset

;
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
We focus on random variates to retain the probabilistic nature of the estimate.
 There are other potential approaches, for instance determining the point
 with the highest estimated PDF.
 Random variates further allow us to make predictions in the context of
 TI estimators - such estimators operate on sets of points.
\end_layout

\end_inset

 we refer to this set as a prediction of 
\begin_inset Formula $X$
\end_inset

.
 We consider the case where an estimate 
\begin_inset Formula $\varphi$
\end_inset

 of the probability 
\begin_inset Formula $\mathcal{P}$
\end_inset

 exists, generated from some set of observations 
\begin_inset Formula $X=[x_{1},...,x_{\ell}]$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi(x:\ X) & \longmapsto\Pr(x|X)=\mathcal{P}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We will generate random variates using the Inverse Transform Sampling (ITS)
 method.
 The ITS method allows the generation of a random variate by transforming
 an observation 
\begin_inset Formula $z$
\end_inset

 drawn from a uniform distribution 
\begin_inset Formula $Z\in(0,1)$
\end_inset

 into a set of predictions which conform to the PDF in question.
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
In this paper, we will always use the random variable 
\begin_inset Formula $Z$
\end_inset

 to refer to a variable drawn from a uniform distribution over various ranges.
 For instance, if we define the range as 
\begin_inset Formula $Z\in[0,1]$
\end_inset

, then the random variable 
\begin_inset Formula $Z$
\end_inset

 will have a uniform distribution over the two points 0 and 1.
\end_layout

\end_inset

 The general approach is to determine the inverse of the PDF's cumulative
 distribution function (CDF).
 Since the CDF is bounded by 
\begin_inset Formula $(0,1)$
\end_inset

, uniform observations drawn from 
\begin_inset Formula $(0,1)$
\end_inset

 can be mapped to appropriate values in the CDF (and thus the PDF).
 We define a prediction function 
\begin_inset Formula $\phi(z:\ \varphi)$
\end_inset

 which implements the ITS method:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\phi(z:\ \varphi) & =\text{CDF}_{\varphi}^{-1}(z)\\
\text{CDF}_{\varphi}(z) & =\int_{-\infty}^{x}\varphi(z)dx\\
z & \in(0,1)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Unfortunately, there is no analytical solution to the inverse CDF of either
 a Parzen or SVM estimator.
 Recall that the PW estimator is defined as
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Start this all off with a discussion of rho
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi(x:\ X) & =\sum_{i=1}^{\ell}\frac{1}{\ell}K_{\gamma}(x,x_{i})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can think of the PW estimator as the sum of the probabilities of each
 observation
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\Pr(x|X) & =\sum_{i=1}^{\ell}\frac{1}{\ell}\Pr(x|x_{i})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can generate random variates by summing random variates drawn from each
 kernel function:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\phi(z:\ \varphi) & =\sum_{i=1}^{\ell}\phi(z:\ x_{i})\\
\phi(z:\ x_{i}) & =\begin{cases}
\phi(z:\ K_{\gamma}(x,x_{i})) & z=i\\
\emptyset & \text{otherwise}\end{cases}\\
Z & \in[1,...,\ell]\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In the case of the RBF kernel, multiple methods exist to generate random
 variates 
\begin_inset Formula $\phi(z:\ K_{\gamma}(x,y))$
\end_inset

.
 In the context of SVM estimators, the prediction function can take advantage
 of the fact that some observations have been eliminated from the estimator.
 Rather than selecting observations at random, we can select observations
 at random, weighted by their coefficients.
 This allows us to generate random deviates without using non-SV observations.
 We can treat the SVM estimator as a similar sum of probabilities
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\Pr(x|X) & =\sum_{i=1}^{\ell}\beta_{i}\Pr(x|x_{i})\\
\phi(z:\ \varphi) & =\sum_{i=1}^{\ell}\phi(z:\ \beta_{i},x_{i})\\
\phi(z:\ \beta_{i},x_{i}) & =\begin{cases}
\phi(z:\ K_{\gamma}(x,x_{i})) & \sum_{j=1}^{i}\beta_{j}\le z<\sum_{j=1}^{\ell}\beta_{j}-\sum_{j=i+1}^{\ell}\beta_{j}\\
\emptyset & \text{otherwise}\end{cases}\\
Z & \in\left(0,\sum_{i=1}^{\ell}\beta_{i}\right)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Generating random variates from TI estimators is less straightforward.
 In the case of a TI estimator, each 
\emph on
window
\emph default
 over the observations 
\begin_inset Formula $X$
\end_inset

 constitutes an observation analogous to 
\begin_inset Formula $x_{i}$
\end_inset

 in the PW and SVM estimators.
 Using the prediction method developed above, we can easily generate a random
 variate for a given window.
 The nature of TI analysis dictates that there are an infinite number of
 mappings from the random variate generated for a given window over 
\begin_inset Formula $X$
\end_inset

 and the abstract space 
\begin_inset Formula $\Omega$
\end_inset

.
 In order to generate a prediction, we must choose a specific affine transformat
ion defined by 
\begin_inset Formula $(\bar{\mathbf{A}},\bar{\mathbf{b}})$
\end_inset

.
\end_layout

\begin_layout Standard
To do so, consider the nature of the TI metric.
 The TI metric is defined as the integral over all possible values of 
\begin_inset Formula $(\mathbf{A},\mathbf{b})$
\end_inset

 of the Pearson divergence of the probability of a point in the context
 of a window and a transformed window
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\|w_{n}^{X},w_{m}^{X}:\ \nu\| & =\int\int\sum_{i=1}^{\ell}\omega_{\alpha}(w_{n}^{\nu},x_{i}^{\nu})\left(\frac{\varphi(x_{i}^{\nu}:\ w_{m}^{X},\mathbf{A}X+\mathbf{b})}{\varphi(x_{i}^{\nu}:\ w_{m}^{X},X)}-1\right)^{2}d\mathbf{A}d\mathbf{b}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Rather than evaluating this over the integral of all possible values of
 
\begin_inset Formula $(\mathbf{A},\mathbf{b})$
\end_inset

, we can formulate an equivalent process; select two sets of points 
\begin_inset Formula $\bar{X}_{n}$
\end_inset

 and 
\begin_inset Formula $\bar{X}_{m}$
\end_inset

 in the windows 
\begin_inset Formula $w_{n}$
\end_inset

 and 
\begin_inset Formula $w_{m}$
\end_inset

 which define a unique transformation between the two windows
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
In order to define a unique transformation, it is sufficient to select 
\begin_inset Formula $|D|+1$
\end_inset

 points, where 
\begin_inset Formula $D$
\end_inset

 is the set of dimensions used in a given TI estimator.
 One point is used to align the two sets by shifting, and the other 
\begin_inset Formula $|D|$
\end_inset

 points are used to define the scale and rotation alignment.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\mathbf{A}X_{n}+\mathbf{b} & =X_{m}\\
f(X_{n},X_{m}) & \longmapsto\mathbf{b}=\left(X_{n}\right)_{1}-\left(X_{m}\right)_{1}\\
g(X_{n},X_{m}) & \longmapsto\mathbf{A}=\left(X_{n}\right)_{i\neq1}\left(X_{m}\right)_{i\neq1}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Make sure this holds
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $(X_{n})_{1}$
\end_inset

 denotes the first element of 
\begin_inset Formula $X_{n}$
\end_inset

 and 
\begin_inset Formula $(X_{n})_{i\neq1}$
\end_inset

 denotes all the elements of 
\begin_inset Formula $X_{n}$
\end_inset

 except the first element.
 Observe that the following is equivalent to the TI metric
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\|w_{n}^{X},w_{m}^{X}:\ \nu\| & =\frac{1}{|X_{n},X_{m}\in X|}\sum_{X_{n},X_{m}\in X}\sum_{i=1}^{\ell}\omega_{\alpha}(w_{n}^{\nu},x_{i}^{\nu})\left(\frac{\varphi\left(x_{i}^{\nu}:\ w_{m}^{X},f(X_{n},X_{m})X+g(X_{n},X_{m})\right)}{\varphi(x_{i}^{\nu}:\ w_{m}^{X},X)}-1\right)^{2}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In essence, this function reduces the search space to the set of transformations
 defined by all subsets of 
\begin_inset Formula $X$
\end_inset

 which define a unique transformation.
 This is analogous to checking the SVM optimization problem only at the
 set of observations (rather than integrating over all possible values of
 
\begin_inset Formula $x$
\end_inset

).
\end_layout

\begin_layout Standard
Using the above definition of the TI metric, we can randomly select values
 of 
\begin_inset Formula $(\bar{\mathbf{A}},\bar{\mathbf{b}})$
\end_inset

 by randomly selecting sets 
\begin_inset Formula $\bar{X}_{n}$
\end_inset

 and 
\begin_inset Formula $\bar{X}_{m}$
\end_inset

 and evaluating 
\begin_inset Formula $f(\bar{X}_{n},\bar{X}_{m})$
\end_inset

 and 
\begin_inset Formula $g(\bar{X}_{n},\bar{X}_{m})$
\end_inset

.
 The problem of predicting values for TI estimators can therefore be reduced
 to the process of predicting a random variate in a given window and selecting
 the transformation sets 
\begin_inset Formula $\bar{X}_{n}$
\end_inset

 and 
\begin_inset Formula $\bar{X}_{m}$
\end_inset

.
 The window's random variate 
\begin_inset Formula $\bar{x}$
\end_inset

 is transformed into a prediction by applying the transformation 
\begin_inset Formula $f(\bar{X}_{n},\bar{X}_{m})\bar{x}+g(\bar{X}_{n},\bar{X}_{m})$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\phi(\vec{z}_{1}\vec{z}_{2},z_{3},z_{4}:\ \varphi^{D}) & =\begin{cases}
f(\bar{X}_{n},\bar{X}_{m})\phi(z_{3}:\ w_{z_{4}})+g(\bar{X}_{n},\bar{X}_{m})\quad & \sum_{j=1}^{i}\beta_{j}\le z<\sum_{j=1}^{\ell}\beta_{j}-\sum_{j=i+1}^{\ell}\beta_{j}\\
\emptyset & \text{otherwise}\end{cases}\\
\phi(z:\ w) & =\phi(z:\ K_{\gamma}(x,x_{i}))\\
\bar{X}_{n} & =[x_{z_{1}^{1}},...,x_{z_{1}^{|D|}}]\\
\bar{X}_{n} & =[x_{z_{2}^{1}},...,x_{z_{2}^{|D|}}]\\
Z_{1},Z_{2} & \in\mathbb{N}^{|D|},\ 1\le Z_{1}^{d}\le\ell\\
Z_{3},Z_{4} & \in[1,...,\ell]\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
You probably need to define 'in a window' better for selecting points.
 Points should probably be randomly selected based on their inclusion in
 a window.
\end_layout

\end_inset


\end_layout

\begin_layout Section
Ensemble Predictions
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
?
\end_layout

\end_inset


\end_layout

\begin_layout Section
Dimension-Conditional Prediction
\end_layout

\begin_layout Standard
We now consider conditional probability distributions.
 Conditional distributions describe 
\begin_inset Formula $\mathcal{P}$
\end_inset

 in a given context.
 We can view the estimation problem as the process of developing a conditional
 distribution where the context is the set of observations 
\begin_inset Formula $X$
\end_inset

.
 We now refine our treatment of the estimation problem to include both the
 set of observations 
\begin_inset Formula $X$
\end_inset

 and some context in which we are estimating.
 Our task is to restrict the estimation task to some subset 
\begin_inset Formula $\hat{\Omega}$
\end_inset

 of 
\begin_inset Formula $\Omega$
\end_inset

, where the difference between the two abstract spaces is a set of 
\emph on
given
\emph default
 values.
 This is to say we wish to estimate the probability of 
\begin_inset Formula $x\in\Omega$
\end_inset

, conditional upon some set of observations 
\begin_inset Formula $\hat{X}$
\end_inset

.
\end_layout

\begin_layout Standard
Conditional probability is defined as
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\Pr(A|B) & =\frac{\Pr(A\cap B)}{\Pr(B)}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Depending on how we define the events 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

, the conditional probability will allow us to predict values of 
\begin_inset Formula $X$
\end_inset

 in different contexts.
 We begin by considering the situation where the two events describe outcomes
 in two disjoint dimensional sets 
\begin_inset Formula $\tilde{D}$
\end_inset

 and 
\begin_inset Formula $\hat{D}$
\end_inset

 .
 In this case the prediction task can be described as making predictions
 of 
\begin_inset Formula $\tilde{x}\in X^{\tilde{D}}$
\end_inset

 conditional upon 
\begin_inset Formula $X^{\hat{D}}$
\end_inset

in the following conditional probability distribution:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\Pr(X^{\tilde{D}}=\tilde{x}\ |\ X^{\hat{D}}=\hat{x}) & =\frac{\Pr(X^{\tilde{D}}=\tilde{x}\ \cap\ X^{\hat{D}}=\hat{x})}{\Pr(X^{\hat{D}}=\hat{x})}\\
 & =\frac{\Pr(X^{\tilde{D}\cap\hat{D}}=\tilde{x}\cap\hat{x})}{\Pr(X^{\hat{D}}=\hat{x})}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Determining this distribution requires us to determine the probability of
 
\begin_inset Formula $\hat{x}$
\end_inset

 and 
\begin_inset Formula $\tilde{x}\cap\hat{x}$
\end_inset

, restricted to the dimensions for which these two points are defined.
 Recall that our estimation algorithm is defined as the product of the kernel
 distance between each vector dimension
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\Pr(X^{\tilde{D}}=\tilde{x}|X^{\hat{D}}=\hat{x}) & \approx\frac{\varphi(\tilde{x}:\ \beta,X,\tilde{D}\cap\hat{D})}{\varphi(\tilde{x}:\ \beta,X,\hat{D})}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can therefore determine 
\begin_inset Formula $\Pr(X^{\tilde{D}\cap\hat{D}})$
\end_inset

 and 
\begin_inset Formula $\Pr(X^{\hat{D}})$
\end_inset

 by restricting the estimator to the appropriate dimensions:
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
For estimating 
\begin_inset Formula $\Pr(X^{\tilde{D}\cap\hat{D}})$
\end_inset

, we use a single point 
\begin_inset Formula $x$
\end_inset

, for which 
\begin_inset Formula $x^{d}=\tilde{x},\ d\in\tilde{D}$
\end_inset

 and 
\begin_inset Formula $x^{d}=\hat{x},\ d\in\hat{D}$
\end_inset

.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi_{\beta}(\vec{x}:\ X,D) & =\sum_{i=1}^{\ell}\beta_{i}K_{\gamma}(\vec{x},\vec{x}_{i}:\ D)\\
K_{\gamma}\left(\vec{x},\vec{y}:\ D\right) & =\prod_{\upsilon\in D}\frac{1}{\gamma\sqrt{2\pi}}e^{-\frac{1}{\gamma}\|x^{\nu},y^{\nu}\|^{2}}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We now consider generating random deviates from the conditional probability
 distribution.
 As before, our objective is to generate deviates from each observation
 and transform them into predictions using a transformation which conforms
 to our probability distribution.
 In this case, some dimensional values of are determined by 
\begin_inset Formula $\hat{x}$
\end_inset

; our task is to generate deviates for the dimensional values 
\begin_inset Formula $\tilde{D}$
\end_inset

.
 We can frame the problem as one of selecting an observation 
\begin_inset Formula $x_{i}$
\end_inset

, such that the probability of selecting any given 
\begin_inset Formula $x_{i}$
\end_inset

 equals the conditional probability of 
\begin_inset Formula $x_{i}$
\end_inset

 given 
\begin_inset Formula $\hat{D}$
\end_inset

.
 To do this we establish a parameter 
\begin_inset Formula $\rho_{i}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\rho_{i} & =\frac{\varphi_{\beta}(x_{i}:\ X,\tilde{D}\cap\hat{D})}{\varphi_{\beta}(x_{i}:\ X,\hat{D})}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The parameter 
\begin_inset Formula $\rho$
\end_inset

 is a generalization of the process used previously with 
\begin_inset Formula $\frac{1}{\ell}$
\end_inset

 and 
\begin_inset Formula $\beta$
\end_inset

; we select observations such that the probability of selecting a given
 observation is equal to the probability of the observation occurring in
 the estimate.
 In the case of PW estimators, each observation is treated as equally probable.
 In the case of SVM estimators, the weight 
\begin_inset Formula $\beta$
\end_inset

 can be interpreted as the probability of the associated point, given the
 other observations.
 We therefore define the conditional prediction equation as
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\phi(z:\ \varphi,\hat{x},\tilde{D}) & =\sum_{i=1}^{\ell}\phi(z:\ \rho_{i},x_{i},\tilde{D})\\
\phi(z:\ \rho_{i},x_{i},\tilde{D}) & =\begin{cases}
[\phi(z:\ K_{\gamma}(x^{d},x_{i}^{d})):\ d\in\tilde{D}] & \quad\sum_{j=1}^{i}\rho_{j}\le z<\sum_{j=1}^{\ell}\rho_{j}-\sum_{j=i+1}^{\ell}\rho_{j}\\
\emptyset & \text{\quad otherwise}\end{cases}\\
Z & \in\left(0,\sum_{i=1}^{\ell}\rho_{i}\right)\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Extending this to TI estimators is trivial; rather than selecting an observation
 for which to generate a random variate we select a window and proceed as
 before.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Is this true? The selection of transform parameters may need to take the
 CDF into consideration.
\end_layout

\end_inset


\end_layout

\begin_layout Section
Set-Conditional Prediction
\end_layout

\begin_layout Standard
Because TI estimators are contingent on the context of observations, we
 can consider conditional probability distributions where one of the events
 is a set of observations.
 In this case, rather than comparing two windows over the observations 
\begin_inset Formula $X$
\end_inset

, we consider windows over some set of observations 
\begin_inset Formula $\hat{X}$
\end_inset

 and the set of observations 
\begin_inset Formula $X$
\end_inset

.
 Here, we define two events 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

.
 The first event is the occurrence of 
\begin_inset Formula $x$
\end_inset

, and the second event is the occurrence of the set of observations 
\begin_inset Formula $\hat{X}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\Pr(A=x\ |\ B=\hat{X}) & =\frac{\Pr(A=x\ \cap\ B=\hat{X})}{\Pr(B=\hat{X})}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can reduce the numerator to the probability of the set 
\begin_inset Formula $\hat{X}\cup x$
\end_inset

, which leaves us with the problem of determining the conditional probability
 of some arbitrary set given the observations 
\begin_inset Formula $X$
\end_inset

.
 Because we are dealing with TI estimators, we can treat both 
\begin_inset Formula $\hat{X}$
\end_inset

 and 
\begin_inset Formula $\hat{X}\cup x$
\end_inset

 as single points and evaluate the probability of those points.
 We can define 
\begin_inset Formula $\rho$
\end_inset

 as
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\rho_{i} & =\frac{\varphi_{\beta}(w_{i}:\ \hat{X}\cup x,X,D)}{\varphi_{\beta}(w_{i}:\ \hat{X},X,D)}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
In the TI SVM optimization, you used two windows; make sure that using a
 single window here doesn't cause problems
\end_layout

\end_inset


\end_layout

\begin_layout Section
Iterative Prediction
\end_layout

\begin_layout Standard
Consider the following scenario; two estimators based on subsets of 
\begin_inset Formula $X$
\end_inset

 have determined that there exists a high probability of the conditional
 probability 
\begin_inset Formula $B|A$
\end_inset

 and 
\begin_inset Formula $C|B$
\end_inset

.
 We would like to generate conditional predictions given the occurrence
 of 
\begin_inset Formula $A$
\end_inset

.
 It is likely that the first estimator will predict 
\begin_inset Formula $B$
\end_inset

, due to the high conditional probability of 
\begin_inset Formula $B|A$
\end_inset

, however the probability of predicting 
\begin_inset Formula $C$
\end_inset

 will be the marginal probability of 
\begin_inset Formula $C$
\end_inset

, which which in this instance we will assume to be low.
 In this case, the prediction task has failed to incorporate the information
 in the second prediction.
\end_layout

\begin_layout Standard
The obvious solution to this problem is to make two iterative predictions
 
\begin_inset Formula $\bar{X}_{1}$
\end_inset

 and 
\begin_inset Formula $\bar{X}_{2}$
\end_inset

.
 The first prediction is likely to include both 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

.
 We formulate the second prediction as a conditional prediction not on 
\begin_inset Formula $A$
\end_inset

, but on 
\begin_inset Formula $\bar{X}_{1}$
\end_inset

 (which we will assume contains 
\begin_inset Formula $B$
\end_inset

).
 The second prediction therefore is likely to include 
\begin_inset Formula $A$
\end_inset

, 
\begin_inset Formula $B$
\end_inset

, and 
\begin_inset Formula $C$
\end_inset

 - the desired result.
\end_layout

\begin_layout Standard
The utility of iterative prediction is not limited to the case of multiple
 partial estimators; the same problem is possible with TI estimators.
 Because TI estimators are context-sensitive, the prediction of a TI estimator
 window may constitute an appropriate context for different window.
 As with the first example, iterative prediction does not necessarily affect
 the conditional risk of a given prediction, however it is possible that
 a broader spectrum of predictions will be generated.
 We therefore develop an iterative prediction algorithm.
 At each iteration of the prediction algorithm, the results of the previous
 iteration are used as a conditional set
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\phi(z:\ \varphi,\bar{X}_{i-1}) & \longmapsto\bar{X}_{i}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In this case, the PDF of 
\begin_inset Formula $\varphi$
\end_inset

 is uniform across iterations - the only difference between iterations is
 the conditional set.
 The iterative predictor described constitutes a Markov Process with stationary
 distribution 
\begin_inset Formula $\varphi$
\end_inset

.
 
\end_layout

\begin_layout Standard
We have described the generation of random variates as a process in which
 a set of random variates is generated at each iterative step.
 We can take a different approach to the prediction task and formulate equivalen
t results by assuming that the generation of random variates is a continuous
 process.
 The iterative approach implies a temporal processing structure; in order
 to formulate a continuous approach we must explicitly define the temporal
 aspect of the process.
 In the continuous approach, the time 
\begin_inset Formula $t_{i}$
\end_inset

 at which a random variate is generated is recorded, and each variate has
 a 
\begin_inset Quotes eld
\end_inset

lifetime
\begin_inset Quotes erd
\end_inset

 denoted as the duration 
\begin_inset Formula $\tau$
\end_inset

.
 The set of predictions at a given point in time 
\begin_inset Formula $t$
\end_inset

 is described by the set of variates generated before 
\begin_inset Formula $t$
\end_inset

 and which 
\begin_inset Quotes eld
\end_inset

expire
\begin_inset Quotes erd
\end_inset

 after 
\begin_inset Formula $t$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\phi(z:\ t) & \longmapsto\bar{x}^{t}\\
\bar{X}^{t} & =\left[\bar{x}^{t_{i}}:\ t\le t_{i}<t+\tau\right]\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We ensure the distribution of 
\begin_inset Formula $\bar{X}$
\end_inset

 conforms to the distribution of 
\begin_inset Formula $\varphi$
\end_inset

 by controlling the rate at which random variates are generated.
 We refer to the generation of random variates as the 
\begin_inset Quotes eld
\end_inset

emission
\begin_inset Quotes erd
\end_inset

 of random variates.
 For a given emitter, the intervals between emissions are selected randomly
 from the interval 
\begin_inset Formula $(0,\frac{\kappa}{\rho})$
\end_inset

, where 
\begin_inset Formula $\kappa$
\end_inset

 is some scaling constant which controls the system's emission rate.
\end_layout

\begin_layout Standard
If we do not update 
\begin_inset Formula $\rho$
\end_inset

 values, the result of the continuous prediction approach at any point in
 time will coincide with the iterative approach.
 The utility of the continous approach is that it can be implemented in
 a distributed manner without the requirement of synchronization between
 iterations and allows fluid integration with new observations.
\end_layout

\begin_layout Standard
There are multiple methods for handling changes in an emitter's 
\begin_inset Formula $\rho$
\end_inset

.
 One is to eliminate any current variates from the estimator and generate
 new ones with the new emission rate.
 Another approach is to simply adjust the emission rate going forward.
 The former option requires the ability to remove variates from the prediction
 set, while the influence of the transition in the latter is not immediately
 available to the system.
 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
That's a lot of text without any math...
\end_layout

\end_inset


\end_layout

\begin_layout Section
Performance Considerations
\end_layout

\begin_layout Standard
Evaluating values of 
\begin_inset Formula $\rho$
\end_inset

 can be computationally expensive.
 In an ideal continuous predictive system, each time a new variate was generated
 the 
\begin_inset Formula $\rho$
\end_inset

 values of each emitter would be immediately updated.
 In practice this requires evaluating kernel distances between each new
 variate and each SV, then computing the conditional probabilities.
 Marginal changes in an emitter's 
\begin_inset Formula $\rho$
\end_inset

 value will produce marginal shifts in the distribution of 
\begin_inset Formula $\bar{X}$
\end_inset

, but since 
\begin_inset Formula $\bar{X}$
\end_inset

 is a probabalistic prediction it is possible 
\begin_inset Quotes eld
\end_inset

noise
\begin_inset Quotes erd
\end_inset

 resulting from the risk of 
\begin_inset Formula $\varphi$
\end_inset

 will be more significant than marginal changes in that emission rate.
 
\end_layout

\begin_layout Standard
A simple method of reducing the computation demands of iterative prediction
 is prioritize emitters in the neighborhood of emitters whose emission rate
 has been changed significantly.
 Fortunately, the kernel matrix for each SV must be computed during the
 optimization process, so using these kernel distances to evaluate the priority
 of evaluating a given SV's 
\begin_inset Formula $\rho$
\end_inset

 value does not require additional computation if the kernel matrix is cached.
 We can formalize this concept by assuming that an iterative process selects
 SV's for 
\begin_inset Formula $\rho$
\end_inset

 evaluation by choosing the SV whose priority value 
\begin_inset Formula $\psi(\cdot)$
\end_inset

 is the greatest:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\psi(x:\ X,\triangle\rho) & =\sum_{x_{i}\in X}\triangle\rho_{i}K_{\gamma}(x,x_{i})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $\triangle\rho_{i}$
\end_inset

 is the most recent change in 
\begin_inset Formula $\rho_{i}$
\end_inset

 for each observation 
\begin_inset Formula $x_{i}$
\end_inset

.
 In general terms, this approach allows us to evaluate the neighborhood
 of SV's where a significant change in 
\begin_inset Formula $\rho$
\end_inset

 has been observed before moving on to randomly selecting SV's.
\end_layout

\begin_layout Section
Hierarchical Considerations
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
I had originally planned to say that we only pass values up when they change,
 but the more I think about that the less I like it.
 Doing so requries that we have absolute certainty that the value has been
 unchanged between outputs, which in our case isn't necessarily so - especially
 if we're optimizing which SV's get updated.
 At the same time, outputting after updates isn't a great idea either -
 not i.i.d.
 if the SV selection is optimized.
 We get the same problem from outputting at emission - we want the upper
 layers to have an accurate 'view' of the processes below, outputting at
 emission would increase the number of points with large rho (which isn't
 needed as rho describes the emission rate).
 So I think the best way to handle this is to either take the state of the
 entire system at some sampling rate, or possibly allow each SV to randomly
 output at a uniform rate.
 
\end_layout

\end_inset


\end_layout

\begin_layout Chapter
Motivated Decision-Making
\end_layout

\begin_layout Standard
Up to this point, our discussion has focused on data analysis.
 We now turn our attention to volitive systems; systems which have the ability
 influence the the probability distribution 
\begin_inset Formula $\mathcal{P}$
\end_inset

 of the observation space 
\begin_inset Formula $\Omega$
\end_inset

, and in which certain types of local probability distributions are preferred
 over others.
 
\end_layout

\begin_layout Section
Motivated Prediction
\end_layout

\begin_layout Standard
Before discussing motivated prediction, let us lay out a few assumptions
 we will make regarding the architecture used for estimation and prediction.
 The first assumption is that at least one dimension of the abstract space
 describes time.
 Second, we assume that the estimator 
\begin_inset Formula $\varphi$
\end_inset

 includes at least one TI estimator.
 
\end_layout

\begin_layout Standard
It is difficult to talk about motivated decision making without assuming
 that the motivated system has access to time data.
 In general terms, motivation is the process of correlating actions with
 consequences and choosing actions which will produce desirable consequences.
 The concept of motivation itself assumes that there will be some change
 in the system's 
\begin_inset Quotes eld
\end_inset

environment
\begin_inset Quotes erd
\end_inset

 as a result of taking specific actions, an assumption inherently based
 on a temporal view of the probability space.
 
\end_layout

\begin_layout Standard
We split the motivated decision making process into two general categories;
 motivated prediction and choice.
 This division is not necessary, however it provides a clean separation
 between functions; the prediction task is to explore potential system states
 and the choice task is to select actions from the available predictions.
 The prediction task as described in the previous section involved exploring
 possible sets of observations in order to learn something about 
\begin_inset Formula $\mathcal{P}$
\end_inset

 and its nature in different contexts.
 Motivated prediction constitutes the same general process, however our
 objective now is to learn the 
\emph on
consequences
\emph default
 of potential 
\emph on
actions
\emph default
.
 We describe a given prediction's 
\begin_inset Quotes eld
\end_inset

utility
\begin_inset Quotes erd
\end_inset

 as the amount of information it contains regarding the correspondance between
 actions and consequences, and our task is to modify the prediction process
 to be biased towards exploring the nature of 
\begin_inset Formula $\mathcal{P}$
\end_inset

 in these contexts.
\end_layout

\begin_layout Standard
We begin by quantifying the utility of a given SV.
 We wish to quantify the extent to which an SV consitutes either a preferred
 or discouraged point in 
\begin_inset Formula $\Omega$
\end_inset

.
 Because we wish our system to both strive for preferred states and avoid
 discouraged states, points which correspond to either are have utility
 in the prediction task.
 We therefore describe the utility 
\begin_inset Formula $u(x)$
\end_inset

 of a point as the average of the absolute value of the motivational state
 of each dimension in the point
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
u_{\theta}(x) & =\frac{1}{d}\sum_{i}^{d}|m_{\theta}(x^{i})|\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can extend this to TI estimators by weighting each point by its membership
 in the window
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
u_{\theta}(w) & =\frac{1}{\sum_{x_{i}\in X}\omega(w,x_{i})}\sum_{x_{i}\in X}\omega(w,x_{i})u_{\theta}(x_{i})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Evaluating the utility of a prediction is less straightforward.
 Because predictions describe potential states (rather than observed states),we
 can't know the prediction's utility based solely on the prediction itself.
 We must evaluate the utility of a prediction in the context not only of
 previous observations, but of the other points in 
\begin_inset Formula $\bar{X}$
\end_inset

.
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
Recall the conditional prediction scenario where the conditional probabilities
 
\begin_inset Formula $A|B$
\end_inset

 and 
\begin_inset Formula $B|C$
\end_inset

 are known to be high, but an iterative predictor will fail to predict 
\begin_inset Formula $C$
\end_inset

.
 This situation applies to utility as well; if the utility of 
\begin_inset Formula $C$
\end_inset

 is high, we would like the utility of 
\begin_inset Formula $A$
\end_inset

 to also be high, since we know that the conditional probability 
\begin_inset Formula $A|C$
\end_inset

 is high.
\end_layout

\end_inset

 We therefore adopt an iterative approach to determining the utility of
 a prediction.
 We begin by evaluating a prediction using the utility of each SV and the
 conditional probability of the prediction given the SV
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
u_{\theta}^{1}(\bar{x}) & =\sum_{x_{i}\in X}u_{\theta}(x_{i})\varphi(x:\ x_{i})+\sum_{w_{i}\in X}u_{\theta}(w_{i})\varphi(\bar{w}:\ w_{i})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $\bar{w}$
\end_inset

 refers to the window defined by 
\begin_inset Formula $\bar{x}$
\end_inset

.
 Our general approach is to ensure that for a point 
\begin_inset Formula $\bar{x}_{i}$
\end_inset

 with high utility, any other points which 
\begin_inset Formula $\bar{x}_{i}$
\end_inset

 is conditional upon also are assigned high utility.
 We then use the conditional probabilities of the other estimates given
 
\begin_inset Formula $\bar{x}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
u_{\theta}^{i}(\bar{x}) & =\sum_{\bar{x}_{i}\in\bar{X}}u_{\theta}^{i-1}(\bar{x}_{i})\frac{\varphi(\bar{x}_{i}:\ \bar{X})}{\varphi(\bar{x}_{i}:\ \bar{X}\vee\bar{x})}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
As this iterative step updates the utility of each observation, it can be
 evaluated for as many iterations as are necessary to provide a suitable
 level of accuracy.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Re-frame for emission
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Returning to the concept of motivated prediction, it is clear that in the
 context of an iterative predictor we would like to emphasize prediction
 in a given iteration based on predictions with high utility in previous
 iterations.
 While predictions are drawn from PDF's, they are not assumed to describe
 a probability density themselves, therefore there is no requirement that
 they be i.i.d.
 points.
 Selecting some predictions to pass through to subsequent iterations and
 not others does not undermine the validity of subsequent predictions; the
 validity of a given iteration is derived from the estimator generating
 it (which is unaffected by the specific set of predictions passed to a
 given iteration).
 We can view the selection process as a type of conditional prediction;
 we are creating predictions in the context of points the system considers
 useful.
 The reason we choose to implement the selection process after predictions
 have been made is that prior to generating a prediction it is uncertain
 exacly what the conditional utility between predictions will be.
 
\end_layout

\begin_layout Standard
We have refined our understanding of the motivated prediction process; the
 prediction task constitutes selecting points of interest from a set of
 predictions and passing them to future iterations of the prediction process.
 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Again - lots of words...
\end_layout

\end_inset


\end_layout

\begin_layout Section
Choice
\end_layout

\begin_layout Standard
We have now developed a robust architecture for estimating correlation between
 observations, generating predictions from that estimate, and evaluating
 the consequences of actions contained in the predictions.
 The final step is to chose specific actions to take.
 This choice reduces to a simple matter of selecting the action with the
 greatest expected correlation with preferred states of 
\begin_inset Formula $\Omega$
\end_inset

, determined by the motivation function 
\begin_inset Formula $m_{\theta}(\cdot)$
\end_inset

 at a given time 
\begin_inset Formula $t$
\end_inset

.
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
We assume that the time 
\begin_inset Formula $t$
\end_inset

 describes the time at which the selection takes place.
 The ability to increase the probability of selecting an action in the future
 is provided by through iterative prediction.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
It cannot be assumed that a prediction at time 
\begin_inset Formula $t$
\end_inset

 exists, so we use the windowing function to select between actions in the
 vicinity of 
\begin_inset Formula $t$
\end_inset

.
 We select from the predictions 
\begin_inset Formula $\bar{X}$
\end_inset

 the action 
\begin_inset Formula $\ddot{a}$
\end_inset

 with the greatest expected correlation with preferred states, scaled by
 each action's inclusion in the window
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\ddot{a}(t) & =\max_{\bar{a}_{i}\in\bar{A}}\omega_{\gamma}(t,a)\ u_{\theta}(a_{i})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
If this was a regression function the output would be a lot smoother.
 Just make sure you don't end up between peaks - this may require some work
 to the motivated prediction section
\end_layout

\end_inset


\end_layout

\begin_layout Section
Curiosity
\end_layout

\begin_layout Standard
Without the ability to take action, a system's accuracy and efficiency for
 a given data-set is limited by the algorithm it uses and the computational
 resources available to it.
 Systems with the ability to influence the observations from which they
 make estimates, on the other hand, can take advantage of this ability to
 increase both their accuracy and performance.
 Before we can discuss the mechanisms by which this is possible, we must
 first develop a more rigorous understanding of these two objectives; accuracy
 and efficiency.
\end_layout

\begin_layout Standard
Our system's accuracy can be described as the empirical loss resulting from
 the SVM optimization process.
 This is an attractive metric as it can be easily computed after optimization
 by subtracting the regularizer term.
 In this case we assume the PW estimate represents the minimal possible
 risk of the system and measure the efficiency of the SVM estimator based
 on its divergence from the PW estimator.
 We can therefore quantify the system's accuracy after 
\begin_inset Formula $\ell$
\end_inset

 observations as the empirical risk 
\begin_inset Formula $R_{\text{emp}}(\ell)$
\end_inset

.
\end_layout

\begin_layout Standard
The efficiency of the system is determined by the amount of computation
 required to generate estimates, which depends on the number of support
 vectors.
 We can therefore describe the system's efficiency as the inverse of the
 number of support vectors 
\begin_inset Formula $|SV|^{-2}$
\end_inset

.
 As the number of SV's grows the computational requirements of estimating
 point's probabilities grows with the size of the kernel matrix ( which
 contains 
\begin_inset Formula $|SV|^{2}$
\end_inset

 elements).
\end_layout

\begin_layout Standard
We can now establish the following metric for the system's performance after
 
\begin_inset Formula $\ell$
\end_inset

 observations
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
p(\ell:\ \varphi) & =\frac{R_{\text{emp}}(\ell)}{|SV_{\ell}|^{2}}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $SV_{\ell}$
\end_inset

 is the set of support vectors after 
\begin_inset Formula $\ell$
\end_inset

 observations.
 The system can be motivated to increase its performance by including 
\begin_inset Formula $p$
\end_inset

 as a system input and motivating positive values
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Make sure p is stationary here - if it's not motivating any specific value
 won't be useful
\end_layout

\end_inset

.
\end_layout

\begin_layout Chapter
Conclusion
\end_layout

\begin_layout Standard
Eat it, bitches
\end_layout

\begin_layout Chapter
\start_of_appendix
Results
\end_layout

\begin_layout Section
Eunite Competition Data
\end_layout

\begin_layout Section
Santa Fe Data
\end_layout

\begin_layout Section
CATS Benchmark Data
\end_layout

\begin_layout Section
Results Summary
\end_layout

\begin_layout Chapter
Discussion of Existing Work
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

%http://en.wikipedia.org/wiki/Expectation-maximization_algorithm
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

%http://en.wikipedia.org/wiki/Stationary_process
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

%http://en.wikipedia.org/wiki/Ergodicity
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

%http://en.wikipedia.org/wiki/Mixing_(mathematics)
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

%http://en.wikipedia.org/wiki/Lyapunov_exponent
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

%http://en.wikipedia.org/wiki/Recurrence_quantification_analysis
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

%http://en.wikipedia.org/wiki/Recurrence_plot
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

%http://en.wikipedia.org/wiki/Autoregressive_fractionally_integrated_moving_averag
e
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

%http://en.wikipedia.org/wiki/Autocorrelation
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

%
\backslash
url{http://en.wikipedia.org/wiki/Linear_discriminant_analysis}
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Hidden Markov Model
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

% cannot account for future states - only capable of prediction
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

% weak, short-term memory
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Box-Jenkins
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

% intended for simplistic processes with well-understood stationarity and
 periodicity
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout

% http://en.wikipedia.org/wiki/Box-Jenkins
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Spectral Analysis
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

% assumes some type of frequency-domain decomposition.
  Frequency-domain signal representations do not do a very good job predicting
 time-domain values.
 
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Shrinking-
\begin_inset Formula $\epsilon$
\end_inset

 SVM Regression
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

% theoretical foundation weak; only compensates for the relevance of recent
 data.
  See Markhov problem
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Chapter
SVM Details & Optimizations
\end_layout

\begin_layout Section
Quadratic Optimization Problem
\end_layout

\begin_layout Section
Support Vector Decomposition 
\end_layout

\begin_layout Standard
\begin_inset Marginal
status collapsed

\begin_layout Plain Layout
This section is probably better as an appendix
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Due to the simplicity of the constraints in the optimization problem, it
 is possible to use the decomposition method of Osuna to reduce the memory
 requirements of the Parzen-SVM algorithm.
\end_layout

\begin_layout Subsection
 Sub-Problem Definition 
\end_layout

\begin_layout Standard
The decomposition algorithm breaks 
\begin_inset Formula $X$
\end_inset

 into two working sets 
\begin_inset Formula $B,N$
\end_inset

, and attempts to optimize 
\begin_inset Formula $B$
\end_inset

 while keeping 
\begin_inset Formula $N$
\end_inset

 fixed.
 This results in the following iterative optimization problem where 
\begin_inset Formula $\boldsymbol{\beta}^{k}$
\end_inset

 denotes the result of the previous iteration:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
W(\boldsymbol{\beta}_{B}) & =\frac{1}{2}\begin{bmatrix}\boldsymbol{\beta}_{B}^{T} & (\boldsymbol{\beta}_{N}^{k})^{T}\end{bmatrix}\begin{bmatrix}P_{BB} & P_{BN}\\
P_{NB} & P_{NN}\end{bmatrix}\begin{bmatrix}\boldsymbol{\beta}_{B}\\
\boldsymbol{\beta}_{N}^{k}\end{bmatrix}-\begin{bmatrix}q_{B}^{T} & q_{N}^{T}\end{bmatrix}\begin{bmatrix}\boldsymbol{\beta}_{B}\\
\boldsymbol{\beta}_{N}^{k}\end{bmatrix}\\
 & =\frac{1}{2}\boldsymbol{\beta}_{B}^{T}P_{BB}\boldsymbol{\beta}_{B}-(-q_{B}+P_{BN}\boldsymbol{\beta}_{N}^{k})^{T}\boldsymbol{\beta}_{B}\\
 & =\frac{1}{2}\begin{bmatrix}\beta_{i} & \beta_{j}\end{bmatrix}\begin{bmatrix}P_{ii} & P_{ij}\\
P_{ij} & P_{jj}\end{bmatrix}\begin{bmatrix}\beta_{i}\\
\beta_{j}\end{bmatrix}-(-q_{B}+P_{BN}\boldsymbol{\beta}_{N}^{k})^{T}\begin{bmatrix}\beta_{i}\\
\beta_{j}\end{bmatrix}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{equation}
\text{subject to}\quad0\le\beta_{i},\beta_{j},\quad\beta_{i}+\beta_{j}=1-\mathbf{1}^{T}\boldsymbol{\beta}_{N}^{k}\end{equation}

\end_inset


\end_layout

\begin_layout Subsection
 Working Set Selection 
\end_layout

\begin_layout Standard
Select
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align}
 & i\in\text{arg}\max_{t}\left\{ -\nabla f(\boldsymbol{\beta}^{k})_{t}\ |\quad t\in I(\boldsymbol{\beta}^{k})\right\} \\
 & j\in\text{arg}\min_{t}\left\{ -\frac{b_{it}^{2}}{a_{it}}\ |\quad t\in I(\boldsymbol{\beta}^{k}),\quad-\nabla f(\boldsymbol{\beta}^{k})_{t}<-\nabla f(\boldsymbol{\beta}^{k})_{i}\right\} \end{align}

\end_inset


\end_layout

\begin_layout Standard
Where 
\begin_inset ERT
status open

\begin_layout Plain Layout

% This needs to be checked for the new optimization scenario
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align}
I(\boldsymbol{\beta}) & \equiv\{t\ |\quad\beta_{t}<1\quad\text{or}\quad\beta_{t}>0\}\\
 & a_{it}=P_{ii}+P_{tt}-2P_{it}\\
 & \bar{a}_{it}=\begin{cases}
a_{it} & \text{if}\ a_{it}>0\\
\delta & \text{otherwise}\end{cases}\\
 & b_{it}=-\nabla f(\boldsymbol{\beta}^{k})_{i}+\nabla f(\boldsymbol{\beta}^{k})_{t}\\
\nabla f(\boldsymbol{\beta})_{i} & \equiv P_{i}\boldsymbol{\beta}-q_{i}\end{align}

\end_inset


\end_layout

\begin_layout Subsection
Stopping Condition 
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{equation}
\max_{i\in I(\boldsymbol{\alpha}^{k})}-\nabla f(\boldsymbol{\alpha})_{i}+\min_{j\in I(\boldsymbol{\alpha}^{k})}\nabla f(\boldsymbol{\alpha})_{j}\le\epsilon\end{equation}

\end_inset


\end_layout

\begin_layout Section
Cascade SVM
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "Hazan08"

\end_inset


\end_layout

\begin_layout Section
Parallel SVM Decomposition
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "Graf04"

\end_inset


\end_layout

\begin_layout Chapter
Implementation details
\end_layout

\begin_layout Standard
Catanzaro frames SMO optimization as MapReduce, although it's still an iterative
 process (each iteration is a MapReduce)
\end_layout

\begin_layout Standard
CouchDB provides erlang-based MapReduce using javascript 'views' on unstructured
 data.
 
\end_layout

\begin_layout Chapter
Further Research
\end_layout

\begin_layout Section
Data Pre-Processing
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

% logistic function using mean and sd to put most training points between
 .1 and .9
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

% logistic function from delta using mean and sd in same way if data non-station
ary
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

% iterative integration process until stationary data found ?
\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Performance
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintAll"
bibfiles "Research/research.bib"
options "bibtotoc,plain"

\end_inset


\end_layout

\end_body
\end_document
