#LyX 1.6.1 created this file. For more info see http://www.lyx.org/
\lyxformat 345
\begin_document
\begin_header
\textclass article
\use_default_options true
\language english
\inputencoding auto
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\cite_engine basic
\use_bibtopic false
\paperorientation portrait
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\author "" 
\author "" 
\end_header

\begin_body

\begin_layout Title
Working Notes
\end_layout

\begin_layout Section
Algorithms
\end_layout

\begin_layout Subsection
Parzen Window Vector Estimate
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
\begin_inset Formula \begin{align}
\phi_{P}(\mathbf{x},X) & =\sum_{x\in X}\frac{1}{|X|}k_{\gamma}(\mathbf{x},x)\label{eq:phiParzen}\\
k_{\gamma}(x,y) & =\prod_{c}\frac{1}{\gamma\sqrt{2\pi}}e^{-\frac{1}{\gamma}\|x^{c}-y^{c}\|^{2}}\label{eq:KParzen}\end{align}

\end_inset


\end_layout

\begin_layout Subsection
Random Vector Estimate
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align}
\phi(x) & =\sum_{i=1}^{\ell}\left(\beta_{i}^{1}\mathcal{K}_{1}(x_{i},x)+...+\beta_{i}^{\kappa}\mathcal{K}_{\kappa}(x_{i},x)\right)\label{eq:phiSV}\\
W(\beta) & =\sum_{i=1}^{\ell}\left(y_{i}-\sum_{j=1}^{\ell}\sum_{n=1}^{\kappa}\beta_{j}^{n}k_{n}(x_{i},x_{j})\right)^{2}+\lambda\sum_{i=1}^{\ell}\sum_{n=1}^{\kappa}\frac{1}{\gamma_{n}}\beta_{i}^{n}\label{eq:WVector}\\
 & \text{subject to}\quad\sum_{i=1}^{\ell}\sum_{n=1}^{\kappa}\beta_{i}^{n}=1,\quad\beta_{i}\ge0\label{eq:VectorConstraints}\\
k(x,x') & =\frac{1}{1+e^{-\gamma(x-x')}}\label{eq:KVector}\\
\mathcal{K}(x,x') & =-\frac{\gamma}{2+e^{\gamma(x-x')}+e^{-\gamma(x-x')}}\label{eq:xKVector}\end{align}

\end_inset


\end_layout

\begin_layout Subsection
Support Vector Random Process Estimate
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align}
\varphi_{SV}(\mathbf{x},S:\beta) & =\sum_{i\in\mathcal{S}}\beta_{i}K_{\gamma}(S_{\mathbf{x}},S_{i})\label{eq:varphiSV}\\
S_{\mathbf{x}} & =\{S\cup\mathbf{x}\}\\
W(\beta) & =\sum_{i,j\in\mathcal{S}}\beta_{i}\beta_{j}\sum_{S\in\mathcal{S}}K_{\gamma}(S,S_{i})K_{\gamma}(S,S_{j})\label{eq:WProcess}\\
 & \qquad\qquad\qquad\qquad+\sum_{i\in\mathcal{S}}\beta_{i}\sum_{S\in\mathcal{S}}\left(\lambda K_{\gamma}(S,S_{i})^{-1}-\frac{2}{|\mathcal{S}|}\sum_{j\in\mathcal{S}}K_{\gamma}(S,S_{i})K_{\gamma}(S,S_{j})\right)\\
 & \text{subject to}\quad\sum_{i}\beta_{i}=1,\quad\beta_{i}\ge0,\ i=1,\ldots,|\mathcal{S}|\label{eq:ProcessConstraints}\\
K_{\gamma}(S_{n},S_{m}) & =\prod_{c}\frac{1}{\gamma\sqrt{2\pi}}e^{-\frac{1}{\gamma}\|S_{n}^{c}-S_{m}^{c}\|_{H}^{2}}\label{eq:KProcessSS}\\
\|S_{n}-S_{m}\|_{H} & =\sum_{\mathbf{x}\in S_{n}}\phi_{m}(\mathbf{x})\ \log\phi_{m}(\mathbf{x})\label{eq:DistKL}\\
K_{\gamma}(X,S_{n}) & =\prod_{c}\frac{1}{\gamma\sqrt{2\pi}}e^{-\frac{1}{\gamma}\|X^{c}-S_{n}^{c}\|_{H}^{2}}\label{eq:KProcessXS}\\
\|X-S_{n}\|_{H} & =\sum_{\mathbf{x}\in X}\phi_{n}(\mathbf{x})\ \log\phi_{n}(\mathbf{x})\label{eq:DistH}\end{align}

\end_inset


\end_layout

\begin_layout Section
Random Vector Estimate Implementation
\end_layout

\begin_layout Standard
From 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:WProcess"

\end_inset

we know that we need to calculate
\end_layout

\begin_layout Standard
\begin_inset Formula \[
\mathbf{K_{i,j}=}\sum_{S\in\mathcal{S}}K_{\gamma}(S,S_{i})K_{\gamma}(S,S_{j})\]

\end_inset


\end_layout

\begin_layout Standard
It would be helpful if this could take advantage of the fact that many subsets
 have overlaps, and it isn't useful to re-calculate each one.
 For starters, we can calculate a shared kernel matrix for subset comparisons,
 which will reduce the amount of computation (and memory) required to calculate
 
\begin_inset Formula $\|S_{n}-S_{m}\|$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\mathbf{D}_{i,j} & =k_{\gamma}(\mathbf{x}_{i},\mathbf{x}_{j})\\
\mathbf{\bar{D}}_{A,B} & =\sum_{\begin{array}{c}
i\in A\\
j\in B\end{array}}\mathbf{D}_{i,j}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\phi_{n}(\mathbf{x}) & =\sum_{i\in S_{n}}\frac{1}{|S_{n}|}k_{\gamma}(\mathbf{x},\mathbf{x}_{i})\\
 & =\frac{1}{|S_{n}|}\mathbf{\bar{D}}_{\mathbf{x},S_{n}}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\|S-S_{n}\|_{H} & =\sum_{\mathbf{x}\in S}\phi_{n}(\mathbf{x})\ \log\phi_{n}(\mathbf{x})\\
 & =\sum_{\mathbf{x}\in S}\frac{\mathbf{\mathbf{\bar{D}}}_{\mathbf{x},S_{n}}}{|S_{n}|}\ \log\frac{\mathbf{\mathbf{\bar{D}}}_{\mathbf{x},S_{n}}}{|S_{n}|}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
In this case, we treat 
\begin_inset Formula $\mathbf{\bar{D}}_{\mathbf{x},S_{i}}$
\end_inset

 as a column vector for all 
\begin_inset Formula $\mathbf{x}\in S$
\end_inset

.
 We're now ready to bring the back to the kernel equation.
 For clarity, we'll represent the kernel matrix as follows:
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\noun off
\color none
\begin_inset Formula \begin{align*}
K_{\gamma}(S_{n},S_{m}) & =\prod_{c}\frac{1}{\gamma\sqrt{2\pi}}e^{-\frac{1}{\gamma}\|S_{n}^{c}-S_{m}^{c}\|_{H}^{2}}\\
 & =\left|S_{n}-S_{m}\right|_{K,\gamma}\\
 & =\left|\sum_{x\in S_{n}}\frac{\mathbf{\mathbf{\bar{D}}}_{x,S_{m}}}{|S_{m}|}\ \log\frac{\mathbf{\mathbf{\bar{D}}}_{x,S_{m}}}{|S_{m}|}\right|_{K,\gamma}\\
\mathbf{K}_{n,m} & =K_{\gamma}(S_{n},S_{m})\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can now restate our objective function:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
W(\beta) & =\sum_{i,j\in\mathcal{S}}\beta_{i}\beta_{j}\sum_{S\in\mathcal{S}}K_{\gamma}(S,S_{i})K_{\gamma}(S,S_{j})\\
 & \qquad\qquad\qquad\qquad+\sum_{i\in\mathcal{S}}\beta_{i}\sum_{S\in\mathcal{S}}\left(\lambda K_{\gamma}(S,S_{i})^{-1}-\frac{2}{|\mathcal{S}|}\sum_{j\in\mathcal{S}}K_{\gamma}(S,S_{i})K_{\gamma}(S,S_{j})\right)\\
\\ & =\frac{1}{2}\beta^{T}P\beta+q^{T}\beta\\
P_{i,j} & =\sum_{\mathbf{x}\in X}K_{\gamma}(S_{\mathbf{x}},S_{i})K_{\gamma}(S_{\mathbf{x}},S_{j})\\
q_{i} & =\sum_{\mathbf{x}\in X}\left(\lambda K_{\gamma}(S_{\mathbf{x}},S_{i})^{-1}-\frac{1}{|\mathcal{S}|}\sum_{j\in\mathcal{S}}K_{\gamma}(S_{\mathbf{x}},S_{i})K_{\gamma}(S_{\mathbf{x}},S_{j})\right)\\
\\P & =\left\langle \mathbf{K}^{T}\cdot\mathbf{K}\right\rangle \\
q & =\lambda\left\langle \mathbf{K}^{T}\cdot\mathbf{1}_{(|\mathcal{S}|,1)}\right\rangle ^{-1}-\frac{1}{|\mathcal{S}|}\left\langle \mathbf{K}^{T}\cdot\mathbf{K}\cdot\mathbf{1}_{(|\mathcal{S}|,1)}\right\rangle \end{align*}

\end_inset


\end_layout

\begin_layout Standard
To implement this, consider two matrices, the first a 2d matrix 
\begin_inset Formula $X$
\end_inset

 containing observations and the second a 2d matrix 
\begin_inset Formula $M$
\end_inset

 used to mask subsets; each 
\begin_inset Formula $S$
\end_inset

 represented as a masking matrix where unmasked values are equal to 
\begin_inset Formula $\frac{1}{|\mathcal{S}|}$
\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
M_{i,j} & =\begin{cases}
0 & \quad X_{j}<t_{i}\\
0 & \quad t_{i}+\theta_{i}\le X_{j}\\
\frac{1}{|S_{i}|} & \quad\text{otherwise}\end{cases}\\
X_{i,0} & =t_{i}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
This allows us to change how we think of 
\begin_inset Formula $\mathbf{D}$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\mathbf{D}_{i,j} & =k_{\gamma}(\mathbf{x}_{i},\mathbf{x}_{j})\\
\mathbf{\bar{D}}_{n,m} & =\sum_{\begin{array}{c}
i=S_{n}\\
j=S_{m}\end{array}}\mathbf{D}_{i,j}\\
 & =\mathbf{D}\times\left\langle M_{n}\cdot M_{m}^{T}\right\rangle \end{align*}

\end_inset


\end_layout

\begin_layout Section
Random Vector Testing Implementation
\end_layout

\begin_layout Standard
Lets take a look at what happens when we have a set of test data.
 In this case, we have test subset 
\begin_inset Formula $S$
\end_inset

, and we want to determine the probability of a set of points based on existing
 support vectors 
\begin_inset Formula $\mathbf{\hat{x}}\in\mathcal{\hat{S}}$
\end_inset

.
 To do so we must evaluate equation
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:varphiSV"

\end_inset

, which includes evaluating the kernel distance from 
\begin_inset Formula $S$
\end_inset

 to each of the support vector subsets.
 There is a possibility that elements of 
\begin_inset Formula $\mathcal{\hat{S}}$
\end_inset

 overlap, so let's treat this situation in a similar manner:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\mathbf{D}_{i,j} & =k_{\gamma}(\mathbf{x},\mathbf{\hat{x}})\\
\mathbf{\bar{D}}_{A,B} & =\sum_{\begin{array}{c}
i\in A\\
j\in B\end{array}}\mathbf{D}_{i,j}\\
 & =\mathbf{D}\times\left\langle M_{n}\cdot M_{m}^{T}\right\rangle \\
\mathbf{\bar{D}}_{x,B} & =\mathbf{D}_{x}\times M_{B}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
If we observe that the distance 
\begin_inset Formula $\|S_{\mathbf{x}}-S_{n}\|$
\end_inset

 is a sum over each element of 
\begin_inset Formula $S_{\mathbf{x}}$
\end_inset

, it becomes obvious that
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\|S_{\mathbf{x}}-S_{n}\|_{H} & =\|S-S_{n}\|_{H}+\|\mathbf{x}-S_{n}\|_{H}\\
 & =\frac{\mathbf{\mathbf{\bar{D}}}_{\mathbf{x},S_{n}}}{|S_{n}|}\ \log\frac{\mathbf{\mathbf{\bar{D}}}_{\mathbf{x},S_{n}}}{|S_{n}|}+\sum_{x\in X}\frac{\mathbf{\mathbf{\bar{D}}}_{x,S_{n}}}{|S_{n}|}\ \log\frac{\mathbf{\mathbf{\bar{D}}}_{x,S_{n}}}{|S_{n}|}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can calculate 
\begin_inset Formula $\|\mathbf{x}-S_{n}\|_{H}$
\end_inset

 as a column vector and add 
\begin_inset Formula $\|S-S_{n}\|_{H}$
\end_inset

 to each element to get the column vector 
\begin_inset Formula $\|S_{\mathbf{x}}-S_{n}\|_{H}$
\end_inset

.
 We know that our estimate of 
\begin_inset Formula $\mathbf{x}$
\end_inset

 is defined as:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
\varphi_{SV}(S_{\mathbf{x}}:\beta) & =\sum_{i\in\mathcal{S}}\beta_{i}K_{\gamma}(S_{\mathbf{x}},\hat{S}_{i})\\
S_{\mathbf{x}} & =\{S\cup\mathbf{x}\}\end{align*}

\end_inset


\end_layout

\begin_layout Standard
We can calculate our results using a matrix 
\begin_inset Formula $R$
\end_inset

:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{align*}
R_{\mathbf{x},n} & =\|S_{\mathbf{x}}-\hat{S}_{n}\|_{H}\\
 & =\|S-\hat{S}_{n}\|_{H}+\|\mathbf{x}-\hat{S}_{n}\|_{H}\\
\varphi_{SV}(S_{\mathbf{x}}:\beta) & =\left\langle R\cdot\beta\right\rangle \end{align*}

\end_inset


\end_layout

\begin_layout Standard
Again, observe that 
\begin_inset Formula $\|S-S_{n}\|_{H}$
\end_inset

 is the same for any 
\begin_inset Formula $\mathbf{x}|S$
\end_inset

.
 
\end_layout

\begin_layout Section
Random Thoughts
\end_layout

\begin_layout Standard
What if instead of using 
\begin_inset Formula $\theta$
\end_inset

, we simply specified a number of observations to include.
 This would allow us to represent each subset with a 3rd dimension in the
 array, since the 3rd dimension would have a set number of values.
 I'm not sure if that helps though - we get back to the data duplication
 issue.
 I think we need to either duplicate the data or mask it - the combination
 of the two seems like the worst of both worlds.
\end_layout

\begin_layout Standard
I'm still leaning towards masking, especially as we start to get into longer
 window lengths.
 How can this be done efficiently?
\end_layout

\end_body
\end_document
